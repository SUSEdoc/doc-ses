<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes"/><title>Erasure Coded Pools | Administration Guide | SUSE Enterprise Storage 6</title><link rel="stylesheet" type="text/css" href="static/css/style.css"/>
<meta name="title" content="Erasure Coded Pools | SES 6"/>
<meta name="description" content="Ceph provides an alternative to the normal replication of data in pools, called erasure or erasure coded pool. Erasure pools do not provide all functionality o…"/>
<meta name="product-name" content="SUSE Enterprise Storage"/>
<meta name="product-number" content="6"/>
<meta name="book-title" content="Administration Guide"/>
<meta name="chapter-title" content="Chapter 24. Erasure Coded Pools"/>
<meta name="tracker-url" content="https://github.com/SUSE/doc-ses/issues/new/choose"/>
<meta name="tracker-type" content="gh"/>
<meta name="tracker-gh-assignee" content="asettle"/>
<meta name="tracker-gh-labels" content="bug,question,feature request"/>
<meta property="og:title" content="Erasure Coded Pools | SES 6"/>
<meta property="og:description" content="Ceph provides an alternative to the normal replication of data in pools, called erasure or erasure coded pool. Erasure pools do not provide all functionality o…"/>
<meta property="og:type" content="article"/>
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Erasure Coded Pools | SES 6"/>
<meta name="twitter:description" content="Ceph provides an alternative to the normal replication of data in pools, called erasure or erasure coded pool. Erasure pools do not provide all functionality o…"/>
<link rel="prev" href="ceph-rbd.html" title="Chapter 23. RADOS Block Device"/><link rel="next" href="cha-ceph-configuration.html" title="Chapter 25. Ceph Cluster Configuration"/>
<script type="text/javascript">

if ( window.location.protocol.toLowerCase() != 'file:' ) {
  document.write('<link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css"></link>');
};

</script><noscript><link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css"/></noscript><script src="static/js/jquery-1.10.2.min.js" type="text/javascript"> </script><script src="static/js/script.js" type="text/javascript"> </script><script src="static/js/highlight.min.js" type="text/javascript"> </script><script>

$(document).ready(function() {
  $('.verbatim-wrap.highlight').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});
hljs.configure({
  useBR: false
});

</script></head><body class="draft wide offline js-off" onload="$('#betawarn-button-wrap').toggle();if (document.cookie.length > 0) {if (document.cookie.indexOf('betawarn=closed') != -1){$('#betawarn').toggle()}};"><div id="betawarn" style="position:fixed;bottom:0;z-index:9025;background-color:#FDE8E8;padding:1em;margin-left:10%;margin-right:10%;display:block;border-top:.75em solid #E11;width:80%"><p style="color:#333;margin:1em 0;padding:0;">This is a draft document that was built and uploaded automatically. It may document beta software and be incomplete or even incorrect. <strong>Use this document at your own risk.</strong></p> <div id="betawarn-button-wrap" style="display:none;margin:0;padding:0;"><a href="#" onclick="$('#betawarn').toggle();var d=new Date();d.setTime(d.getTime()+(0.5*24*60*60*1000));document.cookie='betawarn=closed; expires='+d.toUTCString()+'; path=/'; return false;" style="color:#333;text-decoration:underline;float:left;margin-top:.5em;padding:1em;display:block;background-color:#FABEBE;">I understand this is a draft</a></div></div><div class="bypass-block"><a href="#_content">Jump to content</a><a href="#_bottom-pagination">Jump to page navigation: previous page [access key p]/next page [access key n]</a></div><header id="_mainnav"><div class="growth-inhibitor"><img src="static/images/logo.svg" alt="Logo" class="logo"/></div></header><div class="crumbs"><div class="growth-inhibitor"><a class="crumb" href="index.html">Administration Guide</a><span> / </span><a class="crumb" href="part-operate.html">Operating a Cluster</a><span> / </span><a class="crumb" href="cha-ceph-erasure.html">Erasure Coded Pools</a></div></div><main id="_content"><nav id="_side-toc-overall" class="side-toc"><div class="side-title">Administration Guide</div><ol><li><a href="bk01pr01.html" class=" "><span class="title-number"> </span><span class="title-name">About This Guide</span></a></li><li><a href="part-cluster-managment.html" class="has-children "><span class="title-number">I </span><span class="title-name">Cluster Management</span></a><ol><li><a href="bk01pt01ch01.html" class=" "><span class="title-number">1 </span><span class="title-name">User Privileges and Command Prompts</span></a></li><li><a href="storage-salt-cluster.html" class=" "><span class="title-number">2 </span><span class="title-name">Salt Cluster Administration</span></a></li><li><a href="cha-deployment-backup.html" class=" "><span class="title-number">3 </span><span class="title-name">Backing Up Cluster Configuration and Data</span></a></li></ol></li><li><a href="part-dashboard.html" class="has-children "><span class="title-number">II </span><span class="title-name">Ceph Dashboard</span></a><ol><li><a href="dashboard-about.html" class=" "><span class="title-number">4 </span><span class="title-name">About Ceph Dashboard</span></a></li><li><a href="dashboard-webui-general.html" class=" "><span class="title-number">5 </span><span class="title-name">Dashboard's Web User Interface</span></a></li><li><a href="dashboard-user-mgmt.html" class=" "><span class="title-number">6 </span><span class="title-name">Managing Dashboard Users and Roles</span></a></li><li><a href="dashboard-cluster.html" class=" "><span class="title-number">7 </span><span class="title-name">Viewing Cluster Internals</span></a></li><li><a href="dashboard-pools.html" class=" "><span class="title-number">8 </span><span class="title-name">Managing Pools</span></a></li><li><a href="dashboard-rbds.html" class=" "><span class="title-number">9 </span><span class="title-name">Managing RADOS Block Devices</span></a></li><li><a href="dash-webui-nfs.html" class=" "><span class="title-number">10 </span><span class="title-name">Managing NFS Ganesha</span></a></li><li><a href="dashboard-mds.html" class=" "><span class="title-number">11 </span><span class="title-name">Managing Ceph File Systems</span></a></li><li><a href="dashboard-ogw.html" class=" "><span class="title-number">12 </span><span class="title-name">Managing Object Gateways</span></a></li><li><a href="dashboard-initial-configuration.html" class=" "><span class="title-number">13 </span><span class="title-name">Manual Configuration</span></a></li><li><a href="dashboard-user-roles.html" class=" "><span class="title-number">14 </span><span class="title-name">Managing Users and Roles on the Command Line</span></a></li></ol></li><li class="active"><a href="part-operate.html" class="has-children you-are-here"><span class="title-number">III </span><span class="title-name">Operating a Cluster</span></a><ol><li><a href="cha-ceph-operating.html" class=" "><span class="title-number">15 </span><span class="title-name">Introduction</span></a></li><li><a href="ceph-operating-services.html" class=" "><span class="title-number">16 </span><span class="title-name">Operating Ceph Services</span></a></li><li><a href="ceph-monitor.html" class=" "><span class="title-number">17 </span><span class="title-name">Determining Cluster State</span></a></li><li><a href="monitoring-alerting.html" class=" "><span class="title-number">18 </span><span class="title-name">Monitoring and Alerting</span></a></li><li><a href="cha-storage-cephx.html" class=" "><span class="title-number">19 </span><span class="title-name">Authentication with <code class="systemitem">cephx</code></span></a></li><li><a href="cha-storage-datamgm.html" class=" "><span class="title-number">20 </span><span class="title-name">Stored Data Management</span></a></li><li><a href="cha-mgr-modules.html" class=" "><span class="title-number">21 </span><span class="title-name">Ceph Manager Modules</span></a></li><li><a href="ceph-pools.html" class=" "><span class="title-number">22 </span><span class="title-name">Managing Storage Pools</span></a></li><li><a href="ceph-rbd.html" class=" "><span class="title-number">23 </span><span class="title-name">RADOS Block Device</span></a></li><li><a href="cha-ceph-erasure.html" class=" you-are-here"><span class="title-number">24 </span><span class="title-name">Erasure Coded Pools</span></a></li><li><a href="cha-ceph-configuration.html" class=" "><span class="title-number">25 </span><span class="title-name">Ceph Cluster Configuration</span></a></li></ol></li><li><a href="part-dataccess.html" class="has-children "><span class="title-number">IV </span><span class="title-name">Accessing Cluster Data</span></a><ol><li><a href="cha-ceph-gw.html" class=" "><span class="title-number">26 </span><span class="title-name">Ceph Object Gateway</span></a></li><li><a href="cha-ceph-iscsi.html" class=" "><span class="title-number">27 </span><span class="title-name">Ceph iSCSI Gateway</span></a></li><li><a href="cha-ceph-cephfs.html" class=" "><span class="title-number">28 </span><span class="title-name">Clustered File System</span></a></li><li><a href="cha-ses-cifs.html" class=" "><span class="title-number">29 </span><span class="title-name">Exporting Ceph Data via Samba</span></a></li><li><a href="cha-ceph-nfsganesha.html" class=" "><span class="title-number">30 </span><span class="title-name">NFS Ganesha: Export Ceph Data via NFS</span></a></li></ol></li><li><a href="part-virt.html" class="has-children "><span class="title-number">V </span><span class="title-name">Integration with Virtualization Tools</span></a><ol><li><a href="cha-ceph-libvirt.html" class=" "><span class="title-number">31 </span><span class="title-name">Using <code class="systemitem">libvirt</code> with Ceph</span></a></li><li><a href="cha-ceph-kvm.html" class=" "><span class="title-number">32 </span><span class="title-name">Ceph as a Back-end for QEMU KVM Instance</span></a></li></ol></li><li><a href="part-troubleshooting.html" class="has-children "><span class="title-number">VI </span><span class="title-name">FAQs, Tips and Troubleshooting</span></a><ol><li><a href="storage-tips.html" class=" "><span class="title-number">33 </span><span class="title-name">Hints and Tips</span></a></li><li><a href="storage-faqs.html" class=" "><span class="title-number">34 </span><span class="title-name">Frequently Asked Questions</span></a></li><li><a href="storage-troubleshooting.html" class=" "><span class="title-number">35 </span><span class="title-name">Troubleshooting</span></a></li></ol></li><li><a href="app-stage1-custom.html" class=" "><span class="title-number">A </span><span class="title-name">DeepSea Stage 1 Custom Example</span></a></li><li><a href="bk01apb.html" class=" "><span class="title-number">B </span><span class="title-name">Ceph Maintenance Updates Based on Upstream 'Nautilus' Point Releases</span></a></li><li><a href="bk01go01.html" class=" "><span class="title-number"> </span><span class="title-name">Glossary</span></a></li><li><a href="ap-adm-docupdate.html" class=" "><span class="title-number">C </span><span class="title-name">Documentation Updates</span></a></li> </ol> </nav><button id="_open-side-toc-overall" title="Contents"> </button><article class="documentation"><button id="_unfold-side-toc-page">On this page</button><section class="chapter" id="cha-ceph-erasure" data-id-title="Erasure Coded Pools"><div class="titlepage"><div><div class="version-info">Applies to  <span class="productname">SUSE Enterprise Storage</span> <span class="productnumber">6</span></div><div><h2 class="title"><span class="title-number">24 </span><span class="title-name">Erasure Coded Pools</span> <a title="Permalink" class="permalink" href="cha-ceph-erasure.html#">#</a></h2></div></div></div><p>
  Ceph provides an alternative to the normal replication of data in pools,
  called <span class="emphasis"><em>erasure</em></span> or <span class="emphasis"><em>erasure coded</em></span>
  pool. Erasure pools do not provide all functionality of
  <span class="emphasis"><em>replicated</em></span> pools (for example, they cannot store
  metadata for RBD pools), but require less raw storage. A default erasure pool
  capable of storing 1 TB of data requires 1.5 TB of raw storage, allowing a
  single disk failure. This compares favorably to a replicated pool, which
  needs 2 TB of raw storage for the same purpose.
 </p><p>
  For background information on Erasure Code, see
  <a class="link" href="https://en.wikipedia.org/wiki/Erasure_code" target="_blank">https://en.wikipedia.org/wiki/Erasure_code</a>.
 </p><p>
  For a list of pool values related to EC pools, refer to
  <a class="xref" href="ceph-pools.html#pool-values-ec" title="Erasure Coded Pool Values">Erasure Coded Pool Values</a>.
 </p><div id="id-1.3.5.11.6" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><h6>Note</h6><p>
   When using FileStore, you cannot access erasure coded pools with the RBD
   interface unless you have a cache tier configured. Refer to
   <span class="intraxref">Book “Tuning Guide”, Chapter 7 “Cache Tiering”, Section 7.5 “Erasure Coded Pool and Cache Tiering”</span> for more details, or use the default
   BlueStore (see <span class="intraxref">Book “Deployment Guide”, Chapter 1 “SUSE Enterprise Storage 6 and Ceph”, Section 1.4 “BlueStore”</span>).
  </p></div><section class="sect1" id="ec-prerequisite" data-id-title="Prerequisite for Erasure Coded Pools"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">24.1 </span><span class="title-name">Prerequisite for Erasure Coded Pools</span> <a title="Permalink" class="permalink" href="cha-ceph-erasure.html#ec-prerequisite">#</a></h2></div></div></div><p>
   To make use of erasure coding, you need to:
  </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
     Define an erasure rule in the CRUSH Map.
    </p></li><li class="listitem"><p>
     Define an erasure code profile that specifies the coding algorithm to be
     used.
    </p></li><li class="listitem"><p>
     Create a pool using the previously mentioned rule and profile.
    </p></li></ul></div><p>
   Keep in mind that changing the profile and the details in the profile will
   not be possible after the pool is created and has data.
  </p><p>
   Ensure that the CRUSH rules for <span class="emphasis"><em>erasure pools</em></span> use
   <code class="literal">indep</code> for <code class="literal">step</code>. For details see
   <a class="xref" href="cha-storage-datamgm.html#datamgm-rules-step-mode" title="20.3.2. firstn and indep">Section 20.3.2, “firstn and indep”</a>.
  </p></section><section class="sect1" id="cha-ceph-erasure-default-profile" data-id-title="Creating a Sample Erasure Coded Pool"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">24.2 </span><span class="title-name">Creating a Sample Erasure Coded Pool</span> <a title="Permalink" class="permalink" href="cha-ceph-erasure.html#cha-ceph-erasure-default-profile">#</a></h2></div></div></div><p>
   The simplest erasure coded pool is equivalent to RAID5 and requires at least
   three hosts. This procedure describes how to create a pool for testing
   purposes.
  </p><div class="procedure"><div class="procedure-contents"><ol class="procedure" type="1"><li class="step"><p>
     The command <code class="command">ceph osd pool create</code> is used to create a
     pool with type <span class="emphasis"><em>erasure</em></span>. The <code class="literal">12</code>
     stands for the number of placement groups. With default parameters, the
     pool is able to handle the failure of one OSD.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm@adm &gt; </code>ceph osd pool create ecpool 12 12 erasure
pool 'ecpool' created</pre></div></li><li class="step"><p>
     The string <code class="literal">ABCDEFGHI</code> is written into an object called
     <code class="literal">NYAN</code>.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm@adm &gt; </code>echo ABCDEFGHI | rados --pool ecpool put NYAN -</pre></div></li><li class="step"><p>
     For testing purposes OSDs can now be disabled, for example by
     disconnecting them from the network.
    </p></li><li class="step"><p>
     To test whether the pool can handle the failure of devices, the content of
     the file can be accessed with the <code class="command">rados</code> command.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm@adm &gt; </code>rados --pool ecpool get NYAN -
ABCDEFGHI</pre></div></li></ol></div></div></section><section class="sect1" id="cha-ceph-erasure-erasure-profiles" data-id-title="Erasure Code Profiles"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">24.3 </span><span class="title-name">Erasure Code Profiles</span> <a title="Permalink" class="permalink" href="cha-ceph-erasure.html#cha-ceph-erasure-erasure-profiles">#</a></h2></div></div></div><p>
   When the <code class="command">ceph osd pool create</code> command is invoked to
   create an <span class="emphasis"><em>erasure pool</em></span>, the default profile is used,
   unless another profile is specified. Profiles define the redundancy of data.
   This is done by setting two parameters, arbitrarily named
   <code class="literal">k</code> and <code class="literal">m</code>. k and m define in how many
   <code class="literal">chunks</code> a piece of data is split and how many coding
   chunks are created. Redundant chunks are then stored on different OSDs.
  </p><p>
   Definitions required for erasure pool profiles:
  </p><div class="variablelist"><dl class="variablelist"><dt id="id-1.3.5.11.9.4.1"><span class="term">chunk</span></dt><dd><p>
      when the encoding function is called, it returns chunks of the same size:
      data chunks which can be concatenated to reconstruct the original object
      and coding chunks which can be used to rebuild a lost chunk.
     </p></dd><dt id="id-1.3.5.11.9.4.2"><span class="term">k</span></dt><dd><p>
      the number of data chunks, that is the number of chunks into which the
      original object is divided. For example, if <code class="literal">k = 2</code> a 10
      kB object will be divided into <code class="literal">k</code> objects of 5 kB each.
      The default <code class="literal">min_size</code> on erasure coded pools is
      <code class="literal">k + 1</code>. However, we recommend
      <code class="literal">min_size</code> to be <code class="literal">k + 2</code> or more to
      prevent loss of writes and data.
     </p></dd><dt id="id-1.3.5.11.9.4.3"><span class="term">m</span></dt><dd><p>
      the number of coding chunks, that is the number of additional chunks
      computed by the encoding functions. If there are 2 coding chunks, it
      means 2 OSDs can be out without losing data.
     </p></dd><dt id="id-1.3.5.11.9.4.4"><span class="term">crush-failure-domain</span></dt><dd><p>
      defines to which devices the chunks are distributed. A bucket type needs
      to be set as value. For all bucket types, see
      <a class="xref" href="cha-storage-datamgm.html#datamgm-buckets" title="20.2. Buckets">Section 20.2, “Buckets”</a>. If the failure domain is
      <code class="literal">rack</code>, the chunks will be stored on different racks to
      increase the resilience in case of rack failures. Keep in mind that this
      requires k+m racks.
     </p></dd></dl></div><p>
   With the default erasure code profile used in
   <a class="xref" href="cha-ceph-erasure.html#cha-ceph-erasure-default-profile" title="24.2. Creating a Sample Erasure Coded Pool">Section 24.2, “Creating a Sample Erasure Coded Pool”</a>, you will not lose
   cluster data if a single OSD or host fails. Therefore, to store 1 TB of data
   it needs another 0.5 TB of raw storage. That means 1.5 TB of raw storage is
   required for 1 TB of data (because of k=2, m=1). This is equivalent to a
   common RAID 5 configuration. For comparison, a replicated pool needs 2 TB of
   raw storage to store 1 TB of data.
  </p><p>
   The settings of the default profile can be displayed with:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm@adm &gt; </code>ceph osd erasure-code-profile get default
directory=.libs
k=2
m=1
plugin=jerasure
crush-failure-domain=host
technique=reed_sol_van</pre></div><p>
   Choosing the right profile is important because it cannot be modified after
   the pool is created. A new pool with a different profile needs to be created
   and all objects from the previous pool moved to the new one (see
   <a class="xref" href="ceph-pools.html#pools-migration" title="22.3. Pool Migration">Section 22.3, “Pool Migration”</a>).
  </p><p>
   The most important parameters of the profile are <code class="literal">k</code>,
   <code class="literal">m</code> and <code class="literal">crush-failure-domain</code> because
   they define the storage overhead and the data durability. For example, if
   the desired architecture must sustain the loss of two racks with a storage
   overhead of 66%, the following profile can be defined. Note that this is
   only valid with a CRUSH Map that has buckets of type 'rack':
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm@adm &gt; </code>ceph osd erasure-code-profile set <em class="replaceable">myprofile</em> \
   k=3 \
   m=2 \
   crush-failure-domain=rack</pre></div><p>
   The example <a class="xref" href="cha-ceph-erasure.html#cha-ceph-erasure-default-profile" title="24.2. Creating a Sample Erasure Coded Pool">Section 24.2, “Creating a Sample Erasure Coded Pool”</a> can be
   repeated with this new profile:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm@adm &gt; </code>ceph osd pool create ecpool 12 12 erasure <em class="replaceable">myprofile</em>
<code class="prompt user">cephadm@adm &gt; </code>echo ABCDEFGHI | rados --pool ecpool put NYAN -
<code class="prompt user">cephadm@adm &gt; </code>rados --pool ecpool get NYAN -
ABCDEFGHI</pre></div><p>
   The NYAN object will be divided in three (<code class="literal">k=3</code>) and two
   additional chunks will be created (<code class="literal">m=2</code>). The value of
   <code class="literal">m</code> defines how many OSDs can be lost simultaneously
   without losing any data. The <code class="literal">crush-failure-domain=rack</code>
   will create a CRUSH ruleset that ensures no two chunks are stored in the
   same rack.
  </p><div class="informalfigure"><div class="mediaobject"><a href="images/ceph_erasure_obj.png" target="_blank"><img src="images/ceph_erasure_obj.png" width=""/></a></div></div><section class="sect2" id="ec-create" data-id-title="Creating a New Erasure Code Profile"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">24.3.1 </span><span class="title-name">Creating a New Erasure Code Profile</span> <a title="Permalink" class="permalink" href="cha-ceph-erasure.html#ec-create">#</a></h3></div></div></div><p>
    The following command creates a new erasure code profile:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">root # </code>ceph osd erasure-code-profile set <em class="replaceable">NAME</em> \
 directory=<em class="replaceable">DIRECTORY</em> \
 plugin=<em class="replaceable">PLUGIN</em> \
 stripe_unit=<em class="replaceable">STRIPE_UNIT</em> \
 <em class="replaceable">KEY</em>=<em class="replaceable">VALUE</em> ... \
 --force</pre></div><div class="variablelist"><dl class="variablelist"><dt id="id-1.3.5.11.9.15.4.1"><span class="term">DIRECTORY</span></dt><dd><p>
       Optional. Set the directory name from which the erasure code plugin is
       loaded. Default is <code class="filename">/usr/lib/ceph/erasure-code</code>.
      </p></dd><dt id="id-1.3.5.11.9.15.4.2"><span class="term">PLUGIN</span></dt><dd><p>
       Optional. Use the erasure code plugin to compute coding chunks and
       recover missing chunks. Available plugins are 'jerasure', 'isa', 'lrc',
       and 'shes'. Default is 'jerasure'.
      </p></dd><dt id="id-1.3.5.11.9.15.4.3"><span class="term">STRIPE_UNIT</span></dt><dd><p>
       Optional. The amount of data in a data chunk, per stripe. For example, a
       profile with 2 data chunks and stripe_unit=4K would put the range 0-4K
       in chunk 0, 4K-8K in chunk 1, then 8K-12K in chunk 0 again. This should
       be a multiple of 4K for best performance. The default value is taken
       from the monitor configuration option
       <code class="option">osd_pool_erasure_code_stripe_unit</code> when a pool is
       created. The 'stripe_width' of a pool using this profile will be the
       number of data chunks multiplied by this 'stripe_unit'.
      </p></dd><dt id="id-1.3.5.11.9.15.4.4"><span class="term">KEY=VALUE</span></dt><dd><p>
       Key/value pairs of options specific to the selected erasure code plugin.
      </p></dd><dt id="id-1.3.5.11.9.15.4.5"><span class="term">--force</span></dt><dd><p>
       Optional. Override an existing profile by the same name, and allow
       setting a non-4K-aligned stripe_unit.
      </p></dd></dl></div><div id="id-1.3.5.11.9.15.5" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.svg"/><h6>Warning</h6><p>
     We strongly recommend that profiles are never modified. Instead, a new
     profile should be created and used when creating a new pool or creating a
     new rule for an existing pool. Seek expert advice before performing this
     action in specific circumstances.
    </p></div></section><section class="sect2" id="ec-rm" data-id-title="Removing an Erasure Code Profile"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">24.3.2 </span><span class="title-name">Removing an Erasure Code Profile</span> <a title="Permalink" class="permalink" href="cha-ceph-erasure.html#ec-rm">#</a></h3></div></div></div><p>
    The following command removes an erasure code profile as identified by its
    <em class="replaceable">NAME</em>:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">root # </code>ceph osd erasure-code-profile rm <em class="replaceable">NAME</em></pre></div><div id="id-1.3.5.11.9.16.4" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.svg"/><h6>Important</h6><p>
     If the profile is referenced by a pool, the deletion will fail.
    </p></div></section><section class="sect2" id="ec-get" data-id-title="Displaying an Erasure Code Profiles Details"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">24.3.3 </span><span class="title-name">Displaying an Erasure Code Profile's Details</span> <a title="Permalink" class="permalink" href="cha-ceph-erasure.html#ec-get">#</a></h3></div></div></div><p>
    The following command displays details of an erasure code profile as
    identified by its <em class="replaceable">NAME</em>:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">root # </code>ceph osd erasure-code-profile get <em class="replaceable">NAME</em></pre></div></section><section class="sect2" id="ec-ls" data-id-title="Listing Erasure Code Profiles"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">24.3.4 </span><span class="title-name">Listing Erasure Code Profiles</span> <a title="Permalink" class="permalink" href="cha-ceph-erasure.html#ec-ls">#</a></h3></div></div></div><p>
    The following command lists the names of all erasure code profiles:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">root # </code>ceph osd erasure-code-profile ls</pre></div></section></section><section class="sect1" id="ec-rbd" data-id-title="Erasure Coded Pools with RADOS Block Device"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">24.4 </span><span class="title-name">Erasure Coded Pools with RADOS Block Device</span> <a title="Permalink" class="permalink" href="cha-ceph-erasure.html#ec-rbd">#</a></h2></div></div></div><p>
   To mark an EC pool as an RBD pool, tag it accordingly:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm@adm &gt; </code>ceph osd pool application enable <em class="replaceable">ec_pool_name</em> rbd</pre></div><p>
   RBD can store image <span class="emphasis"><em>data</em></span> in EC pools. However, the
   image header and metadata still need to be stored in a replicated pool.
   Assuming you have the pool named 'rbd' for this purpose:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm@adm &gt; </code>rbd create rbd/<em class="replaceable">image_name</em> --size 1T --data-pool <em class="replaceable">ec_pool_name</em></pre></div><p>
   You can use the image normally like any other image, except that all of the
   data will be stored in the <em class="replaceable">ec_pool_name</em> pool
   instead of 'rbd' pool.
  </p></section></section><nav class="bottom-pagination"><div><a class="pagination-link prev" href="ceph-rbd.html"><span class="pagination-relation">Previous</span><span class="pagination-label"><span class="title-number">Chapter 23 </span>RADOS Block Device</span></a> </div><div><a class="pagination-link next" href="cha-ceph-configuration.html"><span class="pagination-relation">Next</span><span class="pagination-label"><span class="title-number">Chapter 25 </span>Ceph Cluster Configuration</span></a> </div></nav></article><aside id="_side-toc-page" class="side-toc"><div class="side-title">On this page</div><div class="toc"><ul><li><span class="sect1"><a href="cha-ceph-erasure.html#ec-prerequisite"><span class="title-number">24.1 </span><span class="title-name">Prerequisite for Erasure Coded Pools</span></a></span></li><li><span class="sect1"><a href="cha-ceph-erasure.html#cha-ceph-erasure-default-profile"><span class="title-number">24.2 </span><span class="title-name">Creating a Sample Erasure Coded Pool</span></a></span></li><li><span class="sect1"><a href="cha-ceph-erasure.html#cha-ceph-erasure-erasure-profiles"><span class="title-number">24.3 </span><span class="title-name">Erasure Code Profiles</span></a></span></li><li><span class="sect1"><a href="cha-ceph-erasure.html#ec-rbd"><span class="title-number">24.4 </span><span class="title-name">Erasure Coded Pools with RADOS Block Device</span></a></span></li></ul></div><div class="side-title">Give feedback</div><ul class="feedback" id="_give-feedback"><li><a id="_feedback-reportbug" href="#" rel="nofollow" target="_blank">Report an issue</a></li><li><a id="_feedback-editurl" href="https://github.com/SUSE/doc-ses/edit/maintenance/ses6/xml/admin_ceph_erasure.xml" rel="nofollow" target="_blank">Edit source document</a></li></ul><div class="side-title">Share this page</div><ul class="share"><li><a id="_share-fb" href="#" title="Facebook"> </a></li><li><a id="_share-in" href="#" title="LinkedIn"> </a></li><li><a id="_share-tw" href="#" title="Twitter"> </a></li><li><a id="_share-mail" href="#" title="E-Mail"> </a></li><li><a id="_print-button" href="#" title="Print this page"> </a></li></ul> </aside></main><footer id="_footer"><div class="growth-inhibitor"><div class="copy"><span class="copy__rights">© SUSE
                 2022</span></div></div></footer></body></html>