<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes"/><title>Installation of NFS Ganesha | Deployment Guide | SUSE Enterprise Storage 6</title><link rel="stylesheet" type="text/css" href="static/css/style.css"/>
<meta name="title" content="Installation of NFS Ganesha | SES 6"/>
<meta name="description" content="NFS Ganesha provides NFS access to either the Object Gateway or the CephFS. In SUSE Enterprise Storage 6, NFS versions 3 and 4 are supported. NFS Ganesha runs …"/>
<meta name="product-name" content="SUSE Enterprise Storage"/>
<meta name="product-number" content="6"/>
<meta name="book-title" content="Deployment Guide"/>
<meta name="chapter-title" content="Chapter 12. Installation of NFS Ganesha"/>
<meta name="tracker-url" content="https://github.com/SUSE/doc-ses/issues/new/choose"/>
<meta name="tracker-type" content="gh"/>
<meta name="tracker-gh-assignee" content="asettle"/>
<meta name="tracker-gh-labels" content="bug,question,feature request"/>
<meta property="og:title" content="Installation of NFS Ganesha | SES 6"/>
<meta property="og:description" content="NFS Ganesha provides NFS access to either the Object Gateway or the CephFS. In SUSE Enterprise Storage 6, NFS versions 3 and 4 are supported. NFS Ganesha runs …"/>
<meta property="og:type" content="article"/>
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Installation of NFS Ganesha | SES 6"/>
<meta name="twitter:description" content="NFS Ganesha provides NFS access to either the Object Gateway or the CephFS. In SUSE Enterprise Storage 6, NFS versions 3 and 4 are supported. NFS Ganesha runs …"/>
<link rel="prev" href="cha-ceph-as-cephfs.html" title="Chapter 11. Installation of CephFS"/><link rel="next" href="containerized-ses-on-caasp.html" title="Part IV. Cluster Deployment on Top of SUSE CaaS Platform 4 (Technology Preview)"/>
<script type="text/javascript">

if ( window.location.protocol.toLowerCase() != 'file:' ) {
  document.write('<link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css"></link>');
};

</script><noscript><link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css"/></noscript><script src="static/js/jquery-1.10.2.min.js" type="text/javascript"> </script><script src="static/js/script.js" type="text/javascript"> </script><script src="static/js/highlight.min.js" type="text/javascript"> </script><script>

$(document).ready(function() {
  $('.verbatim-wrap.highlight').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});
hljs.configure({
  useBR: false
});

</script></head><body class="draft wide offline js-off" onload="$('#betawarn-button-wrap').toggle();if (document.cookie.length > 0) {if (document.cookie.indexOf('betawarn=closed') != -1){$('#betawarn').toggle()}};"><div id="betawarn" style="position:fixed;bottom:0;z-index:9025;background-color:#FDE8E8;padding:1em;margin-left:10%;margin-right:10%;display:block;border-top:.75em solid #E11;width:80%"><p style="color:#333;margin:1em 0;padding:0;">This is a draft document that was built and uploaded automatically. It may document beta software and be incomplete or even incorrect. <strong>Use this document at your own risk.</strong></p> <div id="betawarn-button-wrap" style="display:none;margin:0;padding:0;"><a href="#" onclick="$('#betawarn').toggle();var d=new Date();d.setTime(d.getTime()+(0.5*24*60*60*1000));document.cookie='betawarn=closed; expires='+d.toUTCString()+'; path=/'; return false;" style="color:#333;text-decoration:underline;float:left;margin-top:.5em;padding:1em;display:block;background-color:#FABEBE;">I understand this is a draft</a></div></div><div class="bypass-block"><a href="#_content">Jump to content</a><a href="#_bottom-pagination">Jump to page navigation: previous page [access key p]/next page [access key n]</a></div><header id="_mainnav"><div class="growth-inhibitor"><img src="static/images/logo.svg" alt="Logo" class="logo"/></div></header><div class="crumbs"><div class="growth-inhibitor"><a class="crumb" href="index.html">Deployment Guide</a><span> / </span><a class="crumb" href="additional-software.html">Installation of Additional Services</a><span> / </span><a class="crumb" href="cha-as-ganesha.html">Installation of NFS Ganesha</a></div></div><main id="_content"><nav id="_side-toc-overall" class="side-toc"><div class="side-title">Deployment Guide</div><ol><li><a href="bk02pr01.html" class=" "><span class="title-number"> </span><span class="title-name">About This Guide</span></a></li><li><a href="part-ses.html" class="has-children "><span class="title-number">I </span><span class="title-name">SUSE Enterprise Storage</span></a><ol><li><a href="cha-storage-about.html" class=" "><span class="title-number">1 </span><span class="title-name">SUSE Enterprise Storage 6 and Ceph</span></a></li><li><a href="storage-bp-hwreq.html" class=" "><span class="title-number">2 </span><span class="title-name">Hardware Requirements and Recommendations</span></a></li><li><a href="cha-admin-ha.html" class=" "><span class="title-number">3 </span><span class="title-name">Admin Node HA Setup</span></a></li><li><a href="bk02pt01ch04.html" class=" "><span class="title-number">4 </span><span class="title-name">User Privileges and Command Prompts</span></a></li></ol></li><li><a href="ses-deployment.html" class="has-children "><span class="title-number">II </span><span class="title-name">Cluster Deployment and Upgrade</span></a><ol><li><a href="ceph-install-saltstack.html" class=" "><span class="title-number">5 </span><span class="title-name">Deploying with DeepSea/Salt</span></a></li><li><a href="cha-ceph-upgrade.html" class=" "><span class="title-number">6 </span><span class="title-name">Upgrading from Previous Releases</span></a></li><li><a href="ceph-deploy-ds-custom.html" class=" "><span class="title-number">7 </span><span class="title-name">Customizing the Default Configuration</span></a></li></ol></li><li class="active"><a href="additional-software.html" class="has-children you-are-here"><span class="title-number">III </span><span class="title-name">Installation of Additional Services</span></a><ol><li><a href="cha-ceph-as-intro.html" class=" "><span class="title-number">8 </span><span class="title-name">Installation of Services to Access your Data</span></a></li><li><a href="cha-ceph-additional-software-installation.html" class=" "><span class="title-number">9 </span><span class="title-name">Ceph Object Gateway</span></a></li><li><a href="cha-ceph-as-iscsi.html" class=" "><span class="title-number">10 </span><span class="title-name">Installation of iSCSI Gateway</span></a></li><li><a href="cha-ceph-as-cephfs.html" class=" "><span class="title-number">11 </span><span class="title-name">Installation of CephFS</span></a></li><li><a href="cha-as-ganesha.html" class=" you-are-here"><span class="title-number">12 </span><span class="title-name">Installation of NFS Ganesha</span></a></li></ol></li><li><a href="containerized-ses-on-caasp.html" class="has-children "><span class="title-number">IV </span><span class="title-name">Cluster Deployment on Top of SUSE CaaS Platform 4 (Technology Preview)</span></a><ol><li><a href="cha-container-kubernetes.html" class=" "><span class="title-number">13 </span><span class="title-name">SUSE Enterprise Storage 6 on Top of SUSE CaaS Platform 4 Kubernetes Cluster</span></a></li></ol></li><li><a href="bk02apa.html" class=" "><span class="title-number">A </span><span class="title-name">Ceph Maintenance Updates Based on Upstream 'Nautilus' Point Releases</span></a></li><li><a href="bk02go01.html" class=" "><span class="title-number"> </span><span class="title-name">Glossary</span></a></li><li><a href="ap-deploy-docupdate.html" class=" "><span class="title-number">B </span><span class="title-name">Documentation Updates</span></a></li> </ol> </nav><button id="_open-side-toc-overall" title="Contents"> </button><article class="documentation"><button id="_unfold-side-toc-page">On this page</button><section class="chapter" id="cha-as-ganesha" data-id-title="Installation of NFS Ganesha"><div class="titlepage"><div><div class="version-info">Applies to  <span class="productname">SUSE Enterprise Storage</span> <span class="productnumber">6</span></div><div><h2 class="title"><span class="title-number">12 </span><span class="title-name">Installation of NFS Ganesha</span> <a title="Permalink" class="permalink" href="cha-as-ganesha.html#">#</a></h2></div></div></div><p>
  NFS Ganesha provides NFS access to either the Object Gateway or the CephFS. In
  SUSE Enterprise Storage 6, NFS versions 3 and 4 are supported. NFS Ganesha
  runs in the user space instead of the kernel space and directly interacts
  with the Object Gateway or CephFS.
 </p><div id="id-1.4.5.6.4" data-id-title="Cross Protocol Access" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.svg"/><h6>Warning: Cross Protocol Access</h6><p>
   Native CephFS and NFS clients are not restricted by file locks obtained
   via Samba, and vice versa. Applications that rely on cross protocol file
   locking may experience data corruption if CephFS backed Samba share paths
   are accessed via other means.
  </p></div><section class="sect1" id="sec-as-ganesha-preparation" data-id-title="Preparation"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">12.1 </span><span class="title-name">Preparation</span> <a title="Permalink" class="permalink" href="cha-as-ganesha.html#sec-as-ganesha-preparation">#</a></h2></div></div></div><section class="sect2" id="sec-as-ganesha-preparation-general" data-id-title="General Information"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">12.1.1 </span><span class="title-name">General Information</span> <a title="Permalink" class="permalink" href="cha-as-ganesha.html#sec-as-ganesha-preparation-general">#</a></h3></div></div></div><p>
    To successfully deploy NFS Ganesha, you need to add a
    <code class="literal">role-ganesha</code> to your
    <code class="filename">/srv/pillar/ceph/proposals/policy.cfg</code>. For details,
    see <a class="xref" href="ceph-install-saltstack.html#policy-configuration" title="5.5.1. The policy.cfg File">Section 5.5.1, “The <code class="filename">policy.cfg</code> File”</a>. NFS Ganesha also needs either a
    <code class="literal">role-rgw</code> or a <code class="literal">role-mds</code> present in the
    <code class="filename">policy.cfg</code>.
   </p><p>
    Although it is possible to install and run the NFS Ganesha server on an
    already existing Ceph node, we recommend running it on a dedicated host
    with access to the Ceph cluster. The client hosts are typically not part
    of the cluster, but they need to have network access to the NFS Ganesha
    server.
   </p><p>
    To enable the NFS Ganesha server at any point after the initial installation,
    add the <code class="literal">role-ganesha</code> to the
    <code class="filename">policy.cfg</code> and re-run at least DeepSea stages 2 and
    4. For details, see <a class="xref" href="ceph-install-saltstack.html#ceph-install-stack" title="5.3. Cluster Deployment">Section 5.3, “Cluster Deployment”</a>.
   </p><p>
    NFS Ganesha is configured via the file
    <code class="filename">/etc/ganesha/ganesha.conf</code> that exists on the NFS Ganesha
    node. However, this file is overwritten each time DeepSea stage 4 is
    executed. Therefore we recommend to edit the template used by Salt, which
    is the file
    <code class="filename">/srv/salt/ceph/ganesha/files/ganesha.conf.j2</code> on the
    Salt master. For details about the configuration file, see
    <span class="intraxref">Book “Administration Guide”, Chapter 30 “NFS Ganesha: Export Ceph Data via NFS”, Section 30.2 “Configuration”</span>.
   </p></section><section class="sect2" id="sec-as-ganesha-preparation-requirements" data-id-title="Summary of Requirements"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">12.1.2 </span><span class="title-name">Summary of Requirements</span> <a title="Permalink" class="permalink" href="cha-as-ganesha.html#sec-as-ganesha-preparation-requirements">#</a></h3></div></div></div><p>
    The following requirements need to be met before DeepSea stages 2 and 4
    can be executed to install NFS Ganesha:
   </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
      At least one node needs to be assigned the
      <code class="literal">role-ganesha</code>.
     </p></li><li class="listitem"><p>
      You can define only one <code class="literal">role-ganesha</code> per minion.
     </p></li><li class="listitem"><p>
      NFS Ganesha needs either an Object Gateway or CephFS to work.
     </p></li><li class="listitem"><p>
      The kernel based NFS needs to be disabled on minions with the
      <code class="literal">role-ganesha</code> role.
     </p></li></ul></div></section></section><section class="sect1" id="sec-as-ganesha-basic-example" data-id-title="Example Installation"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">12.2 </span><span class="title-name">Example Installation</span> <a title="Permalink" class="permalink" href="cha-as-ganesha.html#sec-as-ganesha-basic-example">#</a></h2></div></div></div><p>
   This procedure provides an example installation that uses both the Object Gateway and
   CephFS File System Abstraction Layers (FSAL) of NFS Ganesha.
  </p><div class="procedure"><div class="procedure-contents"><ol class="procedure" type="1"><li class="step"><p>
     If you have not done so, execute DeepSea stages 0 and 1 before
     continuing with this procedure.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">root@master # </code><code class="command">salt-run</code> state.orch ceph.stage.0
<code class="prompt user">root@master # </code><code class="command">salt-run</code> state.orch ceph.stage.1</pre></div></li><li class="step"><p>
     After having executed stage 1 of DeepSea, edit the
     <code class="filename">/srv/pillar/ceph/proposals/policy.cfg</code> and add the
     line
    </p><div class="verbatim-wrap"><pre class="screen">role-ganesha/cluster/<em class="replaceable">NODENAME</em></pre></div><p>
     Replace <em class="replaceable">NODENAME</em> with the name of a node in
     your cluster.
    </p><p>
     Also make sure that a <code class="literal">role-mds</code> and a
     <code class="literal">role-rgw</code> are assigned.
    </p></li><li class="step"><p>
     Execute at least stages 2 and 4 of DeepSea. Running stage 3 in between
     is recommended.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">root@master # </code><code class="command">salt-run</code> state.orch ceph.stage.2
<code class="prompt user">root@master # </code><code class="command">salt-run</code> state.orch ceph.stage.3 # optional but recommended
<code class="prompt user">root@master # </code><code class="command">salt-run</code> state.orch ceph.stage.4</pre></div></li><li class="step"><p>
     Verify that NFS Ganesha is working by checking that the NFS Ganesha service
     is running on the minion node:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">root@master # </code><code class="command">salt</code> -I roles:ganesha service.status nfs-ganesha
<em class="replaceable">MINION_ID</em>:
    True</pre></div></li></ol></div></div></section><section class="sect1" id="sec-ganesha-active-active" data-id-title="Active-Active Configuration"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">12.3 </span><span class="title-name">Active-Active Configuration</span> <a title="Permalink" class="permalink" href="cha-as-ganesha.html#sec-ganesha-active-active">#</a></h2></div></div></div><p>
   This section provides an example of simple active-active NFS Ganesha setup.
   The aim is to deploy two NFS Ganesha servers layered on top of the same
   existing CephFS. The servers will be two Ceph cluster nodes with
   separate addresses. The clients need to be distributed between them
   manually. <span class="quote">“<span class="quote">Failover</span>”</span> in this configuration means manually
   unmounting and remounting the other server on the client.
  </p><section class="sect2" id="sec-ganesha-active-active-prerequisites" data-id-title="Prerequisites"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">12.3.1 </span><span class="title-name">Prerequisites</span> <a title="Permalink" class="permalink" href="cha-as-ganesha.html#sec-ganesha-active-active-prerequisites">#</a></h3></div></div></div><p>
    For our example configuration, you need the following:
   </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
      Running Ceph cluster. See <a class="xref" href="ceph-install-saltstack.html#ceph-install-stack" title="5.3. Cluster Deployment">Section 5.3, “Cluster Deployment”</a> for
      details on deploying and configuring Ceph cluster by using DeepSea.
     </p></li><li class="listitem"><p>
      At least one configured CephFS. See
      <a class="xref" href="cha-ceph-as-cephfs.html" title="Chapter 11. Installation of CephFS">Chapter 11, <em>Installation of CephFS</em></a> for more details on deploying and
      configuring CephFS.
     </p></li><li class="listitem"><p>
      Two Ceph cluster nodes with NFS Ganesha deployed. See
      <a class="xref" href="cha-as-ganesha.html" title="Chapter 12. Installation of NFS Ganesha">Chapter 12, <em>Installation of NFS Ganesha</em></a> for more details on deploying
      NFS Ganesha.
     </p><div id="id-1.4.5.6.7.3.3.3.2" data-id-title="Use Dedicated Servers" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg"/><h6>Tip: Use Dedicated Servers</h6><p>
       Although NFS Ganesha nodes can share resources with other Ceph related
       services, we recommend to use dedicated servers to improve performance.
      </p></div></li></ul></div><p>
    After you deploy the NFS Ganesha nodes, verify that the cluster is
    operational and the default CephFS pools are there:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm@adm &gt; </code>rados lspools
cephfs_data
cephfs_metadata</pre></div></section><section class="sect2" id="sec-ganesha-active-active-configure" data-id-title="Configure NFS Ganesha"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">12.3.2 </span><span class="title-name">Configure NFS Ganesha</span> <a title="Permalink" class="permalink" href="cha-as-ganesha.html#sec-ganesha-active-active-configure">#</a></h3></div></div></div><p>
    Check that both NFS Ganesha nodes have the file
    <code class="filename">/etc/ganesha/ganesha.conf</code> installed. Add the following
    blocks, if they do not exist yet, to the configuration file in order to
    enable RADOS as the recovery backend of NFS Ganesha.
   </p><div class="verbatim-wrap"><pre class="screen">NFS_CORE_PARAM
{
    Enable_NLM = false;
    Enable_RQUOTA = false;
    Protocols = 4;
}
NFSv4
{
    RecoveryBackend = rados_cluster;
    Minor_Versions = 1,2;
}
CACHEINODE {
    Dir_Chunk = 0;
    NParts = 1;
    Cache_Size = 1;
}
RADOS_KV
{
    pool = "<em class="replaceable">rados_pool</em>";
    namespace = "<em class="replaceable">pool_namespace</em>";
    nodeid = "<em class="replaceable">fqdn</em>"
    UserId = "<em class="replaceable">cephx_user_id</em>";
    Ceph_Conf = "<em class="replaceable">path_to_ceph.conf</em>"
}</pre></div><p>
    You can find out the values for <em class="replaceable">rados_pool</em> and
    <em class="replaceable">pool_namespace</em> by checking the already existing
    line in the configuration of the form:
   </p><div class="verbatim-wrap"><pre class="screen">%url rados://<em class="replaceable">rados_pool</em>/<em class="replaceable">pool_namespace</em>/...</pre></div><p>
    The value for <em class="replaceable">nodeid</em> option corresponds to the
    FQDN of the machine, and <em class="replaceable">UserId</em> and
    <em class="replaceable">Ceph_Conf</em> options value can be found in the
    already existing <em class="replaceable">RADOS_URLS</em> block.
   </p><p>
    Because legacy versions of NFS prevent us from lifting the grace period
    early and therefore prolong a server restart, we disable options for NFS
    prior to version 4.2. We also disable most of the NFS Ganesha caching as
    Ceph libraries do aggressive caching already.
   </p><p>
    The 'rados_cluster' recovery back-end stores its info in RADOS objects.
    Although it is not a lot of data, we want it highly available. We use the
    CephFS metadata pool for this purpose, and declare a new 'ganesha'
    namespace in it to keep it distinct from CephFS objects.
   </p><div id="id-1.4.5.6.7.4.9" data-id-title="Cluster Node IDs" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><h6>Note: Cluster Node IDs</h6><p>
     Most of the configuration is identical between the two hosts, however the
     <code class="option">nodeid</code> option in the 'RADOS_KV' block needs to be a
     unique string for each node. By default, NFS Ganesha sets
     <code class="option">nodeid</code> to the host name of the node.
    </p><p>
     If you need to use different fixed values other than host names, you can
     for example set <code class="option">nodeid = 'a'</code> on one node and
     <code class="option">nodeid = 'b'</code> on the other one.
    </p></div></section><section class="sect2" id="ganesha-active-active-grace-db" data-id-title="Populate the Cluster Grace Database"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">12.3.3 </span><span class="title-name">Populate the Cluster Grace Database</span> <a title="Permalink" class="permalink" href="cha-as-ganesha.html#ganesha-active-active-grace-db">#</a></h3></div></div></div><p>
    We need to verify that all of the nodes in the cluster know about each
    other. This done via a RADOS object that is shared between the hosts.
    NFS Ganesha uses this object to communicate the current state with regard to
    a grace period.
   </p><p>
    The <span class="package">nfs-ganesha-rados-grace</span> package contains a command
    line tool for querying and manipulating this database. If the package is
    not installed on at least one of the nodes, install it with
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">root # </code>zypper install nfs-ganesha-rados-grace</pre></div><p>
    We will use the command to create the DB and add both
    <code class="option">nodeid</code>s. In our example, the two NFS Ganesha nodes are named
    <code class="literal">ses6min1.example.com</code> and
    <code class="literal">ses6min2.example.com</code> On one of the NFS Ganesha hosts, run
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm@adm &gt; </code>ganesha-rados-grace -p cephfs_metadata -n ganesha add ses6min1.example.com
<code class="prompt user">cephadm@adm &gt; </code>ganesha-rados-grace -p cephfs_metadata -n ganesha add ses6min2.example.com
<code class="prompt user">cephadm@adm &gt; </code>ganesha-rados-grace -p cephfs_metadata -n ganesha
cur=1 rec=0
======================================================
ses6min1.example.com     E
ses6min2.example.com     E</pre></div><p>
    This creates the grace database and adds both 'ses6min1.example.com' and
    'ses6min2.example.com' to it. The last command dumps the current state.
    Newly added hosts are always considered to be enforcing the grace period so
    they both have the 'E' flag set. The 'cur' and 'rec' values show the
    current and recovery epochs, which is how we keep track of what hosts are
    allowed to perform recovery and when.
   </p></section><section class="sect2" id="ganesha-active-active-restart-servers" data-id-title="Restart NFS Ganesha Services"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">12.3.4 </span><span class="title-name">Restart NFS Ganesha Services</span> <a title="Permalink" class="permalink" href="cha-as-ganesha.html#ganesha-active-active-restart-servers">#</a></h3></div></div></div><p>
    On both NFS Ganesha nodes, restart the related services:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">root # </code>systemctl restart nfs-ganesha.service</pre></div><p>
    After the services are restarted, check the grace database:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm@adm &gt; </code>ganesha-rados-grace -p cephfs_metadata -n ganesha
cur=3 rec=0
======================================================
ses6min1.example.com
ses6min2.example.com</pre></div><div id="id-1.4.5.6.7.6.6" data-id-title="Cleared the E Flag" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><h6>Note: Cleared the 'E' Flag</h6><p>
     Note that both nodes have cleared their 'E' flags, indicating that they
     are no longer enforcing the grace period and are now in normal operation
     mode.
    </p></div></section><section class="sect2" id="ganesha-active-active-conclusion" data-id-title="Conclusion"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">12.3.5 </span><span class="title-name">Conclusion</span> <a title="Permalink" class="permalink" href="cha-as-ganesha.html#ganesha-active-active-conclusion">#</a></h3></div></div></div><p>
    After you complete all the preceding steps, you can mount the exported NFS
    from either of the two NFS Ganesha servers, and perform normal NFS operations
    against them.
   </p><p>
    Our example configuration assumes that if one of the two NFS Ganesha servers
    goes down, you will restart it manually within 5 minutes. After 5 minutes,
    the Metadata Server may cancel the session that the NFS Ganesha client held and all of
    the state associated with it. If the session’s capabilities get cancelled
    before the rest of the cluster goes into the grace period, the server’s
    clients may not be able to recover all of their state.
   </p></section></section><section class="sect1" id="sec-as-ganesha-info" data-id-title="More Information"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">12.4 </span><span class="title-name">More Information</span> <a title="Permalink" class="permalink" href="cha-as-ganesha.html#sec-as-ganesha-info">#</a></h2></div></div></div><p>
   More information can be found in <span class="intraxref">Book “Administration Guide”, Chapter 30 “NFS Ganesha: Export Ceph Data via NFS”</span>.
  </p></section></section><nav class="bottom-pagination"><div><a class="pagination-link prev" href="cha-ceph-as-cephfs.html"><span class="pagination-relation">Previous</span><span class="pagination-label"><span class="title-number">Chapter 11 </span>Installation of CephFS</span></a> </div><div><a class="pagination-link next" href="containerized-ses-on-caasp.html"><span class="pagination-relation">Next</span><span class="pagination-label"><span class="title-number">Part IV </span>Cluster Deployment on Top of SUSE CaaS Platform 4 (Technology Preview)</span></a> </div></nav></article><aside id="_side-toc-page" class="side-toc"><div class="side-title">On this page</div><div class="toc"><ul><li><span class="sect1"><a href="cha-as-ganesha.html#sec-as-ganesha-preparation"><span class="title-number">12.1 </span><span class="title-name">Preparation</span></a></span></li><li><span class="sect1"><a href="cha-as-ganesha.html#sec-as-ganesha-basic-example"><span class="title-number">12.2 </span><span class="title-name">Example Installation</span></a></span></li><li><span class="sect1"><a href="cha-as-ganesha.html#sec-ganesha-active-active"><span class="title-number">12.3 </span><span class="title-name">Active-Active Configuration</span></a></span></li><li><span class="sect1"><a href="cha-as-ganesha.html#sec-as-ganesha-info"><span class="title-number">12.4 </span><span class="title-name">More Information</span></a></span></li></ul></div><div class="side-title">Give feedback</div><ul class="feedback" id="_give-feedback"><li><a id="_feedback-reportbug" href="#" rel="nofollow" target="_blank">Report an issue</a></li><li><a id="_feedback-editurl" href="https://github.com/SUSE/doc-ses/edit/maintenance/ses6/xml/deployment_ganesha.xml" rel="nofollow" target="_blank">Edit source document</a></li></ul><div class="side-title">Share this page</div><ul class="share"><li><a id="_share-fb" href="#" title="Facebook"> </a></li><li><a id="_share-in" href="#" title="LinkedIn"> </a></li><li><a id="_share-tw" href="#" title="Twitter"> </a></li><li><a id="_share-mail" href="#" title="E-Mail"> </a></li><li><a id="_print-button" href="#" title="Print this page"> </a></li></ul> </aside></main><footer id="_footer"><div class="growth-inhibitor"><div class="copy"><span class="copy__rights">© SUSE
                 2022</span></div></div></footer></body></html>