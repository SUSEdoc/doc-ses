<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes"/><title>Installation of iSCSI Gateway | Deployment Guide | SUSE Enterprise Storage 6</title><link rel="stylesheet" type="text/css" href="static/css/style.css"/>
<meta name="title" content="Installation of iSCSI Gateway | SES 6"/>
<meta name="description" content="iSCSI is a storage area network (SAN) protocol that allows clients (called initiators) to send SCSI commands to SCSI storage devices (targets) on remote server…"/>
<meta name="product-name" content="SUSE Enterprise Storage"/>
<meta name="product-number" content="6"/>
<meta name="book-title" content="Deployment Guide"/>
<meta name="chapter-title" content="Chapter 10. Installation of iSCSI Gateway"/>
<meta name="tracker-url" content="https://github.com/SUSE/doc-ses/issues/new/choose"/>
<meta name="tracker-type" content="gh"/>
<meta name="tracker-gh-assignee" content="asettle"/>
<meta name="tracker-gh-labels" content="bug,question,feature request"/>
<meta property="og:title" content="Installation of iSCSI Gateway | SES 6"/>
<meta property="og:description" content="iSCSI is a storage area network (SAN) protocol that allows clients (called initiators) to send SCSI commands to SCSI storage devices (targets) on remote server…"/>
<meta property="og:type" content="article"/>
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Installation of iSCSI Gateway | SES 6"/>
<meta name="twitter:description" content="iSCSI is a storage area network (SAN) protocol that allows clients (called initiators) to send SCSI commands to SCSI storage devices (targets) on remote server…"/>
<link rel="prev" href="cha-ceph-additional-software-installation.html" title="Chapter 9. Ceph Object Gateway"/><link rel="next" href="cha-ceph-as-cephfs.html" title="Chapter 11. Installation of CephFS"/>
<script type="text/javascript">

if ( window.location.protocol.toLowerCase() != 'file:' ) {
  document.write('<link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css"></link>');
};

</script><noscript><link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css"/></noscript><script src="static/js/jquery-1.10.2.min.js" type="text/javascript"> </script><script src="static/js/script.js" type="text/javascript"> </script><script src="static/js/highlight.min.js" type="text/javascript"> </script><script>

$(document).ready(function() {
  $('.verbatim-wrap.highlight').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});
hljs.configure({
  useBR: false
});

</script></head><body class="draft wide offline js-off" onload="$('#betawarn-button-wrap').toggle();if (document.cookie.length > 0) {if (document.cookie.indexOf('betawarn=closed') != -1){$('#betawarn').toggle()}};"><div id="betawarn" style="position:fixed;bottom:0;z-index:9025;background-color:#FDE8E8;padding:1em;margin-left:10%;margin-right:10%;display:block;border-top:.75em solid #E11;width:80%"><p style="color:#333;margin:1em 0;padding:0;">This is a draft document that was built and uploaded automatically. It may document beta software and be incomplete or even incorrect. <strong>Use this document at your own risk.</strong></p> <div id="betawarn-button-wrap" style="display:none;margin:0;padding:0;"><a href="#" onclick="$('#betawarn').toggle();var d=new Date();d.setTime(d.getTime()+(0.5*24*60*60*1000));document.cookie='betawarn=closed; expires='+d.toUTCString()+'; path=/'; return false;" style="color:#333;text-decoration:underline;float:left;margin-top:.5em;padding:1em;display:block;background-color:#FABEBE;">I understand this is a draft</a></div></div><div class="bypass-block"><a href="#_content">Jump to content</a><a href="#_bottom-pagination">Jump to page navigation: previous page [access key p]/next page [access key n]</a></div><header id="_mainnav"><div class="growth-inhibitor"><img src="static/images/logo.svg" alt="Logo" class="logo"/></div></header><div class="crumbs"><div class="growth-inhibitor"><a class="crumb" href="index.html">Deployment Guide</a><span> / </span><a class="crumb" href="additional-software.html">Installation of Additional Services</a><span> / </span><a class="crumb" href="cha-ceph-as-iscsi.html">Installation of iSCSI Gateway</a></div></div><main id="_content"><nav id="_side-toc-overall" class="side-toc"><div class="side-title">Deployment Guide</div><ol><li><a href="bk02pr01.html" class=" "><span class="title-number"> </span><span class="title-name">About This Guide</span></a></li><li><a href="part-ses.html" class="has-children "><span class="title-number">I </span><span class="title-name">SUSE Enterprise Storage</span></a><ol><li><a href="cha-storage-about.html" class=" "><span class="title-number">1 </span><span class="title-name">SUSE Enterprise Storage 6 and Ceph</span></a></li><li><a href="storage-bp-hwreq.html" class=" "><span class="title-number">2 </span><span class="title-name">Hardware Requirements and Recommendations</span></a></li><li><a href="cha-admin-ha.html" class=" "><span class="title-number">3 </span><span class="title-name">Admin Node HA Setup</span></a></li><li><a href="bk02pt01ch04.html" class=" "><span class="title-number">4 </span><span class="title-name">User Privileges and Command Prompts</span></a></li></ol></li><li><a href="ses-deployment.html" class="has-children "><span class="title-number">II </span><span class="title-name">Cluster Deployment and Upgrade</span></a><ol><li><a href="ceph-install-saltstack.html" class=" "><span class="title-number">5 </span><span class="title-name">Deploying with DeepSea/Salt</span></a></li><li><a href="cha-ceph-upgrade.html" class=" "><span class="title-number">6 </span><span class="title-name">Upgrading from Previous Releases</span></a></li><li><a href="ceph-deploy-ds-custom.html" class=" "><span class="title-number">7 </span><span class="title-name">Customizing the Default Configuration</span></a></li></ol></li><li class="active"><a href="additional-software.html" class="has-children you-are-here"><span class="title-number">III </span><span class="title-name">Installation of Additional Services</span></a><ol><li><a href="cha-ceph-as-intro.html" class=" "><span class="title-number">8 </span><span class="title-name">Installation of Services to Access your Data</span></a></li><li><a href="cha-ceph-additional-software-installation.html" class=" "><span class="title-number">9 </span><span class="title-name">Ceph Object Gateway</span></a></li><li><a href="cha-ceph-as-iscsi.html" class=" you-are-here"><span class="title-number">10 </span><span class="title-name">Installation of iSCSI Gateway</span></a></li><li><a href="cha-ceph-as-cephfs.html" class=" "><span class="title-number">11 </span><span class="title-name">Installation of CephFS</span></a></li><li><a href="cha-as-ganesha.html" class=" "><span class="title-number">12 </span><span class="title-name">Installation of NFS Ganesha</span></a></li></ol></li><li><a href="containerized-ses-on-caasp.html" class="has-children "><span class="title-number">IV </span><span class="title-name">Cluster Deployment on Top of SUSE CaaS Platform 4 (Technology Preview)</span></a><ol><li><a href="cha-container-kubernetes.html" class=" "><span class="title-number">13 </span><span class="title-name">SUSE Enterprise Storage 6 on Top of SUSE CaaS Platform 4 Kubernetes Cluster</span></a></li></ol></li><li><a href="bk02apa.html" class=" "><span class="title-number">A </span><span class="title-name">Ceph Maintenance Updates Based on Upstream 'Nautilus' Point Releases</span></a></li><li><a href="bk02go01.html" class=" "><span class="title-number"> </span><span class="title-name">Glossary</span></a></li><li><a href="ap-deploy-docupdate.html" class=" "><span class="title-number">B </span><span class="title-name">Documentation Updates</span></a></li> </ol> </nav><button id="_open-side-toc-overall" title="Contents"> </button><article class="documentation"><button id="_unfold-side-toc-page">On this page</button><section class="chapter" id="cha-ceph-as-iscsi" data-id-title="Installation of iSCSI Gateway"><div class="titlepage"><div><div class="version-info">Applies to  <span class="productname">SUSE Enterprise Storage</span> <span class="productnumber">6</span></div><div><h2 class="title"><span class="title-number">10 </span><span class="title-name">Installation of iSCSI Gateway</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#">#</a></h2></div></div></div><p>
  iSCSI is a storage area network (SAN) protocol that allows clients (called
  <span class="emphasis"><em>initiators</em></span>) to send SCSI commands to SCSI storage
  devices (<span class="emphasis"><em>targets</em></span>) on remote servers. SUSE Enterprise Storage
  6 includes a facility that opens Ceph storage management to
  heterogeneous clients, such as Microsoft Windows* and VMware* vSphere, through the
  iSCSI protocol. Multipath iSCSI access enables availability and scalability
  for these clients, and the standardized iSCSI protocol also provides an
  additional layer of security isolation between clients and the SUSE Enterprise Storage
  6 cluster. The configuration facility is named <code class="systemitem">ceph-iscsi</code>. Using
  <code class="systemitem">ceph-iscsi</code>, Ceph storage administrators can define thin-provisioned,
  replicated, highly-available volumes supporting read-only snapshots,
  read-write clones, and automatic resizing with Ceph RADOS Block Device
  (RBD). Administrators can then export volumes either via a single <code class="systemitem">ceph-iscsi</code>
  gateway host, or via multiple gateway hosts supporting multipath failover.
  Linux, Microsoft Windows, and VMware hosts can connect to volumes using the iSCSI
  protocol, which makes them available like any other SCSI block device. This
  means SUSE Enterprise Storage 6 customers can effectively run a complete
  block-storage infrastructure subsystem on Ceph that provides all the
  features and benefits of a conventional SAN, enabling future growth.
 </p><p>
  This chapter introduces detailed information to set up a Ceph cluster
  infrastructure together with an iSCSI gateway so that the client hosts can
  use remotely stored data as local storage devices using the iSCSI protocol.
 </p><section class="sect1" id="ceph-iscsi-iscsi" data-id-title="iSCSI Block Storage"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">10.1 </span><span class="title-name">iSCSI Block Storage</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#ceph-iscsi-iscsi">#</a></h2></div></div></div><p>
   iSCSI is an implementation of the Small Computer System Interface (SCSI)
   command set using the Internet Protocol (IP), specified in RFC 3720. iSCSI
   is implemented as a service where a client (the initiator) talks to a server
   (the target) via a session on TCP port 3260. An iSCSI target's IP address
   and port are called an iSCSI portal, where a target can be exposed through
   one or more portals. The combination of a target and one or more portals is
   called the target portal group (TPG).
  </p><p>
   The underlying data link layer protocol for iSCSI is commonly Ethernet. More
   specifically, modern iSCSI infrastructures use 10 Gigabit Ethernet or faster
   networks for optimal throughput. 10 Gigabit Ethernet connectivity between
   the iSCSI gateway and the back-end Ceph cluster is strongly recommended.
  </p><section class="sect2" id="ceph-iscsi-iscsi-target" data-id-title="The Linux Kernel iSCSI Target"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">10.1.1 </span><span class="title-name">The Linux Kernel iSCSI Target</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#ceph-iscsi-iscsi-target">#</a></h3></div></div></div><p>
    The Linux kernel iSCSI target was originally named LIO for linux-iscsi.org,
    the project's original domain and Web site. For some time, no fewer than
    four competing iSCSI target implementations were available for the Linux
    platform, but LIO ultimately prevailed as the single iSCSI reference
    target. The mainline kernel code for LIO uses the simple, but somewhat
    ambiguous name "target", distinguishing between "target core" and a variety
    of front-end and back-end target modules.
   </p><p>
    The most commonly used front-end module is arguably iSCSI. However, LIO
    also supports Fibre Channel (FC), Fibre Channel over Ethernet (FCoE) and
    several other front-end protocols. At this time, only the iSCSI protocol is
    supported by SUSE Enterprise Storage.
   </p><p>
    The most frequently used target back-end module is one that is capable of
    simply re-exporting any available block device on the target host. This
    module is named iblock. However, LIO also has an RBD-specific back-end
    module supporting parallelized multipath I/O access to RBD images.
   </p></section><section class="sect2" id="ceph-iscsi-iscsi-initiators" data-id-title="iSCSI Initiators"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">10.1.2 </span><span class="title-name">iSCSI Initiators</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#ceph-iscsi-iscsi-initiators">#</a></h3></div></div></div><p>
    This section introduces brief information on iSCSI initiators used on
    Linux, Microsoft Windows, and VMware platforms.
   </p><section class="sect3" id="id-1.4.5.4.5.5.3" data-id-title="Linux"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">10.1.2.1 </span><span class="title-name">Linux</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#id-1.4.5.4.5.5.3">#</a></h4></div></div></div><p>
     The standard initiator for the Linux platform is
     <code class="systemitem">open-iscsi</code>. <code class="systemitem">open-iscsi</code>
     launches a daemon, <code class="systemitem">iscsid</code>, which the user can
     then use to discover iSCSI targets on any given portal, log in to targets,
     and map iSCSI volumes. <code class="systemitem">iscsid</code> communicates with
     the SCSI mid layer to create in-kernel block devices that the kernel can
     then treat like any other SCSI block device on the system. The
     <code class="systemitem">open-iscsi</code> initiator can be deployed in
     conjunction with the Device Mapper Multipath
     (<code class="systemitem">dm-multipath</code>) facility to provide a highly
     available iSCSI block device.
    </p></section><section class="sect3" id="id-1.4.5.4.5.5.4" data-id-title="Microsoft Windows and Hyper-V"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">10.1.2.2 </span><span class="title-name">Microsoft Windows and Hyper-V</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#id-1.4.5.4.5.5.4">#</a></h4></div></div></div><p>
     The default iSCSI initiator for the Microsoft Windows operating system is the
     Microsoft iSCSI initiator. The iSCSI service can be configured via a
     graphical user interface (GUI), and supports multipath I/O for high
     availability.
    </p></section><section class="sect3" id="id-1.4.5.4.5.5.5" data-id-title="VMware"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">10.1.2.3 </span><span class="title-name">VMware</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#id-1.4.5.4.5.5.5">#</a></h4></div></div></div><p>
     The default iSCSI initiator for VMware vSphere and ESX is the VMware
     ESX software iSCSI initiator, <code class="systemitem">vmkiscsi</code>. When
     enabled, it can be configured either from the vSphere client, or using the
     <code class="command">vmkiscsi-tool</code> command. You can then format storage
     volumes connected through the vSphere iSCSI storage adapter with VMFS, and
     use them like any other VM storage device. The VMware initiator also
     supports multipath I/O for high availability.
    </p></section></section></section><section class="sect1" id="ceph-iscsi-lrbd" data-id-title="General Information about ceph-iscsi"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">10.2 </span><span class="title-name">General Information about <code class="systemitem">ceph-iscsi</code></span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#ceph-iscsi-lrbd">#</a></h2></div></div></div><p>
   <code class="systemitem">ceph-iscsi</code> combines the benefits of RADOS Block Devices with the ubiquitous
   versatility of iSCSI. By employing <code class="systemitem">ceph-iscsi</code> on an iSCSI target host (known
   as the iSCSI Gateway), any application that needs to make use of block storage can
   benefit from Ceph, even if it does not speak any Ceph client protocol.
   Instead, users can use iSCSI or any other target front-end protocol to
   connect to an LIO target, which translates all target I/O to RBD storage
   operations.
  </p><div class="figure" id="id-1.4.5.4.6.3"><div class="figure-contents"><div class="mediaobject"><a href="images/lrbd_scheme1.png" target="_blank"><img src="images/lrbd_scheme1.png" width="" alt="Ceph Cluster with a Single iSCSI Gateway"/></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="title-number">Figure 10.1: </span><span class="title-name">Ceph Cluster with a Single iSCSI Gateway </span><a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#id-1.4.5.4.6.3">#</a></h6></div></div><p>
   <code class="systemitem">ceph-iscsi</code> is inherently highly-available and supports multipath operations.
   Thus, downstream initiator hosts can use multiple iSCSI gateways for both
   high availability and scalability. When communicating with an iSCSI
   configuration with more than one gateway, initiators may load-balance iSCSI
   requests across multiple gateways. In the event of a gateway failing, being
   temporarily unreachable, or being disabled for maintenance, I/O will
   transparently continue via another gateway.
  </p><div class="figure" id="id-1.4.5.4.6.5"><div class="figure-contents"><div class="mediaobject"><a href="images/lrbd_scheme2.png" target="_blank"><img src="images/lrbd_scheme2.png" width="" alt="Ceph Cluster with Multiple iSCSI Gateways"/></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="title-number">Figure 10.2: </span><span class="title-name">Ceph Cluster with Multiple iSCSI Gateways </span><a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#id-1.4.5.4.6.5">#</a></h6></div></div></section><section class="sect1" id="ceph-iscsi-deploy" data-id-title="Deployment Considerations"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">10.3 </span><span class="title-name">Deployment Considerations</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#ceph-iscsi-deploy">#</a></h2></div></div></div><p>
   A minimum configuration of SUSE Enterprise Storage 6 with <code class="systemitem">ceph-iscsi</code>
   consists of the following components:
  </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
     A Ceph storage cluster. The Ceph cluster consists of a minimum of four
     physical servers hosting at least eight object storage daemons (OSDs)
     each. In such a configuration, three OSD nodes also double as a monitor
     (MON) host.
    </p></li><li class="listitem"><p>
     An iSCSI target server running the LIO iSCSI target, configured via
     <code class="systemitem">ceph-iscsi</code>.
    </p></li><li class="listitem"><p>
     An iSCSI initiator host, running <code class="systemitem">open-iscsi</code>
     (Linux), the Microsoft iSCSI Initiator (Microsoft Windows), or any other compatible
     iSCSI initiator implementation.
    </p></li></ul></div><p>
   A recommended production configuration of SUSE Enterprise Storage 6 with
   <code class="systemitem">ceph-iscsi</code> consists of:
  </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
     A Ceph storage cluster. A production Ceph cluster consists of any
     number of (typically more than 10) OSD nodes, each typically running 10-12
     object storage daemons (OSDs), with no fewer than three dedicated MON
     hosts.
    </p></li><li class="listitem"><p>
     Several iSCSI target servers running the LIO iSCSI target, configured via
     <code class="systemitem">ceph-iscsi</code>. For iSCSI fail-over and load-balancing, these servers must run
     a kernel supporting the <code class="systemitem">target_core_rbd</code> module.
     Update packages are available from the SUSE Linux Enterprise Server maintenance channel.
    </p></li><li class="listitem"><p>
     Any number of iSCSI initiator hosts, running
     <code class="systemitem">open-iscsi</code> (Linux), the Microsoft iSCSI Initiator
     (Microsoft Windows), or any other compatible iSCSI initiator implementation.
    </p></li></ul></div></section><section class="sect1" id="ceph-iscsi-install" data-id-title="Installation and Configuration"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">10.4 </span><span class="title-name">Installation and Configuration</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#ceph-iscsi-install">#</a></h2></div></div></div><p>
   This section describes steps to install and configure an iSCSI Gateway on top of
   SUSE Enterprise Storage.
  </p><section class="sect2" id="id-1.4.5.4.8.3" data-id-title="Deploy the iSCSI Gateway to a Ceph Cluster"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">10.4.1 </span><span class="title-name">Deploy the iSCSI Gateway to a Ceph Cluster</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#id-1.4.5.4.8.3">#</a></h3></div></div></div><p>
    You can deploy the iSCSI Gateway either during the Ceph cluster deployment
    process, or add it to an existing cluster using DeepSea.
   </p><p>
    To include the iSCSI Gateway during the cluster deployment process, refer to
    <a class="xref" href="ceph-install-saltstack.html#policy-role-assignment" title="5.5.1.2. Role Assignment">Section 5.5.1.2, “Role Assignment”</a>.
   </p><p>
    To add the iSCSI Gateway to an existing cluster, refer to
    <span class="intraxref">Book “Administration Guide”, Chapter 2 “Salt Cluster Administration”, Section 2.2 “Adding New Roles to Nodes”</span>.
   </p></section><section class="sect2" id="id-1.4.5.4.8.4" data-id-title="Create RBD Images"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">10.4.2 </span><span class="title-name">Create RBD Images</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#id-1.4.5.4.8.4">#</a></h3></div></div></div><p>
    RBD images are created in the Ceph store and subsequently exported to
    iSCSI. We recommend that you use a dedicated RADOS pool for this purpose.
    You can create a volume from any host that is able to connect to your
    storage cluster using the Ceph <code class="command">rbd</code> command line
    utility. This requires the client to have at least a minimal ceph.conf
    configuration file, and appropriate CephX authentication credentials.
   </p><p>
    To create a new volume for subsequent export via iSCSI, use the
    <code class="command">rbd create</code> command, specifying the volume size in
    megabytes. For example, in order to create a 100 GB volume named 'testvol'
    in the pool named 'iscsi-images', run:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm@adm &gt; </code>rbd --pool iscsi-images create --size=102400 'testvol'</pre></div></section><section class="sect2" id="ceph-iscsi-rbd-export" data-id-title="Export RBD Images via iSCSI"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">10.4.3 </span><span class="title-name">Export RBD Images via iSCSI</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#ceph-iscsi-rbd-export">#</a></h3></div></div></div><p>
    To export RBD images via iSCSI, you can use either Ceph Dashboard Web
    interface or the <code class="systemitem">ceph-iscsi</code> gwcli utility. In this section we will focus
    on gwcli only, demonstrating how to create an iSCSI target that exports
    an RBD image using the command line.
   </p><div id="id-1.4.5.4.8.5.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><h6>Note</h6><p>
     Only the following RBD image features are supported:
     <code class="option">layering</code>, <code class="option">striping (v2)</code>,
     <code class="option">exclusive-lock</code>, <code class="option">fast-diff</code>, and
     <code class="option">data-pool</code>. RBD images with any other feature enabled
     cannot be exported.
    </p></div><p>
    As <code class="systemitem">root</code>, start the iSCSI gateway command line interface:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">root # </code>gwcli</pre></div><p>
    Go to <code class="literal">iscsi-targets</code> and create a target with the name
    <code class="literal">iqn.2003-01.org.linux-iscsi.iscsi.<em class="replaceable">SYSTEM-ARCH</em>:testvol</code>:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">gwcli &gt; </code> /&gt; cd /iscsi-targets
<code class="prompt user">gwcli &gt; </code> /iscsi-targets&gt; create iqn.2003-01.org.linux-iscsi.iscsi.<em class="replaceable">SYSTEM-ARCH</em>:testvol</pre></div><p>
    Create the iSCSI gateways by specifying the gateway <code class="literal">name</code>
    and <code class="literal">ip</code> address:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">gwcli &gt; </code> /iscsi-targets&gt; cd iqn.2003-01.org.linux-iscsi.iscsi.<em class="replaceable">SYSTEM-ARCH</em>:testvol/gateways
<code class="prompt user">gwcli &gt; </code> /iscsi-target...tvol/gateways&gt; create iscsi1 192.168.124.104
<code class="prompt user">gwcli &gt; </code> /iscsi-target...tvol/gateways&gt; create iscsi2 192.168.124.105</pre></div><div id="id-1.4.5.4.8.5.10" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg"/><h6>Tip</h6><p>
     Use the <code class="literal">help</code> command to show the list of available
     commands in the current configuration node.
    </p></div><p>
    Add the RBD image with the name 'testvol' in the pool 'iscsi-images':
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">gwcli &gt; </code> /iscsi-target...tvol/gateways&gt; cd /disks
<code class="prompt user">gwcli &gt; </code> /disks&gt; attach iscsi-images/testvol</pre></div><p>
    Map the RBD image to the target:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">gwcli &gt; </code> /disks&gt; cd /iscsi-targets/iqn.2003-01.org.linux-iscsi.iscsi.<em class="replaceable">SYSTEM-ARCH</em>:testvol/disks
<code class="prompt user">gwcli &gt; </code> /iscsi-target...testvol/disks&gt; add iscsi-images/testvol</pre></div><div id="id-1.4.5.4.8.5.15" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><h6>Note</h6><p>
     You can use lower level tools, such as <code class="command">targetcli</code>, to
     query the local configuration, but not to modify it.
    </p></div><div id="id-1.4.5.4.8.5.16" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg"/><h6>Tip</h6><p>
     You can use the <code class="command">ls</code> command to review the configuration.
     Some configuration nodes also support the <code class="command">info</code> command,
     which can be used to display more detailed information.
    </p></div><p>
    Note that, by default, ACL authentication is enabled so this target is not
    accessible yet. Check <a class="xref" href="cha-ceph-as-iscsi.html#iscsi-lrbd-autentication" title="10.4.4. Authentication and Access Control">Section 10.4.4, “Authentication and Access Control”</a> for more
    information about authentication and access control.
   </p></section><section class="sect2" id="iscsi-lrbd-autentication" data-id-title="Authentication and Access Control"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">10.4.4 </span><span class="title-name">Authentication and Access Control</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#iscsi-lrbd-autentication">#</a></h3></div></div></div><p>
    iSCSI authentication is flexible and covers many authentication
    possibilities.
   </p><section class="sect3" id="id-1.4.5.4.8.6.3" data-id-title="No Authentication"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">10.4.4.1 </span><span class="title-name">No Authentication</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#id-1.4.5.4.8.6.3">#</a></h4></div></div></div><p>
     'No authentication' means that any initiator will be able to access any
     LUNs on the corresponding target. You can enable 'No authentication' by
     disabling the ACL authentication:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">gwcli &gt; </code> /&gt; cd /iscsi-targets/iqn.2003-01.org.linux-iscsi.iscsi.<em class="replaceable">SYSTEM-ARCH</em>:testvol/hosts
<code class="prompt user">gwcli &gt; </code> /iscsi-target...testvol/hosts&gt; auth disable_acl</pre></div></section><section class="sect3" id="id-1.4.5.4.8.6.4" data-id-title="ACL Authentication"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">10.4.4.2 </span><span class="title-name">ACL Authentication</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#id-1.4.5.4.8.6.4">#</a></h4></div></div></div><p>
     When using initiator name based ACL authentication, only the defined
     initiators are allowed to connect. You can define an initiator by doing:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">gwcli &gt; </code> /&gt; cd /iscsi-targets/iqn.2003-01.org.linux-iscsi.iscsi.<em class="replaceable">SYSTEM-ARCH</em>:testvol/hosts
<code class="prompt user">gwcli &gt; </code> /iscsi-target...testvol/hosts&gt; create iqn.1996-04.de.suse:01:e6ca28cc9f20</pre></div><p>
     Defined initiators will be able to connect, but will only have access to
     the RBD images that were explicitly added to the initiator:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">gwcli &gt; </code> /iscsi-target...:e6ca28cc9f20&gt; disk add rbd/testvol</pre></div></section><section class="sect3" id="chap-auth-password" data-id-title="CHAP Authentication"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">10.4.4.3 </span><span class="title-name">CHAP Authentication</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#chap-auth-password">#</a></h4></div></div></div><p>
     In addition to the ACL, you can enable the CHAP authentication by
     specifying a user name and password for each initiator:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">gwcli &gt; </code> /&gt; cd /iscsi-targets/iqn.2003-01.org.linux-iscsi.iscsi.<em class="replaceable">SYSTEM-ARCH</em>:testvol/hosts/iqn.1996-04.de.suse:01:e6ca28cc9f20
<code class="prompt user">gwcli &gt; </code> /iscsi-target...:e6ca28cc9f20&gt; auth username=common12 password=pass12345678</pre></div><div id="id-1.4.5.4.8.6.5.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><h6>Note</h6><p>
      User names must have a length of 8 to 64 characters and can contain
      alphanumeric characters, '.', '@', '-', '_' or ':'.
     </p><p>
      Passwords must have a length of 12 to 16 characters and can contain
      alphanumeric characters, '@', '-', '_' or '/'.
     </p></div><p>
     Optionally, you can also enable the CHAP mutual authentication by
     specifying the <code class="option">mutual_username</code> and
     <code class="option">mutual_password</code> parameters in the <code class="command">auth</code>
     command.
    </p></section><section class="sect3" id="id-1.4.5.4.8.6.6" data-id-title="Discovery and Mutual Authentication"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">10.4.4.4 </span><span class="title-name">Discovery and Mutual Authentication</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#id-1.4.5.4.8.6.6">#</a></h4></div></div></div><p>
     <span class="emphasis"><em>Discovery authentication</em></span> is independent of the
     previous authentication methods. It requires credentials for browsing, it
     is optional, and can be configured by:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">gwcli &gt; </code> /&gt; cd /iscsi-targets
<code class="prompt user">gwcli &gt; </code> /iscsi-targets&gt; discovery_auth username=du123456 password=dp1234567890</pre></div><div id="id-1.4.5.4.8.6.6.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><h6>Note</h6><p>
      User-names must have a length of 8 to 64 characters and can only contain
      letters, '.', '@', '-', '_' or ':'.
     </p><p>
      Passwords must have a length of 12 to 16 characters and can only contain
      letters, '@', '-', '_' or '/'.
     </p></div><p>
     Optionally, you can also specify the <code class="option">mutual_username</code> and
     <code class="option">mutual_password</code> parameters in the
     <code class="command">discovery_auth</code> command.
    </p><p>
     Discovery authentication can be disabled by using the following command:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">gwcli &gt; </code> /iscsi-targets&gt; discovery_auth nochap</pre></div></section></section><section class="sect2" id="ceph-iscsi-rbd-advanced" data-id-title="Advanced Settings"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">10.4.5 </span><span class="title-name">Advanced Settings</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#ceph-iscsi-rbd-advanced">#</a></h3></div></div></div><p>
    <code class="systemitem">ceph-iscsi</code> can be configured with advanced parameters which are subsequently
    passed on to the LIO I/O target. The parameters are divided up into
    'target' and 'disk' parameters.
   </p><div id="id-1.4.5.4.8.7.3" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.svg"/><h6>Warning</h6><p>
     Unless otherwise noted, changing these parameters from the default setting
     is not recommended.
    </p></div><section class="sect3" id="id-1.4.5.4.8.7.4" data-id-title="Target Settings"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">10.4.5.1 </span><span class="title-name">Target Settings</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#id-1.4.5.4.8.7.4">#</a></h4></div></div></div><p>
     You can view the value of these settings by using the
     <code class="command">info</code> command:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">gwcli &gt; </code> /&gt; cd /iscsi-targets/iqn.2003-01.org.linux-iscsi.iscsi.<em class="replaceable">SYSTEM-ARCH</em>:testvol
<code class="prompt user">gwcli &gt; </code> /iscsi-target...i.<em class="replaceable">SYSTEM-ARCH</em>:testvol&gt; info</pre></div><p>
     And change a setting using the <code class="command">reconfigure</code> command:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">gwcli &gt; </code> /iscsi-target...i.<em class="replaceable">SYSTEM-ARCH</em>:testvol&gt; reconfigure login_timeout 20</pre></div><p>
     The available 'target' settings are:
    </p><div class="variablelist"><dl class="variablelist"><dt id="id-1.4.5.4.8.7.4.7.1"><span class="term">default_cmdsn_depth</span></dt><dd><p>
        Default CmdSN (Command Sequence Number) depth. Limits the amount of
        requests that an iSCSI initiator can have outstanding at any moment.
       </p></dd><dt id="id-1.4.5.4.8.7.4.7.2"><span class="term">default_erl</span></dt><dd><p>
        Default error recovery level.
       </p></dd><dt id="id-1.4.5.4.8.7.4.7.3"><span class="term">login_timeout</span></dt><dd><p>
        Login timeout value in seconds.
       </p></dd><dt id="id-1.4.5.4.8.7.4.7.4"><span class="term">netif_timeout</span></dt><dd><p>
        NIC failure timeout in seconds.
       </p></dd><dt id="id-1.4.5.4.8.7.4.7.5"><span class="term">prod_mode_write_protect</span></dt><dd><p>
        If set to 1, prevents writes to LUNs.
       </p></dd></dl></div></section><section class="sect3" id="id-1.4.5.4.8.7.5" data-id-title="Disk Settings"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">10.4.5.2 </span><span class="title-name">Disk Settings</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#id-1.4.5.4.8.7.5">#</a></h4></div></div></div><p>
     You can view the value of these settings by using the
     <code class="command">info</code> command:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">gwcli &gt; </code> /&gt; cd /disks/rbd/testvol
<code class="prompt user">gwcli &gt; </code> /disks/rbd/testvol&gt; info</pre></div><p>
     And change a setting using the <code class="command">reconfigure</code> command:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">gwcli &gt; </code> /disks/rbd/testvol&gt; reconfigure rbd/testvol emulate_pr 0</pre></div><p>
     The available 'disk' settings are:
    </p><div class="variablelist"><dl class="variablelist"><dt id="id-1.4.5.4.8.7.5.7.1"><span class="term">block_size</span></dt><dd><p>
        Block size of the underlying device.
       </p></dd><dt id="id-1.4.5.4.8.7.5.7.2"><span class="term">emulate_3pc</span></dt><dd><p>
        If set to 1, enables Third Party Copy.
       </p></dd><dt id="id-1.4.5.4.8.7.5.7.3"><span class="term">emulate_caw</span></dt><dd><p>
        If set to 1, enables Compare and Write.
       </p></dd><dt id="id-1.4.5.4.8.7.5.7.4"><span class="term">emulate_dpo</span></dt><dd><p>
        If set to 1, turns on Disable Page Out.
       </p></dd><dt id="id-1.4.5.4.8.7.5.7.5"><span class="term">emulate_fua_read</span></dt><dd><p>
        If set to 1, enables Force Unit Access read.
       </p></dd><dt id="id-1.4.5.4.8.7.5.7.6"><span class="term">emulate_fua_write</span></dt><dd><p>
        If set to 1, enables Force Unit Access write.
       </p></dd><dt id="id-1.4.5.4.8.7.5.7.7"><span class="term">emulate_model_alias</span></dt><dd><p>
        If set to 1, uses the back-end device name for the model alias.
       </p></dd><dt id="id-1.4.5.4.8.7.5.7.8"><span class="term">emulate_pr</span></dt><dd><p>
        If set to 0, support for SCSI Reservations, including Persistent Group
        Reservations, is disabled. While disabled, the SES iSCSI Gateway can
        ignore reservation state, resulting in improved request latency.
       </p><div id="id-1.4.5.4.8.7.5.7.8.2.2" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg"/><h6>Tip</h6><p>
         Setting backstore_emulate_pr to 0 is recommended if iSCSI initiators
         do not require SCSI Reservation support.
        </p></div></dd><dt id="id-1.4.5.4.8.7.5.7.9"><span class="term">emulate_rest_reord</span></dt><dd><p>
        If set to 0, the Queue Algorithm Modifier has Restricted Reordering.
       </p></dd><dt id="id-1.4.5.4.8.7.5.7.10"><span class="term">emulate_tas</span></dt><dd><p>
        If set to 1, enables Task Aborted Status.
       </p></dd><dt id="id-1.4.5.4.8.7.5.7.11"><span class="term">emulate_tpu</span></dt><dd><p>
        If set to 1, enables Thin Provisioning Unmap.
       </p></dd><dt id="id-1.4.5.4.8.7.5.7.12"><span class="term">emulate_tpws</span></dt><dd><p>
        If set to 1, enables Thin Provisioning Write Same.
       </p></dd><dt id="id-1.4.5.4.8.7.5.7.13"><span class="term">emulate_ua_intlck_ctrl</span></dt><dd><p>
        If set to 1, enables Unit Attention Interlock.
       </p></dd><dt id="id-1.4.5.4.8.7.5.7.14"><span class="term">emulate_write_cache</span></dt><dd><p>
        If set to 1, turns on Write Cache Enable.
       </p></dd><dt id="id-1.4.5.4.8.7.5.7.15"><span class="term">enforce_pr_isids</span></dt><dd><p>
        If set to 1, enforces persistent reservation ISIDs.
       </p></dd><dt id="id-1.4.5.4.8.7.5.7.16"><span class="term">is_nonrot</span></dt><dd><p>
        If set to 1, the backstore is a non-rotational device.
       </p></dd><dt id="id-1.4.5.4.8.7.5.7.17"><span class="term">max_unmap_block_desc_count</span></dt><dd><p>
        Maximum number of block descriptors for UNMAP.
       </p></dd><dt id="id-1.4.5.4.8.7.5.7.18"><span class="term">max_unmap_lba_count:</span></dt><dd><p>
        Maximum number of LBAs for UNMAP.
       </p></dd><dt id="id-1.4.5.4.8.7.5.7.19"><span class="term">max_write_same_len</span></dt><dd><p>
        Maximum length for WRITE_SAME.
       </p></dd><dt id="id-1.4.5.4.8.7.5.7.20"><span class="term">optimal_sectors</span></dt><dd><p>
        Optimal request size in sectors.
       </p></dd><dt id="id-1.4.5.4.8.7.5.7.21"><span class="term">pi_prot_type</span></dt><dd><p>
        DIF protection type.
       </p></dd><dt id="id-1.4.5.4.8.7.5.7.22"><span class="term">queue_depth</span></dt><dd><p>
        Queue depth.
       </p></dd><dt id="id-1.4.5.4.8.7.5.7.23"><span class="term">unmap_granularity</span></dt><dd><p>
        UNMAP granularity.
       </p></dd><dt id="id-1.4.5.4.8.7.5.7.24"><span class="term">unmap_granularity_alignment</span></dt><dd><p>
        UNMAP granularity alignment.
       </p></dd><dt id="id-1.4.5.4.8.7.5.7.25"><span class="term">force_pr_aptpl</span></dt><dd><p>
        When enabled, LIO will always write out the <span class="emphasis"><em>persistent
        reservation</em></span> state to persistent storage, regardless of
        whether or not the client has requested it via
        <code class="option">aptpl=1</code>. This has no effect with the kernel RBD
        back-end for LIO—it always persists PR state. Ideally, the
        <code class="option">target_core_rbd</code> option should force it to '1' and
        throw an error if someone tries to disable it via configfs.
       </p></dd><dt id="id-1.4.5.4.8.7.5.7.26"><span class="term">unmap_zeroes_data</span></dt><dd><p>
        Affects whether LIO will advertise LBPRZ to SCSI initiators, indicating
        that zeros will be read back from a region following UNMAP or WRITE
        SAME with an unmap bit.
       </p></dd></dl></div></section></section></section><section class="sect1" id="iscsi-tcmu" data-id-title="Exporting RADOS Block Device Images Using tcmu-runner"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">10.5 </span><span class="title-name">Exporting RADOS Block Device Images Using <code class="systemitem">tcmu-runner</code></span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#iscsi-tcmu">#</a></h2></div></div></div><p>
   The <code class="systemitem">ceph-iscsi</code> supports both <code class="option">rbd</code> (kernel-based) and
   <code class="option">user:rbd</code> (tcmu-runner) backstores, making all the
   management transparent and independent of the backstore.
  </p><div id="id-1.4.5.4.9.3" data-id-title="Technology Preview" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.svg"/><h6>Warning: Technology Preview</h6><p>
    <code class="systemitem">tcmu-runner</code> based iSCSI Gateway deployments are currently
    a technology preview.
   </p></div><p>
   Unlike kernel-based iSCSI Gateway deployments, <code class="systemitem">tcmu-runner</code>
   based iSCSI Gateways do not offer support for multipath I/O or SCSI Persistent
   Reservations.
  </p><p>
   To export an RADOS Block Device image using <code class="systemitem">tcmu-runner</code>, all you
   need to do is specify the <code class="option">user:rbd</code> backstore when attaching
   the disk:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">gwcli &gt; </code> /disks&gt; attach rbd/testvol backstore=user:rbd</pre></div><div id="id-1.4.5.4.9.7" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><h6>Note</h6><p>
    When using <code class="systemitem">tcmu-runner</code>, the exported RBD image
    must have the <code class="option">exclusive-lock</code> feature enabled.
   </p></div></section></section><nav class="bottom-pagination"><div><a class="pagination-link prev" href="cha-ceph-additional-software-installation.html"><span class="pagination-relation">Previous</span><span class="pagination-label"><span class="title-number">Chapter 9 </span>Ceph Object Gateway</span></a> </div><div><a class="pagination-link next" href="cha-ceph-as-cephfs.html"><span class="pagination-relation">Next</span><span class="pagination-label"><span class="title-number">Chapter 11 </span>Installation of CephFS</span></a> </div></nav></article><aside id="_side-toc-page" class="side-toc"><div class="side-title">On this page</div><div class="toc"><ul><li><span class="sect1"><a href="cha-ceph-as-iscsi.html#ceph-iscsi-iscsi"><span class="title-number">10.1 </span><span class="title-name">iSCSI Block Storage</span></a></span></li><li><span class="sect1"><a href="cha-ceph-as-iscsi.html#ceph-iscsi-lrbd"><span class="title-number">10.2 </span><span class="title-name">General Information about <code class="systemitem">ceph-iscsi</code></span></a></span></li><li><span class="sect1"><a href="cha-ceph-as-iscsi.html#ceph-iscsi-deploy"><span class="title-number">10.3 </span><span class="title-name">Deployment Considerations</span></a></span></li><li><span class="sect1"><a href="cha-ceph-as-iscsi.html#ceph-iscsi-install"><span class="title-number">10.4 </span><span class="title-name">Installation and Configuration</span></a></span></li><li><span class="sect1"><a href="cha-ceph-as-iscsi.html#iscsi-tcmu"><span class="title-number">10.5 </span><span class="title-name">Exporting RADOS Block Device Images Using <code class="systemitem">tcmu-runner</code></span></a></span></li></ul></div><div class="side-title">Give feedback</div><ul class="feedback" id="_give-feedback"><li><a id="_feedback-reportbug" href="#" rel="nofollow" target="_blank">Report an issue</a></li><li><a id="_feedback-editurl" href="https://github.com/SUSE/doc-ses/edit/maintenance/ses6/xml/deployment_iscsi.xml" rel="nofollow" target="_blank">Edit source document</a></li></ul><div class="side-title">Share this page</div><ul class="share"><li><a id="_share-fb" href="#" title="Facebook"> </a></li><li><a id="_share-in" href="#" title="LinkedIn"> </a></li><li><a id="_share-tw" href="#" title="Twitter"> </a></li><li><a id="_share-mail" href="#" title="E-Mail"> </a></li><li><a id="_print-button" href="#" title="Print this page"> </a></li></ul> </aside></main><footer id="_footer"><div class="growth-inhibitor"><div class="copy"><span class="copy__rights">© SUSE
                 2022</span></div></div></footer></body></html>