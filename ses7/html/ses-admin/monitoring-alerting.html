<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes"/><title>SES 7 | Administration and Operations Guide | Monitoring and alerting</title><link rel="stylesheet" type="text/css" href="static/css/style.css"/>
<meta name="title" content="Monitoring and alerting | SES 7"/>
<meta name="description" content="In SUSE Enterprise Storage 7, cephadm deploys a monitoring and alerting stack. Users need to either define the services (such as Prometheus, Alertman…"/>
<meta name="product-name" content="SUSE Enterprise Storage"/>
<meta name="product-number" content="7"/>
<meta name="book-title" content="Administration and Operations Guide"/>
<meta name="chapter-title" content="Chapter 16. Monitoring and alerting"/>
<meta name="tracker-url" content="https://github.com/SUSE/doc-ses/issues/new"/>
<meta name="tracker-type" content="gh"/>
<meta name="tracker-gh-assignee" content="tbazant"/>
<meta name="tracker-gh-template" content="&#10;     ### Type of report&#10;   - [ ] bug&#10;   - [ ] feature request&#10;&#10;### Source Document&#10;@@source@@&#10;&#10;### Summary&#10;&lt;!-- A clear and concise description of what the bug/feature request is. --&gt;&#10;&#10;### Steps To Reproduce&#10;&lt;!-- Steps to reproduce the behavior if you ran through steps in the document. --&gt;&#10;&#10;### Expected Results&#10;&lt;!-- A clear and concise description of what you expected to happen. --&gt;&#10;&#10;### Actual Results&#10;&lt;!-- Explain what actually happened if steps were executed, and if applicable, add screenshots to help explain your problem. --&gt;&#10;&#10;### Notes&#10;&lt;!-- Add any other context about the problem here. --&gt;&#10;&#10;    "/>
<meta name="tracker-gh-labels" content="bug,question,feature request"/>
<meta property="og:title" content="Monitoring and alerting | SES 7"/>
<meta property="og:description" content="In SUSE Enterprise Storage 7, cephadm deploys a monitoring and alerting stack. Users need to either define the services (such as Prometheus, Alertman…"/>
<meta property="og:type" content="article"/>
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Monitoring and alerting | SES 7"/>
<meta name="twitter:description" content="In SUSE Enterprise Storage 7, cephadm deploys a monitoring and alerting stack. Users need to either define the services (such as Prometheus, Alertman…"/>
<link rel="prev" href="cha-deployment-backup.html" title="Chapter 15. Backup and restore"/><link rel="next" href="part-storing-data.html" title="Part III. Storing Data in a Cluster"/>
<script type="text/javascript">

if ( window.location.protocol.toLowerCase() != 'file:' ) {
  document.write('<link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css"></link>');
};

</script><noscript><link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css"/></noscript><script src="static/js/jquery-1.12.4.min.js" type="text/javascript"> </script><script src="static/js/script.js" type="text/javascript"> </script><script src="static/js/highlight.min.js" type="text/javascript"> </script><script>

$(document).ready(function() {
  $('.verbatim-wrap.highlight').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});
hljs.configure({
  useBR: false
});

</script><meta name="edit-url" content="https://github.com/SUSE/doc-ses/edit/main/xml/admin_monitoring_alerting.xml"/></head><body class="draft wide offline js-off" onload="$('#betawarn-button-wrap').toggle();if (document.cookie.length > 0) {if (document.cookie.indexOf('betawarn=closed') != -1){$('#betawarn').toggle()}};"><div id="betawarn" style="position:fixed;bottom:0;z-index:9025;background-color:#FDE8E8;padding:1em;margin-left:10%;margin-right:10%;display:block;border-top:.75em solid #E11;width:80%"><p style="color:#333;margin:1em 0;padding:0;">This is a draft document that was built and uploaded automatically. It may document beta software and be incomplete or even incorrect. <strong>Use this document at your own risk.</strong></p> <div id="betawarn-button-wrap" style="display:none;margin:0;padding:0;"><a href="#" onclick="$('#betawarn').toggle();var d=new Date();d.setTime(d.getTime()+(0.5*24*60*60*1000));document.cookie='betawarn=closed; expires='+d.toUTCString()+'; path=/'; return false;" style="color:#333;text-decoration:underline;float:left;margin-top:.5em;padding:1em;display:block;background-color:#FABEBE;">I understand this is a draft</a></div></div><div class="bypass-block"><a href="#_content">Jump to content</a><a href="#_bottom-pagination">Jump to page navigation: previous page [access key p]/next page [access key n]</a></div><header id="_mainnav"><div class="growth-inhibitor"><img src="static/images/logo.svg" alt="Logo" class="logo"/></div></header><div class="crumbs"><div class="growth-inhibitor"><a class="crumb" href="index.html">Administration and Operations Guide</a><span> / </span><a class="crumb" href="part-cluster-operation.html">Cluster Operation</a><span> / </span><a class="crumb" href="monitoring-alerting.html">Monitoring and alerting</a></div></div><main id="_content"><nav id="_side-toc-overall" class="side-toc"><div class="side-title">Administration and Operations Guide</div><ol><li><a href="preface-admin.html" class=" "><span class="title-number"> </span><span class="title-name">About this guide</span></a></li><li><a href="part-dashboard.html" class="has-children "><span class="title-number">I </span><span class="title-name">Ceph Dashboard</span></a><ol><li><a href="dashboard-about.html" class=" "><span class="title-number">1 </span><span class="title-name">About the Ceph Dashboard</span></a></li><li><a href="dashboard-webui-general.html" class=" "><span class="title-number">2 </span><span class="title-name">Dashboard's Web user interface</span></a></li><li><a href="dashboard-user-mgmt.html" class=" "><span class="title-number">3 </span><span class="title-name">Manage Ceph Dashboard users and roles</span></a></li><li><a href="dashboard-cluster.html" class=" "><span class="title-number">4 </span><span class="title-name">View cluster internals</span></a></li><li><a href="dashboard-pools.html" class=" "><span class="title-number">5 </span><span class="title-name">Manage pools</span></a></li><li><a href="dashboard-rbds.html" class=" "><span class="title-number">6 </span><span class="title-name">Manage RADOS Block Device</span></a></li><li><a href="dash-webui-nfs.html" class=" "><span class="title-number">7 </span><span class="title-name">Manage NFS Ganesha</span></a></li><li><a href="dashboard-mds.html" class=" "><span class="title-number">8 </span><span class="title-name">Manage CephFS</span></a></li><li><a href="dashboard-ogw.html" class=" "><span class="title-number">9 </span><span class="title-name">Manage the Object Gateway</span></a></li><li><a href="dashboard-initial-configuration.html" class=" "><span class="title-number">10 </span><span class="title-name">Manual configuration</span></a></li><li><a href="dashboard-user-roles.html" class=" "><span class="title-number">11 </span><span class="title-name">Manage users and roles on the command line</span></a></li></ol></li><li class="active"><a href="part-cluster-operation.html" class="has-children you-are-here"><span class="title-number">II </span><span class="title-name">Cluster Operation</span></a><ol><li><a href="ceph-monitor.html" class=" "><span class="title-number">12 </span><span class="title-name">Determine the cluster state</span></a></li><li><a href="storage-salt-cluster.html" class=" "><span class="title-number">13 </span><span class="title-name">Operational tasks</span></a></li><li><a href="cha-ceph-operating.html" class=" "><span class="title-number">14 </span><span class="title-name">Operation of Ceph services</span></a></li><li><a href="cha-deployment-backup.html" class=" "><span class="title-number">15 </span><span class="title-name">Backup and restore</span></a></li><li><a href="monitoring-alerting.html" class=" you-are-here"><span class="title-number">16 </span><span class="title-name">Monitoring and alerting</span></a></li></ol></li><li><a href="part-storing-data.html" class="has-children "><span class="title-number">III </span><span class="title-name">Storing Data in a Cluster</span></a><ol><li><a href="cha-storage-datamgm.html" class=" "><span class="title-number">17 </span><span class="title-name">Stored data management</span></a></li><li><a href="ceph-pools.html" class=" "><span class="title-number">18 </span><span class="title-name">Manage storage pools</span></a></li><li><a href="cha-ceph-erasure.html" class=" "><span class="title-number">19 </span><span class="title-name">Erasure coded pools</span></a></li><li><a href="ceph-rbd.html" class=" "><span class="title-number">20 </span><span class="title-name">RADOS Block Device</span></a></li></ol></li><li><a href="part-accessing-data.html" class="has-children "><span class="title-number">IV </span><span class="title-name">Accessing Cluster Data</span></a><ol><li><a href="cha-ceph-gw.html" class=" "><span class="title-number">21 </span><span class="title-name">Ceph Object Gateway</span></a></li><li><a href="cha-ceph-iscsi.html" class=" "><span class="title-number">22 </span><span class="title-name">Ceph iSCSI gateway</span></a></li><li><a href="cha-ceph-cephfs.html" class=" "><span class="title-number">23 </span><span class="title-name">Clustered file system</span></a></li><li><a href="cha-ses-cifs.html" class=" "><span class="title-number">24 </span><span class="title-name">Export Ceph data via Samba</span></a></li><li><a href="cha-ceph-nfsganesha.html" class=" "><span class="title-number">25 </span><span class="title-name">NFS Ganesha</span></a></li></ol></li><li><a href="part-integration-virt.html" class="has-children "><span class="title-number">V </span><span class="title-name">Integration with Virtualization Tools</span></a><ol><li><a href="cha-ceph-libvirt.html" class=" "><span class="title-number">26 </span><span class="title-name"><code class="systemitem">libvirt</code> and Ceph</span></a></li><li><a href="cha-ceph-kvm.html" class=" "><span class="title-number">27 </span><span class="title-name">Ceph as a back-end for QEMU KVM instance</span></a></li></ol></li><li><a href="part-cluster-configuration.html" class="has-children "><span class="title-number">VI </span><span class="title-name">Configuring a Cluster</span></a><ol><li><a href="cha-ceph-configuration.html" class=" "><span class="title-number">28 </span><span class="title-name">Ceph cluster configuration</span></a></li><li><a href="cha-mgr-modules.html" class=" "><span class="title-number">29 </span><span class="title-name">Ceph Manager modules</span></a></li><li><a href="cha-storage-cephx.html" class=" "><span class="title-number">30 </span><span class="title-name">Authentication with <code class="systemitem">cephx</code></span></a></li></ol></li><li><a href="bk02apa.html" class=" "><span class="title-number">A </span><span class="title-name">Ceph maintenance updates based on upstream 'Octopus' point releases</span></a></li><li><a href="bk02go01.html" class=" "><span class="title-number"> </span><span class="title-name">Glossary</span></a></li> </ol> </nav><button id="_open-side-toc-overall" title="Contents"> </button><article class="documentation"><button id="_unfold-side-toc-page">On this page</button><section class="chapter" id="monitoring-alerting" data-id-title="Monitoring and alerting"><div class="titlepage"><div><div class="version-info">Applies to  <span class="productname">SUSE Enterprise Storage</span> <span class="productnumber">7</span></div><div><div class="title-container"><h1 class="title"><span class="title-number-name"><span class="title-number">16 </span><span class="title-name">Monitoring and alerting</span></span> <a title="Permalink" class="permalink" href="monitoring-alerting.html#">#</a></h1><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-ses/edit/main/xml/admin_monitoring_alerting.xml" title="Edit source document"> </a></div></div></div></div></div><p>
  In SUSE Enterprise Storage 7, cephadm deploys a monitoring and alerting
  stack. Users need to either define the services (such as Prometheus,
  Alertmanager, and Grafana) that they want to deploy with cephadm in a
  YAML configuration file, or they can use the CLI to deploy them. When
  multiple services of the same type are deployed, a highly-available setup is
  deployed. The node exporter is an exception to this rule.
 </p><p>
  The following monitoring services can be deployed with cephadm:
 </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
    <span class="bold"><strong>Prometheus</strong></span> is the monitoring and
    alerting toolkit. It collects the data provided by Prometheus exporters and
    fires preconfigured alerts if predefined thresholds have been reached.
   </p></li><li class="listitem"><p>
    <span class="bold"><strong>Alertmanager</strong></span> handles alerts sent by the
    Prometheus server. It deduplicates, groups, and routes the alerts to the
    correct receiver. By default, the Ceph Dashboard will automatically be
    configured as the receiver.
   </p></li><li class="listitem"><p>
    <span class="bold"><strong>Grafana</strong></span> is the visualization and
    alerting software. The alerting functionality of Grafana is not used by
    this monitoring stack. For alerting, the Alertmanager is used.
   </p></li><li class="listitem"><p>
    <span class="bold"><strong>Node exporter</strong></span> is an exporter for
    Prometheus which provides data about the node it is installed on. It is
    recommended to install the node exporter on all nodes.
   </p></li></ul></div><p>
  The Prometheus Manager Module provides a Prometheus exporter to pass on Ceph
  performance counters from the collection point in
  <code class="literal">ceph-mgr</code>.
 </p><p>
  The Prometheus configuration, including <span class="emphasis"><em>scrape</em></span> targets
  (metrics providing daemons), is set up automatically by cephadm. cephadm
  also deploys a list of default alerts, for example <code class="literal">health
  error</code>, <code class="literal">10% OSDs down</code>, or <code class="literal">pgs
  inactive</code>.
 </p><p>
  By default, traffic to Grafana is encrypted with TLS. You can either supply
  your own TLS certificate or use a self-signed one. If no custom certificate
  has been configured before Grafana has been deployed, then a self-signed
  certificate is automatically created and configured for Grafana.
 </p><p>
  You can configure custom certificates for Grafana by following these steps:
 </p><div class="procedure"><div class="procedure-contents"><ol class="procedure" type="1"><li class="step"><p>
    Configure certificate files:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code> ceph config-key set mgr/cephadm/grafana_key -i $PWD/key.pem
<code class="prompt user">cephuser@adm &gt; </code> ceph config-key set mgr/cephadm/grafana_crt -i $PWD/certificate.pem</pre></div></li><li class="step"><p>
    Restart the Ceph Manager service:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph orch restart mgr</pre></div></li><li class="step"><p>
    Reconfigure the Grafana service to reflect the new certificate paths and
    set the right URL for the Ceph Dashboard:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph orch reconfig grafana</pre></div></li></ol></div></div><p>
  The Alertmanager handles alerts sent by the Prometheus server. It takes
  care of deduplicating, grouping, and routing them to the correct receiver.
  Alerts can be silenced using the Alertmanager, but silences can also be
  managed using the Ceph Dashboard.
 </p><p>
  We recommend that the <code class="systemitem">Node exporter</code>
  is deployed on all nodes. This can be done using the
  <code class="filename">monitoring.yaml</code> file with the
  <code class="literal">node-exporter</code> service type. See
  <span class="intraxref">Book “Deployment Guide”, Chapter 8 “Deploying the remaining core services using cephadm”, Section 8.3.8 “Deploying the monitoring stack”</span> for more
  information on deploying services.
 </p><section class="sect1" id="monitoring-custom-images" data-id-title="Configuring custom or local images"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">16.1 </span><span class="title-name">Configuring custom or local images</span></span> <a title="Permalink" class="permalink" href="monitoring-alerting.html#monitoring-custom-images">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-ses/edit/main/xml/admin_monitoring_alerting.xml" title="Edit source document"> </a></div></div></div></div></div><div id="id-1.4.4.6.13.2" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg"/><div class="admon-title">Tip</div><p>
    This section describes how to change the configuration of container images
    which are used when services are deployed or updated. It does not include
    the commands necessary to deploy or re-deploy services.
   </p><p>
    The recommended method to deploy the monitoring stack is by applying its
    specification as described in
    <span class="intraxref">Book “Deployment Guide”, Chapter 8 “Deploying the remaining core services using cephadm”, Section 8.3.8 “Deploying the monitoring stack”</span>.
   </p></div><p>
   To deploy custom or local container images, the images need to be set in
   cephadm. To do so, you will need to run the following command:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph config set mgr mgr/cephadm/<em class="replaceable">OPTION_NAME</em> <em class="replaceable">VALUE</em></pre></div><p>
   Where <em class="replaceable">OPTION_NAME</em> is any of the following names:
  </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
     container_image_prometheus
    </p></li><li class="listitem"><p>
     container_image_node_exporter
    </p></li><li class="listitem"><p>
     container_image_alertmanager
    </p></li><li class="listitem"><p>
     container_image_grafana
    </p></li></ul></div><p>
   If no option is set or if the setting has been removed, the following images
   are used as <em class="replaceable">VALUE</em>:
  </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
     registry.suse.com/ses/7/ceph/prometheus-server:2.27.1
    </p></li><li class="listitem"><p>
     registry.suse.com/ses/7/ceph/prometheus-node-exporter:1.1.2
    </p></li><li class="listitem"><p>
     registry.suse.com/ses/7/ceph/prometheus-alertmanager:0.21.0
    </p></li><li class="listitem"><p>
     registry.suse.com/ses/7/ceph/grafana:7.3.1
    </p></li></ul></div><p>
   For example:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph config set mgr mgr/cephadm/container_image_prometheus prom/prometheus:v1.4.1</pre></div><div id="id-1.4.4.6.13.11" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><div class="admon-title">Note</div><p>
    By setting a custom image, the default value will be overridden (but not
    overwritten). The default value changes when updates become available. By
    setting a custom image, you will not be able to update the component you
    have set the custom image for automatically. You will need to manually
    update the configuration (image name and tag) to be able to install
    updates.
   </p><p>
    If you choose to go with the recommendations instead, you can reset the
    custom image you have set before. After that, the default value will be
    used again. Use <code class="command">ceph config rm</code> to reset the
    configuration option:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph config rm mgr mgr/cephadm/<em class="replaceable">OPTION_NAME</em></pre></div><p>
    For example:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph config rm mgr mgr/cephadm/container_image_prometheus</pre></div></div></section><section class="sect1" id="monitoring-applying-updates" data-id-title="Updating monitoring services"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">16.2 </span><span class="title-name">Updating monitoring services</span></span> <a title="Permalink" class="permalink" href="monitoring-alerting.html#monitoring-applying-updates">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-ses/edit/main/xml/admin_monitoring_alerting.xml" title="Edit source document"> </a></div></div></div></div></div><p>
   As mentioned in <a class="xref" href="monitoring-alerting.html#monitoring-custom-images" title="16.1. Configuring custom or local images">Section 16.1, “Configuring custom or local images”</a>, cephadm is
   shipped with the URLs of the recommended and tested container images, and
   they are used by default.
  </p><p>
   By updating the Ceph packages, new versions of these URLs may be shipped.
   This just updates where the container images are pulled from but does not
   update any services.
  </p><p>
   After the URLs to the new container images have been updated, either
   manually as described in <a class="xref" href="monitoring-alerting.html#monitoring-custom-images" title="16.1. Configuring custom or local images">Section 16.1, “Configuring custom or local images”</a>, or
   automatically through an update of the Ceph package, the monitoring
   services can be updated.
  </p><p>
   To do so, use <code class="command">ceph orch reconfig</code> like so:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph orch reconfig node-exporter
<code class="prompt user">cephuser@adm &gt; </code>ceph orch reconfig prometheus
<code class="prompt user">cephuser@adm &gt; </code>ceph orch reconfig alertmanager
<code class="prompt user">cephuser@adm &gt; </code>ceph orch reconfig grafana</pre></div><p>
   Currently no single command to update all monitoring services exists. The
   order in which these services are updated is not important.
  </p><div id="id-1.4.4.6.14.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><div class="admon-title">Note</div><p>
    If you use custom container images, the URLs specified for the monitoring
    services will not change automatically if the Ceph packages are updated.
    If you have specified custom container images, you will need to specify the
    URLs of the new container images manually. This may be the case if you use
    a local container registry.
   </p><p>
    You can find the URLs of the recommended container images to be used in the
    <a class="xref" href="monitoring-alerting.html#monitoring-custom-images" title="16.1. Configuring custom or local images">Section 16.1, “Configuring custom or local images”</a> section.
   </p></div></section><section class="sect1" id="monitoring-stack-disable" data-id-title="Disabling monitoring"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">16.3 </span><span class="title-name">Disabling monitoring</span></span> <a title="Permalink" class="permalink" href="monitoring-alerting.html#monitoring-stack-disable">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-ses/edit/main/xml/admin_monitoring_alerting.xml" title="Edit source document"> </a></div></div></div></div></div><p>
   To disable the monitoring stack, run the following commands:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph orch rm grafana
<code class="prompt user">cephuser@adm &gt; </code>ceph orch rm prometheus --force   # this will delete metrics data collected so far
<code class="prompt user">cephuser@adm &gt; </code>ceph orch rm node-exporter
<code class="prompt user">cephuser@adm &gt; </code>ceph orch rm alertmanager
<code class="prompt user">cephuser@adm &gt; </code>ceph mgr module disable prometheus</pre></div></section><section class="sect1" id="monitoring-grafana-config" data-id-title="Configuring Grafana"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">16.4 </span><span class="title-name">Configuring Grafana</span></span> <a title="Permalink" class="permalink" href="monitoring-alerting.html#monitoring-grafana-config">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-ses/edit/main/xml/admin_monitoring_alerting.xml" title="Edit source document"> </a></div></div></div></div></div><p>
   The Ceph Dashboard back-end requires the Grafana URL to be able to verify the
   existence of Grafana Dashboards before the front-end even loads them.
   Because of the nature of how Grafana is implemented in Ceph Dashboard, this
   means that two working connections are required in order to be able to see
   Grafana graphs in Ceph Dashboard:
  </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
     The back-end (Ceph MGR module) needs to verify the existence of the
     requested graph. If this request succeeds, it lets the front-end know that
     it can safely access Grafana.
    </p></li><li class="listitem"><p>
     The front-end then requests the Grafana graphs directly from the user's
     browser using an <code class="literal">iframe</code>. The Grafana instance is
     accessed directly without any detour through Ceph Dashboard.
    </p></li></ul></div><p>
   Now, it might be the case that your environment makes it difficult for the
   user's browser to directly access the URL configured in Ceph Dashboard. To
   solve this issue, a separate URL can be configured which will solely be used
   to tell the front-end (the user's browser) which URL it should use to access
   Grafana.
  </p><p>
   To change the URL that is returned to the front-end issue the following
   command:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph dashboard set-grafana-frontend-api-url <em class="replaceable">GRAFANA-SERVER-URL</em></pre></div><p>
   If no value is set for that option, it will simply fall back to the value of
   the <em class="replaceable">GRAFANA_API_URL</em> option, which is set
   automatically and periodically updated by cephadm. If set, it will
   instruct the browser to use this URL to access Grafana.
  </p></section><section class="sect1" id="monitoring-cephadm-config" data-id-title="Configuring the Prometheus Manager Module"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">16.5 </span><span class="title-name">Configuring the Prometheus Manager Module</span></span> <a title="Permalink" class="permalink" href="monitoring-alerting.html#monitoring-cephadm-config">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-ses/edit/main/xml/admin_monitoring_alerting.xml" title="Edit source document"> </a></div></div></div></div></div><p>
   The Prometheus Manager Module is a module inside Ceph that extends Ceph's
   functionality. The module reads (meta-)data from Ceph about its state and
   health, providing the (scraped) data in a consumable format to Prometheus.
  </p><div id="id-1.4.4.6.17.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><div class="admon-title">Note</div><p>
    The Prometheus Manager Module needs to be restarted for the configuration changes to
    be applied.
   </p></div><section class="sect2" id="monitoring-http-requests" data-id-title="Configuring the network interface"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">16.5.1 </span><span class="title-name">Configuring the network interface</span></span> <a title="Permalink" class="permalink" href="monitoring-alerting.html#monitoring-http-requests">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-ses/edit/main/xml/admin_monitoring_alerting.xml" title="Edit source document"> </a></div></div></div></div></div><p>
    By default, the Prometheus Manager Module accepts HTTP requests on port 9283 on all
    IPv4 and IPv6 addresses on the host. The port and listen address are both
    configurable with <code class="option">ceph config-key set</code> , with keys
    <code class="option">mgr/prometheus/server_addr</code> and
    <code class="option">mgr/prometheus/server_port</code> . This port is registered
    withPrometheus's registry.
   </p><p>
    To update the <code class="literal">server_addr</code> execute the following command:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph config set mgr mgr/prometheus/server_addr <em class="replaceable">0.0.0.0</em></pre></div><p>
    To update the <code class="literal">server_port</code> execute the following command:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph config set mgr mgr/prometheus/server_port <em class="replaceable">9283</em></pre></div></section><section class="sect2" id="monitoring-scrape-intervals" data-id-title="Configuring scrape_interval"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">16.5.2 </span><span class="title-name">Configuring <code class="literal">scrape_interval</code></span></span> <a title="Permalink" class="permalink" href="monitoring-alerting.html#monitoring-scrape-intervals">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-ses/edit/main/xml/admin_monitoring_alerting.xml" title="Edit source document"> </a></div></div></div></div></div><p>
    By default, the Prometheus Manager Module is configured with a scrape interval of 15
    seconds. We do not recommend using a scrape interval below 10 seconds. To
    set a different scrape interval in the Prometheus module, set
    <code class="literal">scrape_interval</code> to the desired value:
   </p><div id="id-1.4.4.6.17.5.3" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.svg"/><div class="admon-title">Important</div><p>
     To work properly and not cause any issues, the
     <code class="literal">scrape_interval</code> of this module should always be set to
     match the Prometheus scrape interval .
    </p></div><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph config set mgr mgr/prometheus/scrape_interval <em class="replaceable">15</em></pre></div></section><section class="sect2" id="monitoring-stale-cache" data-id-title="Configuring the cache"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">16.5.3 </span><span class="title-name">Configuring the cache</span></span> <a title="Permalink" class="permalink" href="monitoring-alerting.html#monitoring-stale-cache">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-ses/edit/main/xml/admin_monitoring_alerting.xml" title="Edit source document"> </a></div></div></div></div></div><p>
    On large clusters (more than 1000 OSDs), the time to fetch the metrics may
    become significant. Without the cache, the Prometheus Manager Module can overload the
    manager and lead to unresponsive or crashing Ceph Manager instances. As a result,
    the cache is enabled by default and cannot be disabled, but this does mean
    that the cache can become stale. The cache is considered stale when the
    time to fetch the metrics from Ceph exceeds the configured
    <code class="literal">scrape_interval</code>.
   </p><p>
    If this is the case, a warning will be logged and the module will either:
   </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
      Respond with a 503 HTTP status code (service unavailable).
     </p></li><li class="listitem"><p>
      Return the content of the cache, even though it might be stale.
     </p></li></ul></div><p>
    This behavior can be configured using the <code class="command">ceph config
    set</code> commands.
   </p><p>
    To tell the module to respond with possibly-stale data, set it to
    <code class="literal">return</code>:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph config set mgr mgr/prometheus/stale_cache_strategy return</pre></div><p>
    To tell the module to respond with <code class="literal">service unavailable</code>,
    set it to <code class="literal">fail</code>:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph config set mgr mgr/prometheus/stale_cache_strategy fail</pre></div></section><section class="sect2" id="monitoring-rbd-image" data-id-title="Enabling RBD-image monitoring"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">16.5.4 </span><span class="title-name">Enabling RBD-image monitoring</span></span> <a title="Permalink" class="permalink" href="monitoring-alerting.html#monitoring-rbd-image">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-ses/edit/main/xml/admin_monitoring_alerting.xml" title="Edit source document"> </a></div></div></div></div></div><p>
    The Prometheus Manager Module can optionally collect RBD per-image IO statistics by
    enabling dynamic OSD performance counters. The statistics are gathered for
    all images in the pools that are specified in the
    <code class="literal">mgr/prometheus/rbd_stats_pools</code> configuration parameter.
   </p><p>
    The parameter is a comma- or space-separated list of
    <code class="literal">pool[/namespace]</code> entries. If the namespace is not
    specified, the statistics are collected for all namespaces in the pool.
   </p><p>
    For example:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph config set mgr mgr/prometheus/rbd_stats_pools "<em class="replaceable">pool1,pool2,poolN</em>"</pre></div><p>
    The module scans the specified pools and namespaces and makes a list of all
    available images, and refreshes it periodically. The interval is
    configurable via the
    <code class="literal">mgr/prometheus/rbd_stats_pools_refresh_interval</code>
    parameter (in seconds), and is 300 seconds (five minutes) by default.
   </p><p>
    For example, if you changed the synchronization interval to 10 minutes:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph config set mgr mgr/prometheus/rbd_stats_pools_refresh_interval <em class="replaceable">600</em></pre></div></section></section><section class="sect1" id="prometheus-security-model" data-id-title="Prometheus security model"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">16.6 </span><span class="title-name">Prometheus security model</span></span> <a title="Permalink" class="permalink" href="monitoring-alerting.html#prometheus-security-model">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-ses/edit/main/xml/admin_monitoring_alerting.xml" title="Edit source document"> </a></div></div></div></div></div><p>
   Prometheus' security model presumes that untrusted users have access to
   the Prometheus HTTP endpoint and logs. Untrusted users have access to all
   the (meta-)data Prometheus collects that is contained in the database,
   plus a variety of operational and debugging information.
  </p><p>
   However, Prometheus' HTTP API is limited to read-only operations.
   Configurations cannot be changed using the API, and secrets are not exposed.
   Moreover, Prometheus has some built-in measures to mitigate the impact of
   denial-of-service attacks.
  </p></section><section class="sect1" id="prometheus-webhook-snmp" data-id-title="Prometheus Alertmanager SNMP webhook"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">16.7 </span><span class="title-name">Prometheus Alertmanager SNMP webhook</span></span> <a title="Permalink" class="permalink" href="monitoring-alerting.html#prometheus-webhook-snmp">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-ses/edit/main/xml/admin_monitoring_alerting.xml" title="Edit source document"> </a></div></div></div></div></div><p>
   If you want to get notified about Prometheus alerts via SNMP traps, then
   you can install the Prometheus Alertmanager SNMP webhook via cephadm.
   To do so, you need to create a service and placement specification file with
   the following content:
  </p><div id="id-1.4.4.6.19.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><div class="admon-title">Note</div><p>
    For more information on service and placement files, see
    <span class="intraxref">Book “Deployment Guide”, Chapter 8 “Deploying the remaining core services using cephadm”, Section 8.2 “Service and placement specification”</span>.
   </p></div><div class="verbatim-wrap"><pre class="screen">service_type: container
service_id: prometheus-webhook-snmp
placement:
    <em class="replaceable">ADD_PLACEMENT_HERE</em>
image: registry.suse.com/ses/7/prometheus-webhook-snmp:latest
args:
    - "--publish 9099:9099"
envs:
    - ARGS="--debug --snmp-host=<em class="replaceable">ADD_HOST_GATEWAY_HERE</em>"
    - RUN_ARGS="--metrics"
EOF</pre></div><p>
   Use this service specification to get the service running using its default
   settings.
  </p><p>
   You need to publish the port the Prometheus receiver is listening on by
   using the command line argument <code class="literal">--publish
   <em class="replaceable">HOST_PORT</em>:<em class="replaceable">CONTAINER_PORT</em></code>
   when running the service, because the port is not exposed automatically by
   the container. This can be done by adding the following lines to the
   specification:
  </p><div class="verbatim-wrap"><pre class="screen">args:
    - "--publish 9099:9099"</pre></div><p>
   Alternatively, connect the container to the host network by using the
   command line argument <code class="literal">--network=host</code>.
  </p><div class="verbatim-wrap"><pre class="screen">args:
    - "--network=host"</pre></div><p>
   If the SNMP trap receiver is not installed on the same host as the
   container, then you must also specify the FQDN of the SNMP host. Use the
   container's network gateway to be able to receive SNMP traps outside the
   container/host:
  </p><div class="verbatim-wrap"><pre class="screen">envs:
    - ARGS="--debug --snmp-host=<em class="replaceable">CONTAINER_GATEWAY</em>"</pre></div><section class="sect2" id="configure-prometheus-webhook-snmp" data-id-title="Configuring the prometheus-webhook-snmp service"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">16.7.1 </span><span class="title-name">Configuring the <code class="literal">prometheus-webhook-snmp</code> service</span></span> <a title="Permalink" class="permalink" href="monitoring-alerting.html#configure-prometheus-webhook-snmp">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-ses/edit/main/xml/admin_monitoring_alerting.xml" title="Edit source document"> </a></div></div></div></div></div><p>
    The container can be configured by environment variables or by using a
    configuration file.
   </p><p>
    For the environment variables, use <code class="literal">ARGS</code> to set global
    options and <code class="literal">RUN_ARGS</code> for the <code class="command">run</code>
    command options. You need to adapt the service specification the following
    way:
   </p><div class="verbatim-wrap"><pre class="screen">envs:
    - ARGS="--debug --snmp-host=<em class="replaceable">CONTAINER_GATEWAY</em>"
    - RUN_ARGS="--metrics --port=9101"</pre></div><p>
    To use a configuration file, the service specification must be adapted the
    following way:
   </p><div class="verbatim-wrap"><pre class="screen">files:
    etc/prometheus-webhook-snmp.conf:
        - "debug: True"
        - "snmp_host: <em class="replaceable">ADD_HOST_GATEWAY_HERE</em>"
        - "metrics: True"
volume_mounts:
    etc/prometheus-webhook-snmp.conf: /etc/prometheus-webhook-snmp.conf</pre></div><p>
    To deploy, run the following command:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph orch apply -i <em class="replaceable">SERVICE_SPEC_FILE</em></pre></div><p>
    See <span class="intraxref">Book “Deployment Guide”, Chapter 8 “Deploying the remaining core services using cephadm”, Section 8.3 “Deploy Ceph services”</span> for more information.
   </p></section><section class="sect2" id="configure-prometheus-alertmanager-for-snmp" data-id-title="Configuring the Prometheus Alertmanager for SNMP"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">16.7.2 </span><span class="title-name">Configuring the Prometheus Alertmanager for SNMP</span></span> <a title="Permalink" class="permalink" href="monitoring-alerting.html#configure-prometheus-alertmanager-for-snmp">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-ses/edit/main/xml/admin_monitoring_alerting.xml" title="Edit source document"> </a></div></div></div></div></div><p>
    Finally, the Prometheus Alertmanager needs to be configured
    specifically for SNMP traps. If this service has not been deployed already,
    create a service specification file. You need to replace
    <code class="literal">IP_OR_FQDN</code> with the IP address or FQDN of the host where
    the Prometheus Alertmanager SNMP webhook has been installed. For
    example:
   </p><div id="id-1.4.4.6.19.13.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><div class="admon-title">Note</div><p>
     If you have already deployed this service, then to ensure the
     Alertmanager is set up correctly for SNMP, re-deploy with the following
     settings.
    </p></div><div class="verbatim-wrap"><pre class="screen">  service_type: alertmanager
  placement:
    hosts:
    - <em class="replaceable">HOSTNAME</em>
  user_data:
    default_webhook_urls:
    - 'http://<em class="replaceable">IP_OR_FQDN</em>:9099/'</pre></div><p>
    Apply the service specification with the following command:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph orch apply -i <em class="replaceable">SERVICE_SPEC_FILE</em></pre></div></section></section></section><nav class="bottom-pagination"><div><a class="pagination-link prev" href="cha-deployment-backup.html"><span class="pagination-relation">Previous</span><span class="pagination-label"><span class="title-number">Chapter 15 </span>Backup and restore</span></a> </div><div><a class="pagination-link next" href="part-storing-data.html"><span class="pagination-relation">Next</span><span class="pagination-label"><span class="title-number">Part III </span>Storing Data in a Cluster</span></a> </div></nav></article><aside id="_side-toc-page" class="side-toc"><div class="side-title">On this page</div><div class="toc"><ul><li><span class="sect1"><a href="monitoring-alerting.html#monitoring-custom-images"><span class="title-number">16.1 </span><span class="title-name">Configuring custom or local images</span></a></span></li><li><span class="sect1"><a href="monitoring-alerting.html#monitoring-applying-updates"><span class="title-number">16.2 </span><span class="title-name">Updating monitoring services</span></a></span></li><li><span class="sect1"><a href="monitoring-alerting.html#monitoring-stack-disable"><span class="title-number">16.3 </span><span class="title-name">Disabling monitoring</span></a></span></li><li><span class="sect1"><a href="monitoring-alerting.html#monitoring-grafana-config"><span class="title-number">16.4 </span><span class="title-name">Configuring Grafana</span></a></span></li><li><span class="sect1"><a href="monitoring-alerting.html#monitoring-cephadm-config"><span class="title-number">16.5 </span><span class="title-name">Configuring the Prometheus Manager Module</span></a></span></li><li><span class="sect1"><a href="monitoring-alerting.html#prometheus-security-model"><span class="title-number">16.6 </span><span class="title-name">Prometheus security model</span></a></span></li><li><span class="sect1"><a href="monitoring-alerting.html#prometheus-webhook-snmp"><span class="title-number">16.7 </span><span class="title-name">Prometheus Alertmanager SNMP webhook</span></a></span></li></ul></div><div class="side-title">Share this page</div><ul class="share"><li><a id="_share-fb" href="#" title="Facebook"> </a></li><li><a id="_share-in" href="#" title="LinkedIn"> </a></li><li><a id="_share-tw" href="#" title="Twitter"> </a></li><li><a id="_share-mail" href="#" title="E-Mail"> </a></li><li><a id="_print-button" href="#" title="Print this page"> </a></li></ul> </aside></main><footer id="_footer"><div class="growth-inhibitor"><div class="copy"><span class="copy__rights">© SUSE
                 2023</span></div></div></footer></body></html>