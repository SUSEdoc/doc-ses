<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes"/><title>Deployment of additional services | Deployment Guide | SUSE Enterprise Storage 7</title><link rel="stylesheet" type="text/css" href="static/css/style.css"/>
<meta name="title" content="Deployment of additional services | SES 7"/>
<meta name="description" content="iSCSI is a storage area network (SAN) protocol that allows clients (called initiators) to send SCSI commands to SCSI storage devices (targets) on rem…"/>
<meta name="product-name" content="SUSE Enterprise Storage"/>
<meta name="product-number" content="7"/>
<meta name="book-title" content="Deployment Guide"/>
<meta name="chapter-title" content="Chapter 9. Deployment of additional services"/>
<meta name="tracker-url" content="https://github.com/SUSE/doc-ses/issues/new"/>
<meta name="tracker-type" content="gh"/>
<meta name="tracker-gh-assignee" content="tbazant"/>
<meta name="tracker-gh-template" content="&#10;     ### Type of report&#10;   - [ ] bug&#10;   - [ ] feature request&#10;&#10;### Source Document&#10;@@source@@&#10;&#10;### Summary&#10;&lt;!-- A clear and concise description of what the bug/feature request is. --&gt;&#10;&#10;### Steps To Reproduce&#10;&lt;!-- Steps to reproduce the behavior if you ran through steps in the document. --&gt;&#10;&#10;### Expected Results&#10;&lt;!-- A clear and concise description of what you expected to happen. --&gt;&#10;&#10;### Actual Results&#10;&lt;!-- Explain what actually happened if steps were executed, and if applicable, add screenshots to help explain your problem. --&gt;&#10;&#10;### Notes&#10;&lt;!-- Add any other context about the problem here. --&gt;&#10;&#10;    "/>
<meta name="tracker-gh-labels" content="bug,question,feature request"/>
<meta property="og:title" content="Deployment of additional services | SES 7"/>
<meta property="og:description" content="iSCSI is a storage area network (SAN) protocol that allows clients (called initiators) to send SCSI commands to SCSI storage devices (targets) on rem…"/>
<meta property="og:type" content="article"/>
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Deployment of additional services | SES 7"/>
<meta name="twitter:description" content="iSCSI is a storage area network (SAN) protocol that allows clients (called initiators) to send SCSI commands to SCSI storage devices (targets) on rem…"/>
<link rel="prev" href="deploy-core.html" title="Chapter 8. Deploying the remaining core services using cephadm"/><link rel="next" href="ses-upgrade.html" title="Part III. Upgrading from Previous Releases"/>
<script type="text/javascript">

if ( window.location.protocol.toLowerCase() != 'file:' ) {
  document.write('<link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css"></link>');
};

</script><noscript><link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css"/></noscript><script src="static/js/jquery-1.12.4.min.js" type="text/javascript"> </script><script src="static/js/script.js" type="text/javascript"> </script><script src="static/js/highlight.min.js" type="text/javascript"> </script><script>

$(document).ready(function() {
  $('.verbatim-wrap.highlight').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});
hljs.configure({
  useBR: false
});

</script></head><body class="draft wide offline js-off" onload="$('#betawarn-button-wrap').toggle();if (document.cookie.length > 0) {if (document.cookie.indexOf('betawarn=closed') != -1){$('#betawarn').toggle()}};"><div id="betawarn" style="position:fixed;bottom:0;z-index:9025;background-color:#FDE8E8;padding:1em;margin-left:10%;margin-right:10%;display:block;border-top:.75em solid #E11;width:80%"><p style="color:#333;margin:1em 0;padding:0;">This is a draft document that was built and uploaded automatically. It may document beta software and be incomplete or even incorrect. <strong>Use this document at your own risk.</strong></p> <div id="betawarn-button-wrap" style="display:none;margin:0;padding:0;"><a href="#" onclick="$('#betawarn').toggle();var d=new Date();d.setTime(d.getTime()+(0.5*24*60*60*1000));document.cookie='betawarn=closed; expires='+d.toUTCString()+'; path=/'; return false;" style="color:#333;text-decoration:underline;float:left;margin-top:.5em;padding:1em;display:block;background-color:#FABEBE;">I understand this is a draft</a></div></div><div class="bypass-block"><a href="#_content">Jump to content</a><a href="#_bottom-pagination">Jump to page navigation: previous page [access key p]/next page [access key n]</a></div><header id="_mainnav"><div class="growth-inhibitor"><img src="static/images/logo.svg" alt="Logo" class="logo"/></div></header><div class="crumbs"><div class="growth-inhibitor"><a class="crumb" href="index.html">Deployment Guide</a><span> / </span><a class="crumb" href="ses-deployment.html">Deploying Ceph Cluster</a><span> / </span><a class="crumb" href="deploy-additional.html">Deployment of additional services</a></div></div><main id="_content"><nav id="_side-toc-overall" class="side-toc"><div class="side-title">Deployment Guide</div><ol><li><a href="preface-deployment.html" class=" "><span class="title-number"> </span><span class="title-name">About this guide</span></a></li><li><a href="part-ses.html" class="has-children "><span class="title-number">I </span><span class="title-name">Introducing SUSE Enterprise Storage (SES)</span></a><ol><li><a href="cha-storage-about.html" class=" "><span class="title-number">1 </span><span class="title-name">SES and Ceph</span></a></li><li><a href="storage-bp-hwreq.html" class=" "><span class="title-number">2 </span><span class="title-name">Hardware requirements and recommendations</span></a></li><li><a href="cha-admin-ha.html" class=" "><span class="title-number">3 </span><span class="title-name">Admin Node HA setup</span></a></li></ol></li><li class="active"><a href="ses-deployment.html" class="has-children you-are-here"><span class="title-number">II </span><span class="title-name">Deploying Ceph Cluster</span></a><ol><li><a href="deploy-intro.html" class=" "><span class="title-number">4 </span><span class="title-name">Introduction and common tasks</span></a></li><li><a href="deploy-sles.html" class=" "><span class="title-number">5 </span><span class="title-name">Installing and configuring SUSE Linux Enterprise Server</span></a></li><li><a href="deploy-salt.html" class=" "><span class="title-number">6 </span><span class="title-name">Deploying Salt</span></a></li><li><a href="deploy-bootstrap.html" class=" "><span class="title-number">7 </span><span class="title-name">Deploying the bootstrap cluster using <code class="systemitem">ceph-salt</code></span></a></li><li><a href="deploy-core.html" class=" "><span class="title-number">8 </span><span class="title-name">Deploying the remaining core services using cephadm</span></a></li><li><a href="deploy-additional.html" class=" you-are-here"><span class="title-number">9 </span><span class="title-name">Deployment of additional services</span></a></li></ol></li><li><a href="ses-upgrade.html" class="has-children "><span class="title-number">III </span><span class="title-name">Upgrading from Previous Releases</span></a><ol><li><a href="cha-ceph-upgrade.html" class=" "><span class="title-number">10 </span><span class="title-name">Upgrade from a previous release</span></a></li></ol></li><li><a href="bk01apa.html" class=" "><span class="title-number">A </span><span class="title-name">Ceph maintenance updates based on upstream 'Octopus' point releases</span></a></li><li><a href="bk01go01.html" class=" "><span class="title-number"> </span><span class="title-name">Glossary</span></a></li> </ol> </nav><button id="_open-side-toc-overall" title="Contents"> </button><article class="documentation"><button id="_unfold-side-toc-page">On this page</button><section class="chapter" id="deploy-additional" data-id-title="Deployment of additional services"><div class="titlepage"><div><div class="version-info">Applies to  <span class="productname">SUSE Enterprise Storage</span> <span class="productnumber">7</span></div><div><h1 class="title"><span class="title-number">9 </span><span class="title-name">Deployment of additional services</span> <a title="Permalink" class="permalink" href="deploy-additional.html#">#</a></h1></div></div></div><section class="sect1" id="cha-ceph-as-iscsi" data-id-title="Installation of iSCSI gateway"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">9.1 </span><span class="title-name">Installation of iSCSI gateway</span> <a title="Permalink" class="permalink" href="deploy-additional.html#cha-ceph-as-iscsi">#</a></h2></div></div></div><p>
   iSCSI is a storage area network (SAN) protocol that allows clients (called
   <span class="emphasis"><em>initiators</em></span>) to send SCSI commands to SCSI storage
   devices (<span class="emphasis"><em>targets</em></span>) on remote servers. SUSE Enterprise Storage
   7 includes a facility that opens Ceph storage management to
   heterogeneous clients, such as Microsoft Windows* and VMware* vSphere, through the
   iSCSI protocol. Multipath iSCSI access enables availability and scalability
   for these clients, and the standardized iSCSI protocol also provides an
   additional layer of security isolation between clients and the SUSE Enterprise Storage
   7 cluster. The configuration facility is named <code class="systemitem">ceph-iscsi</code>.
   Using <code class="systemitem">ceph-iscsi</code>, Ceph storage administrators can define thin-provisioned,
   replicated, highly-available volumes supporting read-only snapshots,
   read-write clones, and automatic resizing with Ceph RADOS Block Device
   (RBD). Administrators can then export volumes either via a single <code class="systemitem">ceph-iscsi</code>
   gateway host, or via multiple gateway hosts supporting multipath failover.
   Linux, Microsoft Windows, and VMware hosts can connect to volumes using the iSCSI
   protocol, which makes them available like any other SCSI block device. This
   means SUSE Enterprise Storage 7 customers can effectively run a complete
   block-storage infrastructure subsystem on Ceph that provides all the
   features and benefits of a conventional SAN, enabling future growth.
  </p><p>
   This chapter introduces detailed information to set up a Ceph cluster
   infrastructure together with an iSCSI gateway so that the client hosts can
   use remotely stored data as local storage devices using the iSCSI protocol.
  </p><section class="sect2" id="ceph-iscsi-iscsi" data-id-title="iSCSI block storage"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">9.1.1 </span><span class="title-name">iSCSI block storage</span> <a title="Permalink" class="permalink" href="deploy-additional.html#ceph-iscsi-iscsi">#</a></h3></div></div></div><p>
    iSCSI is an implementation of the Small Computer System Interface (SCSI)
    command set using the Internet Protocol (IP), specified in RFC 3720. iSCSI
    is implemented as a service where a client (the initiator) talks to a
    server (the target) via a session on TCP port 3260. An iSCSI target's IP
    address and port are called an <span class="emphasis"><em>iSCSI portal</em></span>, where a
    target can be exposed through one or more portals. The combination of a
    target and one or more portals is called the <span class="emphasis"><em>target portal
    group</em></span> (TPG).
   </p><p>
    The underlying data link layer protocol for iSCSI is most often Ethernet.
    More specifically, modern iSCSI infrastructures use 10 GigE Ethernet or
    faster networks for optimal throughput. 10 Gigabit Ethernet connectivity
    between the iSCSI gateway and the back-end Ceph cluster is strongly
    recommended.
   </p><section class="sect3" id="ceph-iscsi-iscsi-target" data-id-title="The Linux kernel iSCSI target"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">9.1.1.1 </span><span class="title-name">The Linux kernel iSCSI target</span> <a title="Permalink" class="permalink" href="deploy-additional.html#ceph-iscsi-iscsi-target">#</a></h4></div></div></div><p>
     The Linux kernel iSCSI target was originally named LIO for
     <code class="literal">linux-iscsi.org</code>, the project's original domain and Web
     site. For some time, no fewer than four competing iSCSI target
     implementations were available for the Linux platform, but LIO ultimately
     prevailed as the single iSCSI reference target. The mainline kernel code
     for LIO uses the simple, but somewhat ambiguous name "target",
     distinguishing between "target core" and a variety of front-end and
     back-end target modules.
    </p><p>
     The most commonly used front-end module is arguably iSCSI. However, LIO
     also supports Fibre Channel (FC), Fibre Channel over Ethernet (FCoE) and
     several other front-end protocols. At this time, only the iSCSI protocol
     is supported by SUSE Enterprise Storage.
    </p><p>
     The most frequently used target back-end module is one that is capable of
     simply re-exporting any available block device on the target host. This
     module is named <span class="emphasis"><em>iblock</em></span>. However, LIO also has an
     RBD-specific back-end module supporting parallelized multipath I/O access
     to RBD images.
    </p></section><section class="sect3" id="ceph-iscsi-iscsi-initiators" data-id-title="iSCSI initiators"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">9.1.1.2 </span><span class="title-name">iSCSI initiators</span> <a title="Permalink" class="permalink" href="deploy-additional.html#ceph-iscsi-iscsi-initiators">#</a></h4></div></div></div><p>
     This section introduces brief information on iSCSI initiators used on
     Linux, Microsoft Windows, and VMware platforms.
    </p><section class="sect4" id="ceph-iscsi-initiators-linux" data-id-title="Linux"><div class="titlepage"><div><div><h5 class="title"><span class="title-number">9.1.1.2.1 </span><span class="title-name">Linux</span> <a title="Permalink" class="permalink" href="deploy-additional.html#ceph-iscsi-initiators-linux">#</a></h5></div></div></div><p>
      The standard initiator for the Linux platform is
      <code class="systemitem">open-iscsi</code>. <code class="systemitem">open-iscsi</code>
      launches a daemon, <code class="systemitem">iscsid</code>, which the user can
      then use to discover iSCSI targets on any given portal, log in to
      targets, and map iSCSI volumes. <code class="systemitem">iscsid</code>
      communicates with the SCSI mid layer to create in-kernel block devices
      that the kernel can then treat like any other SCSI block device on the
      system. The <code class="systemitem">open-iscsi</code> initiator can be deployed
      in conjunction with the Device Mapper Multipath
      (<code class="systemitem">dm-multipath</code>) facility to provide a highly
      available iSCSI block device.
     </p></section><section class="sect4" id="ceph-iscsi-mswin-hyperv" data-id-title="Microsoft Windows and Hyper-V"><div class="titlepage"><div><div><h5 class="title"><span class="title-number">9.1.1.2.2 </span><span class="title-name">Microsoft Windows and Hyper-V</span> <a title="Permalink" class="permalink" href="deploy-additional.html#ceph-iscsi-mswin-hyperv">#</a></h5></div></div></div><p>
      The default iSCSI initiator for the Microsoft Windows operating system is the
      Microsoft iSCSI initiator. The iSCSI service can be configured via a
      graphical user interface (GUI), and supports multipath I/O for high
      availability.
     </p></section><section class="sect4" id="ceph-iscsi-vmware" data-id-title="VMware"><div class="titlepage"><div><div><h5 class="title"><span class="title-number">9.1.1.2.3 </span><span class="title-name">VMware</span> <a title="Permalink" class="permalink" href="deploy-additional.html#ceph-iscsi-vmware">#</a></h5></div></div></div><p>
      The default iSCSI initiator for VMware vSphere and ESX is the VMware
      ESX software iSCSI initiator, <code class="systemitem">vmkiscsi</code>. When
      enabled, it can be configured either from the vSphere client, or using
      the <code class="command">vmkiscsi-tool</code> command. You can then format storage
      volumes connected through the vSphere iSCSI storage adapter with VMFS,
      and use them like any other VM storage device. The VMware initiator
      also supports multipath I/O for high availability.
     </p></section></section></section><section class="sect2" id="ceph-iscsi-lrbd" data-id-title="General information about ceph-iscsi"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">9.1.2 </span><span class="title-name">General information about <code class="systemitem">ceph-iscsi</code></span> <a title="Permalink" class="permalink" href="deploy-additional.html#ceph-iscsi-lrbd">#</a></h3></div></div></div><p>
    <code class="systemitem">ceph-iscsi</code> combines the benefits of RADOS Block Devices with the ubiquitous
    versatility of iSCSI. By employing <code class="systemitem">ceph-iscsi</code> on an iSCSI target host (known
    as the iSCSI Gateway), any application that needs to make use of block storage can
    benefit from Ceph, even if it does not speak any Ceph client protocol.
    Instead, users can use iSCSI or any other target front-end protocol to
    connect to an LIO target, which translates all target I/O to RBD storage
    operations.
   </p><div class="figure" id="id-1.3.4.7.2.5.3"><div class="figure-contents"><div class="mediaobject"><a href="images/lrbd_scheme1.png"><img src="images/lrbd_scheme1.png" width="75%" alt="Ceph Cluster with a Single iSCSI Gateway" title="Ceph Cluster with a Single iSCSI Gateway"/></a></div></div><div class="figure-title-wrap"><div class="figure-title"><span class="title-number">Figure 9.1: </span><span class="title-name">Ceph Cluster with a Single iSCSI Gateway </span><a title="Permalink" class="permalink" href="deploy-additional.html#id-1.3.4.7.2.5.3">#</a></div></div></div><p>
    <code class="systemitem">ceph-iscsi</code> is inherently highly-available and supports multipath operations.
    Thus, downstream initiator hosts can use multiple iSCSI gateways for both
    high availability and scalability. When communicating with an iSCSI
    configuration with more than one gateway, initiators may load-balance iSCSI
    requests across multiple gateways. In the event of a gateway failing, being
    temporarily unreachable, or being disabled for maintenance, I/O will
    transparently continue via another gateway.
   </p><div class="figure" id="id-1.3.4.7.2.5.5"><div class="figure-contents"><div class="mediaobject"><a href="images/lrbd_scheme2.png"><img src="images/lrbd_scheme2.png" width="75%" alt="Ceph cluster with multiple iSCSI gateways" title="Ceph cluster with multiple iSCSI gateways"/></a></div></div><div class="figure-title-wrap"><div class="figure-title"><span class="title-number">Figure 9.2: </span><span class="title-name">Ceph cluster with multiple iSCSI gateways </span><a title="Permalink" class="permalink" href="deploy-additional.html#id-1.3.4.7.2.5.5">#</a></div></div></div></section><section class="sect2" id="ceph-iscsi-deploy" data-id-title="Deployment considerations"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">9.1.3 </span><span class="title-name">Deployment considerations</span> <a title="Permalink" class="permalink" href="deploy-additional.html#ceph-iscsi-deploy">#</a></h3></div></div></div><p>
    A minimum configuration of SUSE Enterprise Storage 7 with <code class="systemitem">ceph-iscsi</code>
    consists of the following components:
   </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
      A Ceph storage cluster. The Ceph cluster consists of a minimum of
      four physical servers hosting at least eight object storage daemons
      (OSDs) each. In such a configuration, three OSD nodes also double as a
      monitor (MON) host.
     </p></li><li class="listitem"><p>
      An iSCSI target server running the LIO iSCSI target, configured via
      <code class="systemitem">ceph-iscsi</code>.
     </p></li><li class="listitem"><p>
      An iSCSI initiator host, running <code class="systemitem">open-iscsi</code>
      (Linux), the Microsoft iSCSI Initiator (Microsoft Windows), or any other compatible
      iSCSI initiator implementation.
     </p></li></ul></div><p>
    A recommended production configuration of SUSE Enterprise Storage 7
    with <code class="systemitem">ceph-iscsi</code> consists of:
   </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
      A Ceph storage cluster. A production Ceph cluster consists of any
      number of (typically more than 10) OSD nodes, each typically running
      10-12 object storage daemons (OSDs), with a minimum of three dedicated
      MON hosts.
     </p></li><li class="listitem"><p>
      Several iSCSI target servers running the LIO iSCSI target, configured via
      <code class="systemitem">ceph-iscsi</code>. For iSCSI failover and load-balancing, these servers must run
      a kernel supporting the <code class="systemitem">target_core_rbd</code> module.
      Update packages are available from the SUSE Linux Enterprise Server maintenance channel.
     </p></li><li class="listitem"><p>
      Any number of iSCSI initiator hosts, running
      <code class="systemitem">open-iscsi</code> (Linux), the Microsoft iSCSI
      Initiator (Microsoft Windows), or any other compatible iSCSI initiator
      implementation.
     </p></li></ul></div></section><section class="sect2" id="ceph-iscsi-install" data-id-title="Installation and configuration"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">9.1.4 </span><span class="title-name">Installation and configuration</span> <a title="Permalink" class="permalink" href="deploy-additional.html#ceph-iscsi-install">#</a></h3></div></div></div><p>
    This section describes steps to install and configure an iSCSI Gateway on top of
    SUSE Enterprise Storage.
   </p><section class="sect3" id="ceph-iscsi-install-igw-ceph-cluster" data-id-title="Deploy the iSCSI Gateway to a Ceph cluster"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">9.1.4.1 </span><span class="title-name">Deploy the iSCSI Gateway to a Ceph cluster</span> <a title="Permalink" class="permalink" href="deploy-additional.html#ceph-iscsi-install-igw-ceph-cluster">#</a></h4></div></div></div><p>
     The Ceph iSCSI Gateway deployment follows the same procedure as the deployment
     of other Ceph services—by means of cephadm. For more details, see
     <a class="xref" href="deploy-core.html#deploy-cephadm-day2-service-igw" title="8.3.5. Deploying iSCSI Gateways">Section 8.3.5, “Deploying iSCSI Gateways”</a>.
    </p></section><section class="sect3" id="ceph-iscsi-rbd-images" data-id-title="Creating RBD images"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">9.1.4.2 </span><span class="title-name">Creating RBD images</span> <a title="Permalink" class="permalink" href="deploy-additional.html#ceph-iscsi-rbd-images">#</a></h4></div></div></div><p>
     RBD images are created in the Ceph store and subsequently exported to
     iSCSI. We recommend that you use a dedicated RADOS pool for this purpose.
     You can create a volume from any host that is able to connect to your
     storage cluster using the Ceph <code class="command">rbd</code> command line
     utility. This requires the client to have at least a minimal
     <code class="filename">ceph.conf</code> configuration file, and appropriate CephX
     authentication credentials.
    </p><p>
     To create a new volume for subsequent export via iSCSI, use the
     <code class="command">rbd create</code> command, specifying the volume size in
     megabytes. For example, in order to create a 100 GB volume named
     <code class="literal">testvol</code> in the pool named
     <code class="literal">iscsi-images</code>, run:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>rbd --pool iscsi-images create --size=102400 <em class="replaceable">testvol</em></pre></div></section><section class="sect3" id="ceph-iscsi-rbd-export" data-id-title="Exporting RBD images via iSCSI"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">9.1.4.3 </span><span class="title-name">Exporting RBD images via iSCSI</span> <a title="Permalink" class="permalink" href="deploy-additional.html#ceph-iscsi-rbd-export">#</a></h4></div></div></div><p>
     To export RBD images via iSCSI, you can use either Ceph Dashboard Web
     interface or the <code class="systemitem">ceph-iscsi</code> gwcli utility. In this section, we will focus
     on gwcli only, demonstrating how to create an iSCSI target that exports
     an RBD image using the command line.
    </p><div id="id-1.3.4.7.2.7.5.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><div class="admon-title">Note</div><p>
      RBD images with the following properties cannot be exported via iSCSI:
     </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
        images with the <code class="option">journaling</code> feature enabled
       </p></li><li class="listitem"><p>
        images with a <code class="option">stripe unit</code> less than 4096 bytes
       </p></li></ul></div></div><p>
     As <code class="systemitem">root</code>, enter the iSCSI Gateway container:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt root"># </code>cephadm enter --name <em class="replaceable">CONTAINER_NAME</em></pre></div><p>
     As <code class="systemitem">root</code>, start the iSCSI Gateway command line interface:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt root"># </code>gwcli</pre></div><p>
     Go to <code class="literal">iscsi-targets</code> and create a target with the name
     <code class="literal">iqn.2003-01.org.linux-iscsi.iscsi.<em class="replaceable">SYSTEM-ARCH</em>:testvol</code>:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">gwcli &gt; </code> /&gt; cd /iscsi-targets
<code class="prompt user">gwcli &gt; </code> /iscsi-targets&gt; create iqn.2003-01.org.linux-iscsi.iscsi.<em class="replaceable">SYSTEM-ARCH</em>:testvol</pre></div><p>
     Create the iSCSI gateways by specifying the gateway
     <code class="literal">name</code> and <code class="literal">ip</code> address:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">gwcli &gt; </code> /iscsi-targets&gt; cd iqn.2003-01.org.linux-iscsi.iscsi.<em class="replaceable">SYSTEM-ARCH</em>:testvol/gateways
<code class="prompt user">gwcli &gt; </code> /iscsi-target...tvol/gateways&gt; create iscsi1 192.168.124.104
<code class="prompt user">gwcli &gt; </code> /iscsi-target...tvol/gateways&gt; create iscsi2 192.168.124.105</pre></div><div id="id-1.3.4.7.2.7.5.12" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg"/><div class="admon-title">Tip</div><p>
      Use the <code class="literal">help</code> command to show the list of available
      commands in the current configuration node.
     </p></div><p>
     Add the RBD image with the name <code class="literal">testvol</code> in the pool
     <code class="literal">iscsi-images</code>::
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">gwcli &gt; </code> /iscsi-target...tvol/gateways&gt; cd /disks
<code class="prompt user">gwcli &gt; </code> /disks&gt; attach iscsi-images/testvol</pre></div><p>
     Map the RBD image to the target:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">gwcli &gt; </code> /disks&gt; cd /iscsi-targets/iqn.2003-01.org.linux-iscsi.iscsi.<em class="replaceable">SYSTEM-ARCH</em>:testvol/disks
<code class="prompt user">gwcli &gt; </code> /iscsi-target...testvol/disks&gt; add iscsi-images/testvol</pre></div><div id="id-1.3.4.7.2.7.5.17" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><div class="admon-title">Note</div><p>
      You can use lower-level tools, such as <code class="command">targetcli</code>, to
      query the local configuration, but not to modify it.
     </p></div><div id="id-1.3.4.7.2.7.5.18" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg"/><div class="admon-title">Tip</div><p>
      You can use the <code class="command">ls</code> command to review the
      configuration. Some configuration nodes also support the
      <code class="command">info</code> command, which can be used to display more
      detailed information.
     </p></div><p>
     Note that, by default, ACL authentication is enabled so this target is not
     accessible yet. Check <a class="xref" href="deploy-additional.html#iscsi-lrbd-authentication" title="9.1.4.4. Authentication and access control">Section 9.1.4.4, “Authentication and access control”</a> for
     more information about authentication and access control.
    </p></section><section class="sect3" id="iscsi-lrbd-authentication" data-id-title="Authentication and access control"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">9.1.4.4 </span><span class="title-name">Authentication and access control</span> <a title="Permalink" class="permalink" href="deploy-additional.html#iscsi-lrbd-authentication">#</a></h4></div></div></div><p>
     iSCSI authentication is flexible and covers many authentication
     possibilities.
    </p><section class="sect4" id="iscsi-no-auth" data-id-title="Disabling ACL authentication"><div class="titlepage"><div><div><h5 class="title"><span class="title-number">9.1.4.4.1 </span><span class="title-name">Disabling ACL authentication</span> <a title="Permalink" class="permalink" href="deploy-additional.html#iscsi-no-auth">#</a></h5></div></div></div><p>
      <span class="emphasis"><em>No Authentication</em></span> means that any initiator will be
      able to access any LUNs on the corresponding target. You can enable
      <span class="emphasis"><em>No Authentication</em></span> by disabling the ACL
      authentication:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">gwcli &gt; </code> /&gt; cd /iscsi-targets/iqn.2003-01.org.linux-iscsi.iscsi.<em class="replaceable">SYSTEM-ARCH</em>:testvol/hosts
<code class="prompt user">gwcli &gt; </code> /iscsi-target...testvol/hosts&gt; auth disable_acl</pre></div></section><section class="sect4" id="iscsi-acl-auth" data-id-title="Using ACL authentication"><div class="titlepage"><div><div><h5 class="title"><span class="title-number">9.1.4.4.2 </span><span class="title-name">Using ACL authentication</span> <a title="Permalink" class="permalink" href="deploy-additional.html#iscsi-acl-auth">#</a></h5></div></div></div><p>
      When using initiator-name-based ACL authentication, only the defined
      initiators are allowed to connect. You can define an initiator by doing:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">gwcli &gt; </code> /&gt; cd /iscsi-targets/iqn.2003-01.org.linux-iscsi.iscsi.<em class="replaceable">SYSTEM-ARCH</em>:testvol/hosts
<code class="prompt user">gwcli &gt; </code> /iscsi-target...testvol/hosts&gt; create iqn.1996-04.de.suse:01:e6ca28cc9f20</pre></div><p>
      Defined initiators will be able to connect, but will only have access to
      the RBD images that were explicitly added to the initiator:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">gwcli &gt; </code> /iscsi-target...:e6ca28cc9f20&gt; disk add rbd/testvol</pre></div></section><section class="sect4" id="chap-auth-password" data-id-title="Enabling CHAP authentication"><div class="titlepage"><div><div><h5 class="title"><span class="title-number">9.1.4.4.3 </span><span class="title-name">Enabling CHAP authentication</span> <a title="Permalink" class="permalink" href="deploy-additional.html#chap-auth-password">#</a></h5></div></div></div><p>
      In addition to the ACL, you can enable CHAP authentication by specifying
      a user name and password for each initiator:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">gwcli &gt; </code> /&gt; cd /iscsi-targets/iqn.2003-01.org.linux-iscsi.iscsi.<em class="replaceable">SYSTEM-ARCH</em>:testvol/hosts/iqn.1996-04.de.suse:01:e6ca28cc9f20
<code class="prompt user">gwcli &gt; </code> /iscsi-target...:e6ca28cc9f20&gt; auth username=common12 password=pass12345678</pre></div><div id="id-1.3.4.7.2.7.6.5.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><div class="admon-title">Note</div><p>
       User names must have a length of 8 to 64 characters and can contain
       alphanumeric characters, <code class="literal">.</code>, <code class="literal">@</code>,
       <code class="literal">-</code>, <code class="literal">_</code> or <code class="literal">:</code>.
      </p><p>
       Passwords must have a length of 12 to 16 characters and can contain
       alphanumeric characters, <code class="literal">@</code>, <code class="literal">-</code>,
       <code class="literal">_</code> or <code class="literal">/</code>..
      </p></div><p>
      Optionally, you can also enable CHAP mutual authentication by specifying
      the <code class="option">mutual_username</code> and <code class="option">mutual_password</code>
      parameters in the <code class="command">auth</code> command.
     </p></section><section class="sect4" id="iscsi-discovery-mutual-auth" data-id-title="Configuring discovery and mutual authentication"><div class="titlepage"><div><div><h5 class="title"><span class="title-number">9.1.4.4.4 </span><span class="title-name">Configuring discovery and mutual authentication</span> <a title="Permalink" class="permalink" href="deploy-additional.html#iscsi-discovery-mutual-auth">#</a></h5></div></div></div><p>
      <span class="emphasis"><em>Discovery authentication</em></span> is independent of the
      previous authentication methods. It requires credentials for browsing, it
      is optional, and can be configured by:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">gwcli &gt; </code> /&gt; cd /iscsi-targets
<code class="prompt user">gwcli &gt; </code> /iscsi-targets&gt; discovery_auth username=du123456 password=dp1234567890</pre></div><div id="id-1.3.4.7.2.7.6.6.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><div class="admon-title">Note</div><p>
       User names must have a length of 8 to 64 characters and can only contain
       letters, <code class="literal">.</code>, <code class="literal">@</code>,
       <code class="literal">-</code>, <code class="literal">_</code> or <code class="literal">:</code>.
      </p><p>
       Passwords must have a length of 12 to 16 characters and can only contain
       letters, <code class="literal">@</code>, <code class="literal">-</code>,
       <code class="literal">_</code> or <code class="literal">/</code>.
      </p></div><p>
      Optionally, you can also specify the <code class="option">mutual_username</code> and
      <code class="option">mutual_password</code> parameters in the
      <code class="command">discovery_auth</code> command.
     </p><p>
      Discovery authentication can be disabled by using the following command:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">gwcli &gt; </code> /iscsi-targets&gt; discovery_auth nochap</pre></div></section></section><section class="sect3" id="ceph-iscsi-rbd-advanced" data-id-title="Configuring advanced settings"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">9.1.4.5 </span><span class="title-name">Configuring advanced settings</span> <a title="Permalink" class="permalink" href="deploy-additional.html#ceph-iscsi-rbd-advanced">#</a></h4></div></div></div><p>
     <code class="systemitem">ceph-iscsi</code> can be configured with advanced parameters which are
     subsequently passed on to the LIO I/O target. The parameters are divided
     up into <code class="literal">target</code> and <code class="literal">disk</code> parameters.
    </p><div id="id-1.3.4.7.2.7.7.3" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.svg"/><div class="admon-title">Warning</div><p>
      Unless otherwise noted, changing these parameters from the default
      setting is not recommended.
     </p></div><section class="sect4" id="iscsi-target-settings" data-id-title="Viewing target settings"><div class="titlepage"><div><div><h5 class="title"><span class="title-number">9.1.4.5.1 </span><span class="title-name">Viewing target settings</span> <a title="Permalink" class="permalink" href="deploy-additional.html#iscsi-target-settings">#</a></h5></div></div></div><p>
      You can view the value of these settings by using the
      <code class="command">info</code> command:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">gwcli &gt; </code> /&gt; cd /iscsi-targets/iqn.2003-01.org.linux-iscsi.iscsi.<em class="replaceable">SYSTEM-ARCH</em>:testvol
<code class="prompt user">gwcli &gt; </code> /iscsi-target...i.<em class="replaceable">SYSTEM-ARCH</em>:testvol&gt; info</pre></div><p>
      And change a setting using the <code class="command">reconfigure</code> command:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">gwcli &gt; </code> /iscsi-target...i.<em class="replaceable">SYSTEM-ARCH</em>:testvol&gt; reconfigure login_timeout 20</pre></div><p>
      The available <code class="literal">target</code> settings are:
     </p><div class="variablelist"><dl class="variablelist"><dt id="id-1.3.4.7.2.7.7.4.7.1"><span class="term">default_cmdsn_depth</span></dt><dd><p>
         Default CmdSN (Command Sequence Number) depth. Limits the amount of
         requests that an iSCSI initiator can have outstanding at any moment.
        </p></dd><dt id="id-1.3.4.7.2.7.7.4.7.2"><span class="term">default_erl</span></dt><dd><p>
         Default error recovery level.
        </p></dd><dt id="id-1.3.4.7.2.7.7.4.7.3"><span class="term">login_timeout</span></dt><dd><p>
         Login timeout value in seconds.
        </p></dd><dt id="id-1.3.4.7.2.7.7.4.7.4"><span class="term">netif_timeout</span></dt><dd><p>
         NIC failure timeout in seconds.
        </p></dd><dt id="id-1.3.4.7.2.7.7.4.7.5"><span class="term">prod_mode_write_protect</span></dt><dd><p>
         If set to <code class="literal">1</code>, prevents writes to LUNs.
        </p></dd></dl></div></section><section class="sect4" id="iscsi-disk-settings" data-id-title="Viewing disk settings"><div class="titlepage"><div><div><h5 class="title"><span class="title-number">9.1.4.5.2 </span><span class="title-name">Viewing disk settings</span> <a title="Permalink" class="permalink" href="deploy-additional.html#iscsi-disk-settings">#</a></h5></div></div></div><p>
      You can view the value of these settings by using the
      <code class="command">info</code> command:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">gwcli &gt; </code> /&gt; cd /disks/rbd/testvol
<code class="prompt user">gwcli &gt; </code> /disks/rbd/testvol&gt; info</pre></div><p>
      And change a setting using the <code class="command">reconfigure</code> command:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">gwcli &gt; </code> /disks/rbd/testvol&gt; reconfigure rbd/testvol emulate_pr 0</pre></div><p>
      The available <code class="literal">disk</code> settings are:
     </p><div class="variablelist"><dl class="variablelist"><dt id="id-1.3.4.7.2.7.7.5.7.1"><span class="term">block_size</span></dt><dd><p>
         Block size of the underlying device.
        </p></dd><dt id="id-1.3.4.7.2.7.7.5.7.2"><span class="term">emulate_3pc</span></dt><dd><p>
         If set to <code class="literal">1</code>, enables Third Party Copy.
        </p></dd><dt id="id-1.3.4.7.2.7.7.5.7.3"><span class="term">emulate_caw</span></dt><dd><p>
         If set to <code class="literal">1</code>, enables Compare and Write.
        </p></dd><dt id="id-1.3.4.7.2.7.7.5.7.4"><span class="term">emulate_dpo</span></dt><dd><p>
         If set to 1, turns on Disable Page Out.
        </p></dd><dt id="id-1.3.4.7.2.7.7.5.7.5"><span class="term">emulate_fua_read</span></dt><dd><p>
         If set to <code class="literal">1</code>, enables Force Unit Access read.
        </p></dd><dt id="id-1.3.4.7.2.7.7.5.7.6"><span class="term">emulate_fua_write</span></dt><dd><p>
         If set to <code class="literal">1</code>, enables Force Unit Access write.
        </p></dd><dt id="id-1.3.4.7.2.7.7.5.7.7"><span class="term">emulate_model_alias</span></dt><dd><p>
         If set to <code class="literal">1</code>, uses the back-end device name for the
         model alias.
        </p></dd><dt id="id-1.3.4.7.2.7.7.5.7.8"><span class="term">emulate_pr</span></dt><dd><p>
         If set to 0, support for SCSI Reservations, including Persistent Group
         Reservations, is disabled. While disabled, the SES iSCSI Gateway can
         ignore reservation state, resulting in improved request latency.
        </p><div id="id-1.3.4.7.2.7.7.5.7.8.2.2" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg"/><div class="admon-title">Tip</div><p>
          Setting <code class="literal">backstore_emulate_pr</code> to
          <code class="literal">0</code> is recommended if iSCSI initiators do not
          require SCSI Reservation support.
         </p></div></dd><dt id="id-1.3.4.7.2.7.7.5.7.9"><span class="term">emulate_rest_reord</span></dt><dd><p>
         If set to <code class="literal">0</code>, the Queue Algorithm Modifier has
         Restricted Reordering.
        </p></dd><dt id="id-1.3.4.7.2.7.7.5.7.10"><span class="term">emulate_tas</span></dt><dd><p>
         If set to <code class="literal">1</code>, enables Task Aborted Status.
        </p></dd><dt id="id-1.3.4.7.2.7.7.5.7.11"><span class="term">emulate_tpu</span></dt><dd><p>
         If set to <code class="literal">1</code>, enables Thin Provisioning Unmap.
        </p></dd><dt id="id-1.3.4.7.2.7.7.5.7.12"><span class="term">emulate_tpws</span></dt><dd><p>
         If set to <code class="literal">1</code>, enables Thin Provisioning Write Same.
        </p></dd><dt id="id-1.3.4.7.2.7.7.5.7.13"><span class="term">emulate_ua_intlck_ctrl</span></dt><dd><p>
         If set to <code class="literal">1</code>, enables Unit Attention Interlock.
        </p></dd><dt id="id-1.3.4.7.2.7.7.5.7.14"><span class="term">emulate_write_cache</span></dt><dd><p>
         If set to <code class="literal">1</code>, turns on Write Cache Enable.
        </p></dd><dt id="id-1.3.4.7.2.7.7.5.7.15"><span class="term">enforce_pr_isids</span></dt><dd><p>
         If set to <code class="literal">1</code>, enforces persistent reservation ISIDs.
        </p></dd><dt id="id-1.3.4.7.2.7.7.5.7.16"><span class="term">is_nonrot</span></dt><dd><p>
         If set to <code class="literal">1</code>, the backstore is a non-rotational
         device.
        </p></dd><dt id="id-1.3.4.7.2.7.7.5.7.17"><span class="term">max_unmap_block_desc_count</span></dt><dd><p>
         Maximum number of block descriptors for UNMAP.
        </p></dd><dt id="id-1.3.4.7.2.7.7.5.7.18"><span class="term">max_unmap_lba_count:</span></dt><dd><p>
         Maximum number of LBAs for UNMAP.
        </p></dd><dt id="id-1.3.4.7.2.7.7.5.7.19"><span class="term">max_write_same_len</span></dt><dd><p>
         Maximum length for WRITE_SAME.
        </p></dd><dt id="id-1.3.4.7.2.7.7.5.7.20"><span class="term">optimal_sectors</span></dt><dd><p>
         Optimal request size in sectors.
        </p></dd><dt id="id-1.3.4.7.2.7.7.5.7.21"><span class="term">pi_prot_type</span></dt><dd><p>
         DIF protection type.
        </p></dd><dt id="id-1.3.4.7.2.7.7.5.7.22"><span class="term">queue_depth</span></dt><dd><p>
         Queue depth.
        </p></dd><dt id="id-1.3.4.7.2.7.7.5.7.23"><span class="term">unmap_granularity</span></dt><dd><p>
         UNMAP granularity.
        </p></dd><dt id="id-1.3.4.7.2.7.7.5.7.24"><span class="term">unmap_granularity_alignment</span></dt><dd><p>
         UNMAP granularity alignment.
        </p></dd><dt id="id-1.3.4.7.2.7.7.5.7.25"><span class="term">force_pr_aptpl</span></dt><dd><p>
         When enabled, LIO will always write out the <span class="emphasis"><em>persistent
         reservation</em></span> state to persistent storage, regardless of
         whether the client has requested it via <code class="option">aptpl=1</code>. This
         has no effect with the kernel RBD back-end for LIO—it always
         persists PR state. Ideally, the <code class="option">target_core_rbd</code>
         option should force it to '1' and throw an error if someone tries to
         disable it via configuration.
        </p></dd><dt id="id-1.3.4.7.2.7.7.5.7.26"><span class="term">unmap_zeroes_data</span></dt><dd><p>
         Affects whether LIO will advertise LBPRZ to SCSI initiators,
         indicating that zeros will be read back from a region following UNMAP
         or WRITE SAME with an unmap bit.
        </p></dd></dl></div></section></section></section><section class="sect2" id="iscsi-tcmu" data-id-title="Exporting RADOS Block Device images using tcmu-runner"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">9.1.5 </span><span class="title-name">Exporting RADOS Block Device images using <code class="systemitem">tcmu-runner</code></span> <a title="Permalink" class="permalink" href="deploy-additional.html#iscsi-tcmu">#</a></h3></div></div></div><p>
    The <code class="systemitem">ceph-iscsi</code> supports both <code class="option">rbd</code> (kernel-based) and
    <code class="option">user:rbd</code> (tcmu-runner) backstores, making all the
    management transparent and independent of the backstore.
   </p><div id="id-1.3.4.7.2.8.3" data-id-title="Technology preview" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.svg"/><div class="admon-title">Warning: Technology preview</div><p>
     <code class="systemitem">tcmu-runner</code> based iSCSI Gateway deployments are currently
     a technology preview.
    </p></div><p>
    Unlike kernel-based iSCSI Gateway deployments, <code class="systemitem">tcmu-runner</code>
    based iSCSI Gateways do not offer support for multipath I/O or SCSI Persistent
    Reservations.
   </p><p>
    To export an RADOS Block Device image using <code class="systemitem">tcmu-runner</code>, all
    you need to do is specify the <code class="option">user:rbd</code> backstore when
    attaching the disk:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">gwcli &gt; </code> /disks&gt; attach rbd/testvol backstore=user:rbd</pre></div><div id="id-1.3.4.7.2.8.7" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><div class="admon-title">Note</div><p>
     When using <code class="systemitem">tcmu-runner</code>, the exported RBD image
     must have the <code class="option">exclusive-lock</code> feature enabled.
    </p></div></section></section></section><nav class="bottom-pagination"><div><a class="pagination-link prev" href="deploy-core.html"><span class="pagination-relation">Previous</span><span class="pagination-label"><span class="title-number">Chapter 8 </span>Deploying the remaining core services using cephadm</span></a> </div><div><a class="pagination-link next" href="ses-upgrade.html"><span class="pagination-relation">Next</span><span class="pagination-label"><span class="title-number">Part III </span>Upgrading from Previous Releases</span></a> </div></nav></article><aside id="_side-toc-page" class="side-toc"><div class="side-title">On this page</div><div class="toc"><ul><li><span class="sect1"><a href="deploy-additional.html#cha-ceph-as-iscsi"><span class="title-number">9.1 </span><span class="title-name">Installation of iSCSI gateway</span></a></span></li></ul></div><div class="side-title">Give feedback</div><ul class="feedback" id="_give-feedback"><li><a id="_feedback-editurl" href="https://github.com/SUSE/doc-ses/edit/main/xml/deploy_additional.xml" rel="nofollow" target="_blank">Edit source document</a></li></ul><div class="side-title">Share this page</div><ul class="share"><li><a id="_share-fb" href="#" title="Facebook"> </a></li><li><a id="_share-in" href="#" title="LinkedIn"> </a></li><li><a id="_share-tw" href="#" title="Twitter"> </a></li><li><a id="_share-mail" href="#" title="E-Mail"> </a></li><li><a id="_print-button" href="#" title="Print this page"> </a></li></ul> </aside></main><footer id="_footer"><div class="growth-inhibitor"><div class="copy"><span class="copy__rights">© SUSE
                 2022</span></div></div></footer></body></html>