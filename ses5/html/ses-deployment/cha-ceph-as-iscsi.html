<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes"/><title>Installation of iSCSI Gateway | Deployment Guide | SUSE Enterprise Storage 5.5 (SES 5 &amp; SES 5.5)</title><link rel="stylesheet" type="text/css" href="static/css/style.css"/>
<meta name="title" content="Installation of iSCSI Gateway | SES 5.5 (SES 5 &amp; SES 5…"/>
<meta name="description" content="iSCSI is a storage area network (SAN) protocol that allows clients (called initiators) to send SCSI commands to SCSI storage devices (targets) on remote server…"/>
<meta name="product-name" content="SUSE Enterprise Storage"/>
<meta name="product-number" content="5.5 (SES 5 &amp; SES 5.5)"/>
<meta name="book-title" content="Deployment Guide"/>
<meta name="chapter-title" content="Chapter 10. Installation of iSCSI Gateway"/>
<meta name="tracker-url" content="https://bugzilla.suse.com/enter_bug.cgi"/>
<meta name="tracker-type" content="bsc"/>
<meta name="tracker-bsc-assignee" content="tbazant@suse.com"/>
<meta name="tracker-bsc-component" content="Documentation"/>
<meta name="tracker-bsc-product" content="SUSE Enterprise Storage 5"/>
<meta property="og:title" content="Installation of iSCSI Gateway | SES 5.5 (SES 5 &amp; SES 5…"/>
<meta property="og:description" content="iSCSI is a storage area network (SAN) protocol that allows clients (called initiators) to send SCSI commands to SCSI storage devices (targets) on remote server…"/>
<meta property="og:type" content="article"/>
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Installation of iSCSI Gateway | SES 5.5 (SES 5 &amp; SES 5…"/>
<meta name="twitter:description" content="iSCSI is a storage area network (SAN) protocol that allows clients (called initiators) to send SCSI commands to SCSI storage devices (targets) on remote server…"/>
<link rel="prev" href="cha-ceph-additional-software-installation.html" title="Chapter 9. Ceph Object Gateway"/><link rel="next" href="cha-ceph-as-cephfs.html" title="Chapter 11. Installation of CephFS"/>
<script type="text/javascript">

if ( window.location.protocol.toLowerCase() != 'file:' ) {
  document.write('<link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css"></link>');
};

</script><noscript><link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css"/></noscript><script src="static/js/jquery-1.10.2.min.js" type="text/javascript"> </script><script src="static/js/script.js" type="text/javascript"> </script><script src="static/js/highlight.min.js" type="text/javascript"> </script><script>

$(document).ready(function() {
  $('.verbatim-wrap.highlight').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});
hljs.configure({
  useBR: false
});

</script></head><body class="draft wide offline js-off" onload="$('#betawarn-button-wrap').toggle();if (document.cookie.length > 0) {if (document.cookie.indexOf('betawarn=closed') != -1){$('#betawarn').toggle()}};"><div id="betawarn" style="position:fixed;bottom:0;z-index:9025;background-color:#FDE8E8;padding:1em;margin-left:10%;margin-right:10%;display:block;border-top:.75em solid #E11;width:80%"><p style="color:#333;margin:1em 0;padding:0;">This is a draft document that was built and uploaded automatically. It may document beta software and be incomplete or even incorrect. <strong>Use this document at your own risk.</strong></p> <div id="betawarn-button-wrap" style="display:none;margin:0;padding:0;"><a href="#" onclick="$('#betawarn').toggle();var d=new Date();d.setTime(d.getTime()+(0.5*24*60*60*1000));document.cookie='betawarn=closed; expires='+d.toUTCString()+'; path=/'; return false;" style="color:#333;text-decoration:underline;float:left;margin-top:.5em;padding:1em;display:block;background-color:#FABEBE;">I understand this is a draft</a></div></div><div class="bypass-block"><a href="#_content">Jump to content</a><a href="#_bottom-pagination">Jump to page navigation: previous page [access key p]/next page [access key n]</a></div><header id="_mainnav"><div class="growth-inhibitor"><img src="static/images/logo.svg" alt="Logo" class="logo"/></div></header><div class="crumbs"><div class="growth-inhibitor"><a class="crumb" href="index.html">Deployment Guide</a><span> / </span><a class="crumb" href="additional-software.html">Installation of Additional Services</a><span> / </span><a class="crumb" href="cha-ceph-as-iscsi.html">Installation of iSCSI Gateway</a></div></div><main id="_content"><nav id="_side-toc-overall" class="side-toc"><div class="side-title">Deployment Guide</div><ol><li><a href="bk02pr01.html" class=" "><span class="title-number"> </span><span class="title-name">About This Guide</span></a></li><li><a href="part-ses.html" class="has-children "><span class="title-number">I </span><span class="title-name">SUSE Enterprise Storage</span></a><ol><li><a href="cha-storage-about.html" class=" "><span class="title-number">1 </span><span class="title-name">SUSE Enterprise Storage 5.5 and Ceph</span></a></li><li><a href="storage-bp-hwreq.html" class=" "><span class="title-number">2 </span><span class="title-name">Hardware Requirements and Recommendations</span></a></li><li><a href="cha-admin-ha.html" class=" "><span class="title-number">3 </span><span class="title-name">Ceph Admin Node HA Setup</span></a></li></ol></li><li><a href="ses-deployment.html" class="has-children "><span class="title-number">II </span><span class="title-name">Cluster Deployment and Upgrade</span></a><ol><li><a href="ceph-install-saltstack.html" class=" "><span class="title-number">4 </span><span class="title-name">Deploying with DeepSea/Salt</span></a></li><li><a href="cha-ceph-upgrade.html" class=" "><span class="title-number">5 </span><span class="title-name">Upgrading from Previous Releases</span></a></li><li><a href="cha-deployment-backup.html" class=" "><span class="title-number">6 </span><span class="title-name">Backing Up the Cluster Configuration</span></a></li><li><a href="ceph-deploy-ds-custom.html" class=" "><span class="title-number">7 </span><span class="title-name">Customizing the Default Configuration</span></a></li></ol></li><li class="active"><a href="additional-software.html" class="has-children you-are-here"><span class="title-number">III </span><span class="title-name">Installation of Additional Services</span></a><ol><li><a href="cha-ceph-as-intro.html" class=" "><span class="title-number">8 </span><span class="title-name">Installation of Services to Access your Data</span></a></li><li><a href="cha-ceph-additional-software-installation.html" class=" "><span class="title-number">9 </span><span class="title-name">Ceph Object Gateway</span></a></li><li><a href="cha-ceph-as-iscsi.html" class=" you-are-here"><span class="title-number">10 </span><span class="title-name">Installation of iSCSI Gateway</span></a></li><li><a href="cha-ceph-as-cephfs.html" class=" "><span class="title-number">11 </span><span class="title-name">Installation of CephFS</span></a></li><li><a href="cha-as-ganesha.html" class=" "><span class="title-number">12 </span><span class="title-name">Installation of NFS Ganesha</span></a></li><li><a href="cha-ses-cifs.html" class=" "><span class="title-number">13 </span><span class="title-name">Exporting Ceph Data via Samba</span></a></li></ol></li><li><a href="ap-deploy-docupdate.html" class=" "><span class="title-number">A </span><span class="title-name">Documentation Updates</span></a></li> </ol> </nav><button id="_open-side-toc-overall" title="Contents"> </button><article class="documentation"><button id="_unfold-side-toc-page">On this page</button><section class="chapter" id="cha-ceph-as-iscsi" data-id-title="Installation of iSCSI Gateway"><div class="titlepage"><div><div class="version-info">Applies to  <span class="productname">SUSE Enterprise Storage</span> <span class="productnumber">5.5 (SES 5 &amp; SES 5.5)</span></div><div><h2 class="title"><span class="title-number">10 </span><span class="title-name">Installation of iSCSI Gateway</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#">#</a></h2></div></div></div><p>
  iSCSI is a storage area network (SAN) protocol that allows clients (called
  <span class="emphasis"><em>initiators</em></span>) to send SCSI commands to SCSI storage
  devices (<span class="emphasis"><em>targets</em></span>) on remote servers. SUSE Enterprise Storage
  5.5 includes a facility that opens Ceph storage management to
  heterogeneous clients, such as Microsoft Windows* and VMware* vSphere, through the
  iSCSI protocol. Multipath iSCSI access enables availability and scalability
  for these clients, and the standardized iSCSI protocol also provides an
  additional layer of security isolation between clients and the SUSE Enterprise Storage
  5.5 cluster. The configuration facility is named
  <code class="systemitem">lrbd</code>. Using <code class="systemitem">lrbd</code>, Ceph
  storage administrators can define thin-provisioned, replicated,
  highly-available volumes supporting read-only snapshots, read-write clones,
  and automatic resizing with Ceph RADOS Block Device (RBD). Administrators
  can then export volumes either via a single <code class="systemitem">lrbd</code>
  gateway host, or via multiple gateway hosts supporting multipath failover.
  Linux, Microsoft Windows, and VMware hosts can connect to volumes using the iSCSI
  protocol, which makes them available like any other SCSI block device. This
  means SUSE Enterprise Storage 5.5 customers can effectively run a complete
  block-storage infrastructure subsystem on Ceph that provides all the
  features and benefits of a conventional SAN, enabling future growth.
 </p><p>
  This chapter introduces detailed information to set up a Ceph cluster
  infrastructure together with an iSCSI gateway so that the client hosts can
  use remotely stored data as local storage devices using the iSCSI protocol.
 </p><section class="sect1" id="ceph-iscsi-iscsi" data-id-title="iSCSI Block Storage"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">10.1 </span><span class="title-name">iSCSI Block Storage</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#ceph-iscsi-iscsi">#</a></h2></div></div></div><p>
   iSCSI is an implementation of the Small Computer System Interface (SCSI)
   command set using the Internet Protocol (IP), specified in RFC 3720. iSCSI
   is implemented as a service where a client (the initiator) talks to a server
   (the target) via a session on TCP port 3260. An iSCSI target's IP address
   and port are called an iSCSI portal, where a target can be exposed through
   one or more portals. The combination of a target and one or more portals is
   called the target portal group (TPG).
  </p><p>
   The underlying data link layer protocol for iSCSI is commonly Ethernet. More
   specifically, modern iSCSI infrastructures use 10 Gigabit Ethernet or faster
   networks for optimal throughput. 10 Gigabit Ethernet connectivity between
   the iSCSI gateway and the back-end Ceph cluster is strongly recommended.
  </p><section class="sect2" id="ceph-iscsi-iscsi-target" data-id-title="The Linux Kernel iSCSI Target"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">10.1.1 </span><span class="title-name">The Linux Kernel iSCSI Target</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#ceph-iscsi-iscsi-target">#</a></h3></div></div></div><p>
    The Linux kernel iSCSI target was originally named LIO for linux-iscsi.org,
    the project's original domain and Web site. For some time, no fewer than
    four competing iSCSI target implementations were available for the Linux
    platform, but LIO ultimately prevailed as the single iSCSI reference
    target. The mainline kernel code for LIO uses the simple, but somewhat
    ambiguous name "target", distinguishing between "target core" and a variety
    of front-end and back-end target modules.
   </p><p>
    The most commonly used front-end module is arguably iSCSI. However, LIO
    also supports Fibre Channel (FC), Fibre Channel over Ethernet (FCoE) and
    several other front-end protocols. At this time, only the iSCSI protocol is
    supported by SUSE Enterprise Storage.
   </p><p>
    The most frequently used target back-end module is one that is capable of
    simply re-exporting any available block device on the target host. This
    module is named iblock. However, LIO also has an RBD-specific back-end
    module supporting parallelized multipath I/O access to RBD images.
   </p></section><section class="sect2" id="ceph-iscsi-iscsi-initiators" data-id-title="iSCSI Initiators"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">10.1.2 </span><span class="title-name">iSCSI Initiators</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#ceph-iscsi-iscsi-initiators">#</a></h3></div></div></div><p>
    This section introduces brief information on iSCSI initiators used on
    Linux, Microsoft Windows, and VMware platforms.
   </p><section class="sect3" id="id-1.4.5.4.5.5.3" data-id-title="Linux"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">10.1.2.1 </span><span class="title-name">Linux</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#id-1.4.5.4.5.5.3">#</a></h4></div></div></div><p>
     The standard initiator for the Linux platform is
     <code class="systemitem">open-iscsi</code>. <code class="systemitem">open-iscsi</code>
     launches a daemon, <code class="systemitem">iscsid</code>, which the user can
     then use to discover iSCSI targets on any given portal, log in to targets,
     and map iSCSI volumes. <code class="systemitem">iscsid</code> communicates with
     the SCSI mid layer to create in-kernel block devices that the kernel can
     then treat like any other SCSI block device on the system. The
     <code class="systemitem">open-iscsi</code> initiator can be deployed in
     conjunction with the Device Mapper Multipath
     (<code class="systemitem">dm-multipath</code>) facility to provide a highly
     available iSCSI block device.
    </p></section><section class="sect3" id="id-1.4.5.4.5.5.4" data-id-title="Microsoft Windows and Hyper-V"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">10.1.2.2 </span><span class="title-name">Microsoft Windows and Hyper-V</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#id-1.4.5.4.5.5.4">#</a></h4></div></div></div><p>
     The default iSCSI initiator for the Microsoft Windows operating system is the
     Microsoft iSCSI initiator. The iSCSI service can be configured via a
     graphical user interface (GUI), and supports multipath I/O for high
     availability.
    </p></section><section class="sect3" id="id-1.4.5.4.5.5.5" data-id-title="VMware"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">10.1.2.3 </span><span class="title-name">VMware</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#id-1.4.5.4.5.5.5">#</a></h4></div></div></div><p>
     The default iSCSI initiator for VMware vSphere and ESX is the VMware
     ESX software iSCSI initiator, <code class="systemitem">vmkiscsi</code>. When
     enabled, it can be configured either from the vSphere client, or using the
     <code class="command">vmkiscsi-tool</code> command. You can then format storage
     volumes connected through the vSphere iSCSI storage adapter with VMFS, and
     use them like any other VM storage device. The VMware initiator also
     supports multipath I/O for high availability.
    </p></section></section></section><section class="sect1" id="ceph-iscsi-lrbd" data-id-title="General Information about lrbd"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">10.2 </span><span class="title-name">General Information about lrbd</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#ceph-iscsi-lrbd">#</a></h2></div></div></div><p>
   <code class="systemitem">lrbd</code> combines the benefits of RADOS Block Devices
   with the ubiquitous versatility of iSCSI. By employing
   <code class="systemitem">lrbd</code> on an iSCSI target host (known as the
   <code class="systemitem">lrbd</code> gateway), any application that needs to make
   use of block storage can benefit from Ceph, even if it does not speak any
   Ceph client protocol. Instead, users can use iSCSI or any other target
   front-end protocol to connect to an LIO target, which translates all target
   I/O to RBD storage operations.
  </p><div class="figure" id="id-1.4.5.4.6.3"><div class="figure-contents"><div class="mediaobject"><a href="images/lrbd_scheme1.png" target="_blank"><img src="images/lrbd_scheme1.png" width="" alt="Ceph Cluster with a Single iSCSI Gateway"/></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="title-number">Figure 10.1: </span><span class="title-name">Ceph Cluster with a Single iSCSI Gateway </span><a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#id-1.4.5.4.6.3">#</a></h6></div></div><p>
   <code class="systemitem">lrbd</code> is inherently highly-available and supports
   multipath operations. Thus, downstream initiator hosts can use multiple
   iSCSI gateways for both high availability and scalability. When
   communicating with an iSCSI configuration with more than one gateway,
   initiators may load-balance iSCSI requests across multiple gateways. In the
   event of a gateway failing, being temporarily unreachable, or being disabled
   for maintenance, I/O will transparently continue via another gateway.
  </p><div class="figure" id="id-1.4.5.4.6.5"><div class="figure-contents"><div class="mediaobject"><a href="images/lrbd_scheme2.png" target="_blank"><img src="images/lrbd_scheme2.png" width="" alt="Ceph Cluster with Multiple iSCSI Gateways"/></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="title-number">Figure 10.2: </span><span class="title-name">Ceph Cluster with Multiple iSCSI Gateways </span><a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#id-1.4.5.4.6.5">#</a></h6></div></div></section><section class="sect1" id="ceph-iscsi-deploy" data-id-title="Deployment Considerations"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">10.3 </span><span class="title-name">Deployment Considerations</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#ceph-iscsi-deploy">#</a></h2></div></div></div><p>
   A minimum configuration of SUSE Enterprise Storage 5.5 with
   <code class="systemitem">lrbd</code> consists of the following components:
  </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
     A Ceph storage cluster. The Ceph cluster consists of a minimum of four
     physical servers hosting at least eight object storage daemons (OSDs)
     each. In such a configuration, three OSD nodes also double as a monitor
     (MON) host.
    </p></li><li class="listitem"><p>
     An iSCSI target server running the LIO iSCSI target, configured via
     <code class="systemitem">lrbd</code>.
    </p></li><li class="listitem"><p>
     An iSCSI initiator host, running <code class="systemitem">open-iscsi</code>
     (Linux), the Microsoft iSCSI Initiator (Microsoft Windows), or any other compatible
     iSCSI initiator implementation.
    </p></li></ul></div><p>
   A recommended production configuration of SUSE Enterprise Storage 5.5 with
   <code class="systemitem">lrbd</code> consists of:
  </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
     A Ceph storage cluster. A production Ceph cluster consists of any
     number of (typically more than 10) OSD nodes, each typically running 10-12
     object storage daemons (OSDs), with no fewer than three dedicated MON
     hosts.
    </p></li><li class="listitem"><p>
     Several iSCSI target servers running the LIO iSCSI target, configured via
     <code class="systemitem">lrbd</code>. For iSCSI fail-over and load-balancing,
     these servers must run a kernel supporting the
     <code class="systemitem">target_core_rbd</code> module. Update packages are
     available from the SUSE Linux Enterprise Server maintenance channel.
    </p></li><li class="listitem"><p>
     Any number of iSCSI initiator hosts, running
     <code class="systemitem">open-iscsi</code> (Linux), the Microsoft iSCSI Initiator
     (Microsoft Windows), or any other compatible iSCSI initiator implementation.
    </p></li></ul></div></section><section class="sect1" id="ceph-iscsi-install" data-id-title="Installation and Configuration"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">10.4 </span><span class="title-name">Installation and Configuration</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#ceph-iscsi-install">#</a></h2></div></div></div><p>
   This section describes steps to install and configure an iSCSI Gateway on top of
   SUSE Enterprise Storage.
  </p><section class="sect2" id="id-1.4.5.4.8.3" data-id-title="Deploy the iSCSI Gateway to a Ceph Cluster"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">10.4.1 </span><span class="title-name">Deploy the iSCSI Gateway to a Ceph Cluster</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#id-1.4.5.4.8.3">#</a></h3></div></div></div><p>
    You can deploy the iSCSI Gateway either during Ceph cluster deployment process,
    or add it to an existing cluster using DeepSea.
   </p><p>
    To include the iSCSI Gateway during the cluster deployment process, refer to
    <a class="xref" href="ceph-install-saltstack.html#policy-role-assignment" title="4.5.1.2. Role Assignment">Section 4.5.1.2, “Role Assignment”</a>.
   </p><p>
    To add the iSCSI Gateway to an existing cluster, refer to
    <span class="intraxref">Book “Administration Guide”, Chapter 1 “Salt Cluster Administration”, Section 1.2 “Adding New Roles to Nodes”</span>.
   </p></section><section class="sect2" id="id-1.4.5.4.8.4" data-id-title="Create RBD Images"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">10.4.2 </span><span class="title-name">Create RBD Images</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#id-1.4.5.4.8.4">#</a></h3></div></div></div><p>
    RBD images are created in the Ceph store and subsequently exported to
    iSCSI. We recommend that you use a dedicated RADOS pool for this purpose.
    You can create a volume from any host that is able to connect to your
    storage cluster using the Ceph <code class="command">rbd</code> command line
    utility. This requires the client to have at least a minimal ceph.conf
    configuration file, and appropriate CephX authentication credentials.
   </p><p>
    To create a new volume for subsequent export via iSCSI, use the
    <code class="command">rbd create</code> command, specifying the volume size in
    megabytes. For example, in order to create a 100 GB volume named
    <code class="literal">testvol</code> in the pool named <code class="literal">iscsi</code>, run:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>rbd --pool iscsi create --size=102400 testvol</pre></div><p>
    The above command creates an RBD volume in the default format 2.
   </p><div id="id-1.4.5.4.8.4.6" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><h6>Note</h6><p>
     Since SUSE Enterprise Storage 3, the default volume format is 2, and format 1 is
     deprecated. However, you can still create the deprecated format 1 volumes
     with the <code class="option">--image-format 1</code> option.
    </p></div></section><section class="sect2" id="ceph-iscsi-rbd-export" data-id-title="Export RBD Images via iSCSI"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">10.4.3 </span><span class="title-name">Export RBD Images via iSCSI</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#ceph-iscsi-rbd-export">#</a></h3></div></div></div><p>
    To export RBD images via iSCSI, use the <code class="systemitem">lrbd</code>
    utility. <code class="systemitem">lrbd</code> allows you to create, review, and
    modify the iSCSI target configuration, which uses a JSON format.
   </p><div id="id-1.4.5.4.8.5.3" data-id-title="Import Changes into openATTIC" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg"/><h6>Tip: Import Changes into openATTIC</h6><p>
     Any changes made to the iSCSI Gateway configuration using the
     <code class="command">lrbd</code> command are not visible to DeepSea and openATTIC. To
     import your manual changes, you need to export the iSCSI Gateway configuration to
     a file:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">root@minion &gt; </code>lrbd -o /tmp/lrbd.conf</pre></div><p>
     Then copy it to the Salt master so that DeepSea and openATTIC can see it:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">root@minion &gt; </code>scp /tmp/lrbd.conf ses5master:/srv/salt/ceph/igw/cache/lrbd.conf</pre></div><p>
     Finally, edit <code class="filename">/srv/pillar/ceph/stack/global.yml</code> and
     set:
    </p><div class="verbatim-wrap"><pre class="screen">igw_config: default-ui</pre></div></div><p>
    In order to edit the configuration, use <code class="command">lrbd -e</code> or
    <code class="command">lrbd --edit</code>. This command will invoke the default
    editor, as defined by the <code class="literal">EDITOR</code> environment variable.
    You may override this behavior by setting the <code class="option">-E</code> option in
    addition to <code class="option">-e</code>.
   </p><p>
    Below is an example configuration for
   </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
      two iSCSI gateway hosts named <code class="literal">iscsi1.example.com</code> and
      <code class="literal">iscsi2.example.com</code>,
     </p></li><li class="listitem"><p>
      defining a single iSCSI target with an iSCSI Qualified Name (IQN) of
      <code class="literal">iqn.2003-01.org.linux-iscsi.iscsi.x86:testvol</code>,
     </p></li><li class="listitem"><p>
      with a single iSCSI Logical Unit (LU),
     </p></li><li class="listitem"><p>
      backed by an RBD image named <code class="literal">testvol</code> in the RADOS pool
      <code class="literal">rbd</code>,
     </p></li><li class="listitem"><p>
      and exporting the target via two portals named "east" and "west":
     </p></li></ul></div><div class="verbatim-wrap"><pre class="screen">{
    "auth": [
        {
            "target": "iqn.2003-01.org.linux-iscsi.iscsi.x86:testvol",
            "authentication": "none"
        }
    ],
    "targets": [
        {
            "target": "iqn.2003-01.org.linux-iscsi.iscsi.x86:testvol",
            "hosts": [
                {
                    "host": "iscsi1.example.com",
                    "portal": "east"
                },
                {
                    "host": "iscsi2.example.com",
                    "portal": "west"
                }
            ]
        }
    ],
    "portals": [
        {
            "name": "east",
            "addresses": [
                "192.168.124.104"
            ]
        },
        {
            "name": "west",
            "addresses": [
                "192.168.124.105"
            ]
        }
    ],
    "pools": [
        {
            "pool": "rbd",
            "gateways": [
                {
                    "target": "iqn.2003-01.org.linux-iscsi.iscsi.x86:testvol",
                    "tpg": [
                        {
                            "image": "testvol"
                        }
                    ]
                }
            ]
        }
    ]
    }</pre></div><p>
    Note that whenever you refer to a host name in the configuration, this host
    name must match the iSCSI gateway's <code class="command">uname -n</code> command
    output.
   </p><p>
    The edited JSON is stored in the extended attributes (xattrs) of a single
    RADOS object per pool. This object is available to the gateway hosts where
    the JSON is edited, as well as to all gateway hosts connected to the same
    Ceph cluster. No configuration information is stored locally on the
    <code class="systemitem">lrbd</code> gateway.
   </p><p>
    To activate the configuration, store it in the Ceph cluster, and do one
    of the following things (as <code class="systemitem">root</code>):
   </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
      Run the <code class="command">lrbd</code> command (without additional options) from
      the command line,
     </p></li></ul></div><p>
    or
   </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
      Restart the <code class="systemitem">lrbd</code> service with <code class="command">service
      lrbd restart</code>.
     </p></li></ul></div><p>
    The <code class="systemitem">lrbd</code> "service" does not operate any background
    daemon. Instead, it simply invokes the <code class="command">lrbd</code> command.
    This type of service is known as a "one-shot" service.
   </p><p>
    You should also enable <code class="systemitem">lrbd</code> to auto-configure on
    system start-up. To do so, run the <code class="command">systemctl enable lrbd</code>
    command.
   </p><p>
    The configuration above reflects a simple, one-gateway setup.
    <code class="systemitem">lrbd</code> configuration can be much more complex and
    powerful. The <code class="systemitem">lrbd</code> RPM package comes with an
    extensive set of configuration examples, which you may refer to by checking
    the content of the
    <code class="filename">/usr/share/doc/packages/lrbd/samples</code> directory after
    installation. The samples are also available from
    <a class="link" href="https://github.com/SUSE/lrbd/tree/master/samples" target="_blank">https://github.com/SUSE/lrbd/tree/master/samples</a>.
   </p></section><section class="sect2" id="iscsi-lrbd-autentication" data-id-title="Authentication and Access Control"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">10.4.4 </span><span class="title-name">Authentication and Access Control</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#iscsi-lrbd-autentication">#</a></h3></div></div></div><p>
    iSCSI authentication is flexible and covers many possibilities. The five
    possible top level settings are <code class="option">none</code>,
    <code class="option">tpg</code>, <code class="option">acls</code>,
    <code class="option">tpg+identified</code> and <code class="option">identified</code>.
   </p><section class="sect3" id="id-1.4.5.4.8.6.3" data-id-title="No Authentication"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">10.4.4.1 </span><span class="title-name">No Authentication</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#id-1.4.5.4.8.6.3">#</a></h4></div></div></div><p>
     'No authentication' means that no initiator will require a user name and
     password to access any LUNs for a specified host or target. 'No
     authentication' can be set explicitly or implicitly. Specify a value of
     'none' for authentication to be set explicitly:
    </p><div class="verbatim-wrap"><pre class="screen">{
    "host": "igw1",
    "authentication": none
}</pre></div><p>
     Removing the entire <code class="option">auth</code> section from the configuration
     will use no authentication implicitly.
    </p></section><section class="sect3" id="id-1.4.5.4.8.6.4" data-id-title="TPG Authentication"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">10.4.4.2 </span><span class="title-name">TPG Authentication</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#id-1.4.5.4.8.6.4">#</a></h4></div></div></div><p>
     For common credentials or a shared user name/password, set authentication
     to <code class="option">tpg</code>. This setting will apply to all initiators for the
     associated host or target. In the following example, the same user name
     and password are used for the redundant target and a target local to
     <code class="literal">igw1</code>:
    </p><div class="verbatim-wrap"><pre class="screen">{
  "target": "iqn.2003-01.org.linux-iscsi.igw.x86:sn.redundant",
  "authentication": tpg,
  "tpg": {
      "userid": "common1",
      "password": "pass1"
  }
},
{
    "host": "igw1",
    "authentication": tpg,
    "tpg": {
        "userid": "common1",
        "password": "pass1"
    }
}</pre></div><p>
     Redundant configurations will have the same credentials across gateways
     but are independent of other configurations. In other words, LUNs
     configured specifically for a host and multiple redundant configurations
     can have a unique user name and password for each.
    </p><p>
     One caveat is that any initiator setting will be ignored when using
     <code class="option">tpg</code> authentication. Using common credentials does not
     restrict which initiators may connect. This configuration may be suitable
     in isolated network environments.
    </p></section><section class="sect3" id="id-1.4.5.4.8.6.5" data-id-title="ACLs Authentication"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">10.4.4.3 </span><span class="title-name">ACLs Authentication</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#id-1.4.5.4.8.6.5">#</a></h4></div></div></div><p>
     For unique credentials for each initiator, set authentication to
     <code class="option">acls</code>. Additionally, only defined initiators are allowed
     to connect.
    </p><div class="verbatim-wrap"><pre class="screen">{
    "host": "igw1",
    "authentication": acls,
    "acls": [
        {
            "initiator": "iqn.1996-04.de.suse:01:e6ca28cc9f20",
            "userid": "initiator1",
            "password": "pass1",
        }
    ]
},</pre></div></section><section class="sect3" id="id-1.4.5.4.8.6.6" data-id-title="TPG+identified Authentication"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">10.4.4.4 </span><span class="title-name">TPG+identified Authentication</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#id-1.4.5.4.8.6.6">#</a></h4></div></div></div><p>
     The previous two authentication settings pair two independent features:
     TPG pairs common credentials with unidentified initiators, while ACLs pair
     unique credentials with identified initiators.
    </p><p>
     Setting authentication to <code class="option">tpg+identified</code> pairs common
     credentials with identified initiators. Although you can imitate the same
     behavior choosing <code class="option">acls</code> and repeating the same credentials
     with each initiator, the configuration would grow huge and harder to
     maintain.
    </p><p>
     The following configuration uses the <code class="option">tpg</code> configuration
     with only the authentication keyword changing.
    </p><div class="verbatim-wrap"><pre class="screen">{
  "target": "iqn.2003-01.org.linux-iscsi.igw.x86:sn.redundant",
  "authentication": tpg+identified,
  "tpg": {
      "userid": "common1",
      "password": "pass1"
  }
},
{
    "host": "igw1",
    "authentication": tpg+identified,
    "tpg": {
        "userid": "common1",
        "password": "pass1"
    }
}</pre></div><p>
     The list of initiators is gathered from those defined in the pools for the
     given hosts and targets in the authentication section.
    </p></section><section class="sect3" id="id-1.4.5.4.8.6.7" data-id-title="Identified Authentication"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">10.4.4.5 </span><span class="title-name">Identified Authentication</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#id-1.4.5.4.8.6.7">#</a></h4></div></div></div><p>
     This type of authentication does not use any credentials. In secure
     environments where only assignment of initiators is needed, set the
     authentication to <code class="option">identified</code>. All initiators will connect
     but only have access to the images listed in the <code class="literal">pools</code>
     section.
    </p><div class="verbatim-wrap"><pre class="screen">{
    "target": "iqn.2003-01.org.linux-iscsi:igw.x86:sn.redundant",
    "authentication": "identified",
},
{
    "host": "igw1",
    "authentication": "identified",
}</pre></div></section><section class="sect3" id="id-1.4.5.4.8.6.8" data-id-title="Discovery and Mutual Authentication"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">10.4.4.6 </span><span class="title-name">Discovery and Mutual Authentication</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#id-1.4.5.4.8.6.8">#</a></h4></div></div></div><p>
     <span class="emphasis"><em>Discovery authentication</em></span> is independent of the
     previous authentication methods. It requires credentials for browsing.
    </p><p>
     Authentication of type <code class="option">tpg</code>,
     <code class="option">tpg+identified</code>, <code class="option">acls</code>, and
     <code class="option">discovery</code> support mutual authentication. Specifying the
     mutual settings requires that the target authenticates against the
     initiator.
    </p><p>
     Discovery and mutual authentications are optional. These options can be
     present, but disabled allowing experimentation with a particular
     configuration. After you decide, you can remove the disabled entries
     without breaking the configuration.
    </p><p>
     Refer to the examples in
     <code class="filename">/usr/share/doc/packages/lrbd/samples</code>. You can combine
     excerpts from one file with others to create unique configurations.
    </p></section></section><section class="sect2" id="ceph-iscsi-rbd-optional" data-id-title="Optional Settings"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">10.4.5 </span><span class="title-name">Optional Settings</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#ceph-iscsi-rbd-optional">#</a></h3></div></div></div><p>
    The following settings may be useful for some environments. For images,
    there are <code class="option">uuid</code>, <code class="option">lun</code>,
    <code class="option">retries</code>, <code class="option">sleep</code>, and
    <code class="option">retry_errors</code> attributes. The first
    two—<code class="option">uuid</code> and <code class="option">lun</code>—allow
    hardcoding of the 'uuid' or 'lun' for a specific image. You can specify
    either of them for an image. The <code class="option">retries</code>,
    <code class="option">sleep</code> and <code class="option">retry_errors</code> affect attempts to
    map an rbd image.
   </p><div id="id-1.4.5.4.8.7.3" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg"/><h6>Tip</h6><p>
     If a site needs statically assigned LUNs, then assign numbers to each LUN.
    </p></div><div class="verbatim-wrap"><pre class="screen">"pools": [
    {
        "pool": "rbd",
        "gateways": [
        {
        "host": "igw1",
        "tpg": [
                    {
                        "image": "archive",
                        "uuid": "12345678-abcd-9012-efab-345678901234",
                        "lun": "2",
                        "retries": "3",
                        "sleep": "4",
                        "retry_errors": [ 95 ],
                        [...]
                    }
                ]
            }
        ]
    }
]</pre></div></section><section class="sect2" id="ceph-iscsi-rbd-advanced" data-id-title="Advanced Settings"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">10.4.6 </span><span class="title-name">Advanced Settings</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#ceph-iscsi-rbd-advanced">#</a></h3></div></div></div><p>
    <code class="systemitem">lrbd</code> can be configured with advanced parameters
    which are subsequently passed on to the LIO I/O target. The parameters are
    divided up into iSCSI and backing store components, which can then be
    specified in the "targets" and "tpg" sections, respectively, of the
    <code class="systemitem">lrbd</code> configuration.
   </p><div id="id-1.4.5.4.8.8.3" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.svg"/><h6>Warning</h6><p>
     Unless otherwise noted, changing these parameters from the default setting
     is not recommended.
    </p></div><div class="verbatim-wrap"><pre class="screen">"targets": [
    {
        [...]
        "tpg_default_cmdsn_depth": "64",
        "tpg_default_erl": "0",
        "tpg_login_timeout": "10",
        "tpg_netif_timeout": "2",
        "tpg_prod_mode_write_protect": "0",
    }
]</pre></div><p>
    A description of the options follows:
   </p><div class="variablelist"><dl class="variablelist"><dt id="id-1.4.5.4.8.8.6.1"><span class="term">tpg_default_cmdsn_depth</span></dt><dd><p>
       Default CmdSN (Command Sequence Number) depth. Limits the amount of
       requests that an iSCSI initiator can have outstanding at any moment.
      </p></dd><dt id="id-1.4.5.4.8.8.6.2"><span class="term">tpg_default_erl</span></dt><dd><p>
       Default error recovery level.
      </p></dd><dt id="id-1.4.5.4.8.8.6.3"><span class="term">tpg_login_timeout</span></dt><dd><p>
       Login timeout value in seconds.
      </p></dd><dt id="id-1.4.5.4.8.8.6.4"><span class="term">tpg_netif_timeout</span></dt><dd><p>
       NIC failure timeout in seconds.
      </p></dd><dt id="id-1.4.5.4.8.8.6.5"><span class="term">tpg_prod_mode_write_protect</span></dt><dd><p>
       If set to 1, prevents writes to LUNs.
      </p></dd></dl></div><div class="verbatim-wrap"><pre class="screen">"pools": [
    {
        "pool": "rbd",
        "gateways": [
        {
        "host": "igw1",
        "tpg": [
                    {
                        "image": "archive",
                        "backstore_block_size": "512",
                        "backstore_emulate_3pc": "1",
                        "backstore_emulate_caw": "1",
                        "backstore_emulate_dpo": "0",
                        "backstore_emulate_fua_read": "0",
                        "backstore_emulate_fua_write": "1",
                        "backstore_emulate_model_alias": "0",
                        "backstore_emulate_pr": "1",
                        "backstore_emulate_rest_reord": "0",
                        "backstore_emulate_tas": "1",
                        "backstore_emulate_tpu": "0",
                        "backstore_emulate_tpws": "0",
                        "backstore_emulate_ua_intlck_ctrl": "0",
                        "backstore_emulate_write_cache": "0",
                        "backstore_enforce_pr_isids": "1",
                        "backstore_fabric_max_sectors": "8192",
                        "backstore_hw_block_size": "512",
                        "backstore_hw_max_sectors": "8192",
                        "backstore_hw_pi_prot_type": "0",
                        "backstore_hw_queue_depth": "128",
                        "backstore_is_nonrot": "1",
                        "backstore_max_unmap_block_desc_count": "1",
                        "backstore_max_unmap_lba_count": "8192",
                        "backstore_max_write_same_len": "65535",
                        "backstore_optimal_sectors": "8192",
                        "backstore_pi_prot_format": "0",
                        "backstore_pi_prot_type": "0",
                        "backstore_queue_depth": "128",
                        "backstore_unmap_granularity": "8192",
                        "backstore_unmap_granularity_alignment": "4194304"
                    }
                ]
            }
        ]
    }
]</pre></div><p>
    A description of the options follows:
   </p><div class="variablelist"><dl class="variablelist"><dt id="id-1.4.5.4.8.8.9.1"><span class="term">backstore_block_size</span></dt><dd><p>
       Block size of the underlying device.
      </p></dd><dt id="id-1.4.5.4.8.8.9.2"><span class="term">backstore_emulate_3pc</span></dt><dd><p>
       If set to 1, enables Third Party Copy.
      </p></dd><dt id="id-1.4.5.4.8.8.9.3"><span class="term">backstore_emulate_caw</span></dt><dd><p>
       If set to 1, enables Compare and Write.
      </p></dd><dt id="id-1.4.5.4.8.8.9.4"><span class="term">backstore_emulate_dpo</span></dt><dd><p>
       If set to 1, turns on Disable Page Out.
      </p></dd><dt id="id-1.4.5.4.8.8.9.5"><span class="term">backstore_emulate_fua_read</span></dt><dd><p>
       If set to 1, enables Force Unit Access read.
      </p></dd><dt id="id-1.4.5.4.8.8.9.6"><span class="term">backstore_emulate_fua_write</span></dt><dd><p>
       If set to 1, enables Force Unit Access write.
      </p></dd><dt id="id-1.4.5.4.8.8.9.7"><span class="term">backstore_emulate_model_alias</span></dt><dd><p>
       If set to 1, uses the back-end device name for the model alias.
      </p></dd><dt id="id-1.4.5.4.8.8.9.8"><span class="term">backstore_emulate_pr</span></dt><dd><p>
       If set to 0, support for SCSI Reservations, including Persistent Group
       Reservations, is disabled. While disabled, the SES iSCSI Gateway can
       ignore reservation state, resulting in improved request latency.
      </p><div id="id-1.4.5.4.8.8.9.8.2.2" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg"/><h6>Tip</h6><p>
        Setting backstore_emulate_pr to 0 is recommended if iSCSI initiators do
        not require SCSI Reservation support.
       </p></div></dd><dt id="id-1.4.5.4.8.8.9.9"><span class="term">backstore_emulate_rest_reord</span></dt><dd><p>
       If set to 0, the Queue Algorithm Modifier has Restricted Reordering.
      </p></dd><dt id="id-1.4.5.4.8.8.9.10"><span class="term">backstore_emulate_tas</span></dt><dd><p>
       If set to 1, enables Task Aborted Status.
      </p></dd><dt id="id-1.4.5.4.8.8.9.11"><span class="term">backstore_emulate_tpu</span></dt><dd><p>
       If set to 1, enables Thin Provisioning Unmap.
      </p></dd><dt id="id-1.4.5.4.8.8.9.12"><span class="term">backstore_emulate_tpws</span></dt><dd><p>
       If set to 1, enables Thin Provisioning Write Same.
      </p></dd><dt id="id-1.4.5.4.8.8.9.13"><span class="term">backstore_emulate_ua_intlck_ctrl</span></dt><dd><p>
       If set to 1, enables Unit Attention Interlock.
      </p></dd><dt id="id-1.4.5.4.8.8.9.14"><span class="term">backstore_emulate_write_cache</span></dt><dd><p>
       If set to 1, turns on Write Cache Enable.
      </p></dd><dt id="id-1.4.5.4.8.8.9.15"><span class="term">backstore_enforce_pr_isids</span></dt><dd><p>
       If set to 1, enforces persistent reservation ISIDs.
      </p></dd><dt id="id-1.4.5.4.8.8.9.16"><span class="term">backstore_fabric_max_sectors</span></dt><dd><p>
       Maximum number of sectors the fabric can transfer at once.
      </p></dd><dt id="id-1.4.5.4.8.8.9.17"><span class="term">backstore_hw_block_size</span></dt><dd><p>
       Hardware block size in bytes.
      </p></dd><dt id="id-1.4.5.4.8.8.9.18"><span class="term">backstore_hw_max_sectors</span></dt><dd><p>
       Maximum number of sectors the hardware can transfer at once.
      </p></dd><dt id="id-1.4.5.4.8.8.9.19"><span class="term">backstore_hw_pi_prot_type</span></dt><dd><p>
       If non-zero, DIF protection is enabled on the underlying hardware.
      </p></dd><dt id="id-1.4.5.4.8.8.9.20"><span class="term">backstore_hw_queue_depth</span></dt><dd><p>
       Hardware queue depth.
      </p></dd><dt id="id-1.4.5.4.8.8.9.21"><span class="term">backstore_is_nonrot</span></dt><dd><p>
       If set to 1, the backstore is a non-rotational device.
      </p></dd><dt id="id-1.4.5.4.8.8.9.22"><span class="term">backstore_max_unmap_block_desc_count</span></dt><dd><p>
       Maximum number of block descriptors for UNMAP.
      </p></dd><dt id="id-1.4.5.4.8.8.9.23"><span class="term">backstore_max_unmap_lba_count:</span></dt><dd><p>
       Maximum number of LBAs for UNMAP.
      </p></dd><dt id="id-1.4.5.4.8.8.9.24"><span class="term">backstore_max_write_same_len</span></dt><dd><p>
       Maximum length for WRITE_SAME.
      </p></dd><dt id="id-1.4.5.4.8.8.9.25"><span class="term">backstore_optimal_sectors</span></dt><dd><p>
       Optimal request size in sectors.
      </p></dd><dt id="id-1.4.5.4.8.8.9.26"><span class="term">backstore_pi_prot_format</span></dt><dd><p>
       DIF protection format.
      </p></dd><dt id="id-1.4.5.4.8.8.9.27"><span class="term">backstore_pi_prot_type</span></dt><dd><p>
       DIF protection type.
      </p></dd><dt id="id-1.4.5.4.8.8.9.28"><span class="term">backstore_queue_depth</span></dt><dd><p>
       Queue depth.
      </p></dd><dt id="id-1.4.5.4.8.8.9.29"><span class="term">backstore_unmap_granularity</span></dt><dd><p>
       UNMAP granularity.
      </p></dd><dt id="id-1.4.5.4.8.8.9.30"><span class="term">backstore_unmap_granularity_alignment</span></dt><dd><p>
       UNMAP granularity alignment.
      </p></dd></dl></div><p>
    For targets, the <code class="option">tpg</code> attributes allow tuning of kernel
    parameters. Use with caution.
   </p><div class="verbatim-wrap"><pre class="screen">"targets": [
{
    "host": "igw1",
    "target": "iqn.2003-01.org.linux-iscsi.generic.x86:sn.abcdefghijk",
    "tpg_default_cmdsn_depth": "64",
    "tpg_default_erl": "0",
    "tpg_login_timeout": "10",
    "tpg_netif_timeout": "2",
    "tpg_prod_mode_write_protect": "0",
    "tpg_t10_pi": "0"
}</pre></div><p>
    For initiators, the <code class="option">attrib</code> and <code class="option">param</code>
    settings allow the tuning of kernel parameters. Use with caution. These are
    set in the authentication section. If the authentication is
    <code class="option">tpg+identified</code> or <code class="option">identified</code>, then the
    subsection is identified.
   </p><div class="verbatim-wrap"><pre class="screen">"auth": [
  {
      "authentication": "tpg+identified",
      "identified": [
        {
          "initiator": "iqn.1996-04.de.suse:01:e6ca28cc9f20",
          "attrib_dataout_timeout": "3",
          "attrib_dataout_timeout_retries": "5",
          "attrib_default_erl": "0",
          "attrib_nopin_response_timeout": "30",
          "attrib_nopin_timeout": "15",
          "attrib_random_datain_pdu_offsets": "0",
          "attrib_random_datain_seq_offsets": "0",
          "attrib_random_r2t_offsets": "0",
          "param_DataPDUInOrder": "1",
          "param_DataSequenceInOrder": "1",
          "param_DefaultTime2Retain": "0",
          "param_DefaultTime2Wait": "2",
          "param_ErrorRecoveryLevel": "0",
          "param_FirstBurstLength": "65536",
          "param_ImmediateData": "1",
          "param_InitialR2T": "1",
          "param_MaxBurstLength": "262144",
          "param_MaxConnections": "1",
          "param_MaxOutstandingR2T": "1"
        }
      ]
  }
]</pre></div><p>
    If the authentication is <code class="option">acls</code>, then the settings are
    included in the <code class="option">acls</code> subsection. One caveat is that
    settings are only applied for active initiators. If an initiator is absent
    from the pools section, the <code class="option">acl</code> entry is not created and
    settings cannot be applied.
   </p></section></section><section class="sect1" id="iscsi-tcmu" data-id-title="Exporting RADOS Block Device Images using tcmu-runner"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">10.5 </span><span class="title-name">Exporting RADOS Block Device Images using <code class="systemitem">tcmu-runner</code></span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#iscsi-tcmu">#</a></h2></div></div></div><p>
   Since version 5, SUSE Enterprise Storage ships a user space RBD back-end for
   <code class="systemitem">tcmu-runner</code> (see <code class="command">man 8
   tcmu-runner</code> for details).
  </p><div id="id-1.4.5.4.9.3" data-id-title="Technology Preview" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.svg"/><h6>Warning: Technology Preview</h6><p>
    <code class="systemitem">tcmu-runner</code> based iSCSI Gateway deployments are currently
    a technology preview. See <a class="xref" href="cha-ceph-as-iscsi.html" title="Chapter 10. Installation of iSCSI Gateway">Chapter 10, <em>Installation of iSCSI Gateway</em></a> for
    instructions on kernel-based iSCSI Gateway deployment with
    <code class="systemitem">lrbd</code>.
   </p></div><p>
   Unlike kernel-based <code class="systemitem">lrbd</code> iSCSI Gateway deployments,
   <code class="systemitem">tcmu-runner</code> based iSCSI Gateways do not offer support for
   multipath I/O or SCSI Persistent Reservations.
  </p><p>
   As DeepSea and openATTIC do not currently support
   <code class="systemitem">tcmu-runner</code> deployments, you need to manage the
   installation, deployment, and monitoring manually.
  </p><section class="sect2" id="iscsi-tcmu-install" data-id-title="Installation"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">10.5.1 </span><span class="title-name">Installation</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#iscsi-tcmu-install">#</a></h3></div></div></div><p>
    On your iSCSI Gateway node, install the
    <code class="systemitem">tcmu-runner-handler-rbd</code> package from the
    SUSE Enterprise Storage 5 media, together with the <code class="systemitem">libtcmu1</code>
    and <code class="systemitem">tcmu-runner</code> package dependencies. Install the
    <code class="systemitem">targetcli-fb</code> package for configuration purposes.
    Note that the <code class="systemitem">targetcli-fb</code> package is incompatible
    with the 'non-fb' version of the <code class="systemitem">targetcli</code>
    package.
   </p><p>
    Confirm that the <code class="systemitem">tcmu-runner</code> <code class="systemitem">systemd</code> service is
    running:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">root # </code>systemctl enable tcmu-runner
tcmu-gw:~ # systemctl status tcmu-runner
● tcmu-runner.service - LIO Userspace-passthrough daemon
  Loaded: loaded (/usr/lib/systemd/system/tcmu-runner.service; static; vendor
  preset: disabled)
    Active: active (running) since ...</pre></div></section><section class="sect2" id="iscsi-tcmu-depl" data-id-title="Configuration and Deployment"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">10.5.2 </span><span class="title-name">Configuration and Deployment</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#iscsi-tcmu-depl">#</a></h3></div></div></div><p>
    Create a RADOS Block Device image on your existing Ceph cluster. In the following
    example, we will use a 10G image called 'tcmu-lu' located in the 'rbd'
    pool.
   </p><p>
    Following RADOS Block Device image creation, run <code class="command">targetcli</code>, and
    ensure that the tcmu-runner RBD handler (plug-in) is available:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">root # </code>targetcli
targetcli shell version 2.1.fb46
Copyright 2011-2013 by Datera, Inc and others.
For help on commands, type 'help'.

/&gt; ls
o- / ................................... [...]
  o- backstores ........................ [...]
...
  | o- user:rbd ......... [Storage Objects: 0]</pre></div><p>
    Create a backstore configuration entry for the RBD image:
   </p><div class="verbatim-wrap"><pre class="screen">/&gt; cd backstores/user:rbd
/backstores/user:rbd&gt; create tcmu-lu 10G /rbd/tcmu-lu
Created user-backed storage object tcmu-lu size 10737418240.</pre></div><p>
    Create an iSCSI transport configuration entry. In the following example,
    the target IQN "iqn.2003-01.org.linux-iscsi.tcmu-gw.x8664:sn.cb3d2a3a" is
    automatically generated by <code class="command">targetcli</code> for use as a unique
    iSCSI target identifier:
   </p><div class="verbatim-wrap"><pre class="screen">/backstores/user:rbd&gt; cd /iscsi
/iscsi&gt; create
Created target iqn.2003-01.org.linux-iscsi.tcmu-gw.x8664:sn.cb3d2a3a.
Created TPG 1.
Global pref auto_add_default_portal=true
Created default portal listening on all IPs (0.0.0.0), port 3260.</pre></div><p>
    Create an ACL entry for the iSCSI initiator(s) that you want to connect
    to the target. In the following example, an initiator IQN of
    "iqn.1998-01.com.vmware:esxi-872c4888" is used:
   </p><div class="verbatim-wrap"><pre class="screen">/iscsi&gt; cd
iqn.2003-01.org.linux-iscsi.tcmu-gw.x8664:sn.cb3d2a3a/tpg1/acls/
/iscsi/iqn.20...a3a/tpg1/acls&gt; create iqn.1998-01.com.vmware:esxi-872c4888</pre></div><p>
    Finally, link the previously created RBD backstore configuration to the
    iSCSI target:
   </p><div class="verbatim-wrap"><pre class="screen">/iscsi/iqn.20...a3a/tpg1/acls&gt; cd ../luns
/iscsi/iqn.20...a3a/tpg1/luns&gt; create /backstores/user:rbd/tcmu-lu
Created LUN 0.
Created LUN 0-&gt;0 mapping in node ACL iqn.1998-01.com.vmware:esxi-872c4888</pre></div><p>
    Exit the shell to save the existing configuration:
   </p><div class="verbatim-wrap"><pre class="screen">/iscsi/iqn.20...a3a/tpg1/luns&gt; exit
Global pref auto_save_on_exit=true
Last 10 configs saved in /etc/target/backup.
Configuration saved to /etc/target/saveconfig.json</pre></div></section><section class="sect2" id="iscsi-tcmu-use" data-id-title="Usage"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">10.5.3 </span><span class="title-name">Usage</span> <a title="Permalink" class="permalink" href="cha-ceph-as-iscsi.html#iscsi-tcmu-use">#</a></h3></div></div></div><p>
    From your iSCSI initiator (client) node, connect to your newly
    provisioned iSCSI target using the IQN and host name configured above.
   </p><div class="verbatim-wrap"><pre class="screen">"auth": [
    {
        "host": "igw1",
        "authentication": "acls",
        "acls": [
            {
                "initiator": "iqn.1996-04.de.suse:01:e6ca28cc9f20",
                "userid": "initiator1",
                "password": "pass1",
                "attrib_dataout_timeout": "3",
                "attrib_dataout_timeout_retries": "5",
                "attrib_default_erl": "0",
                "attrib_nopin_response_timeout": "30",
                "attrib_nopin_timeout": "15",
                "attrib_random_datain_pdu_offsets": "0",
                "attrib_random_datain_seq_offsets": "0",
                "attrib_random_r2t_offsets": "0",
                "param_DataPDUInOrder": "1",
                "param_DataSequenceInOrder": "1",
                "param_DefaultTime2Retain": "0",
                "param_DefaultTime2Wait": "2",
                "param_ErrorRecoveryLevel": "0",
                "param_FirstBurstLength": "65536",
                "param_ImmediateData": "1",
                "param_InitialR2T": "1",
                "param_MaxBurstLength": "262144",
                "param_MaxConnections": "1",
                "param_MaxOutstandingR2T": "1"
            }
        ]
    },
]</pre></div></section></section></section><nav class="bottom-pagination"><div><a class="pagination-link prev" href="cha-ceph-additional-software-installation.html"><span class="pagination-relation">Previous</span><span class="pagination-label"><span class="title-number">Chapter 9 </span>Ceph Object Gateway</span></a> </div><div><a class="pagination-link next" href="cha-ceph-as-cephfs.html"><span class="pagination-relation">Next</span><span class="pagination-label"><span class="title-number">Chapter 11 </span>Installation of CephFS</span></a> </div></nav></article><aside id="_side-toc-page" class="side-toc"><div class="side-title">On this page</div><div class="toc"><ul><li><span class="sect1"><a href="cha-ceph-as-iscsi.html#ceph-iscsi-iscsi"><span class="title-number">10.1 </span><span class="title-name">iSCSI Block Storage</span></a></span></li><li><span class="sect1"><a href="cha-ceph-as-iscsi.html#ceph-iscsi-lrbd"><span class="title-number">10.2 </span><span class="title-name">General Information about lrbd</span></a></span></li><li><span class="sect1"><a href="cha-ceph-as-iscsi.html#ceph-iscsi-deploy"><span class="title-number">10.3 </span><span class="title-name">Deployment Considerations</span></a></span></li><li><span class="sect1"><a href="cha-ceph-as-iscsi.html#ceph-iscsi-install"><span class="title-number">10.4 </span><span class="title-name">Installation and Configuration</span></a></span></li><li><span class="sect1"><a href="cha-ceph-as-iscsi.html#iscsi-tcmu"><span class="title-number">10.5 </span><span class="title-name">Exporting RADOS Block Device Images using <code class="systemitem">tcmu-runner</code></span></a></span></li></ul></div><div class="side-title">Give feedback</div><ul class="feedback" id="_give-feedback"><li><a id="_feedback-reportbug" href="#" rel="nofollow" target="_blank">Report an issue</a></li><li><a id="_feedback-editurl" href="https://github.com/SUSE/doc-ses/edit/maintenance/ses5/xml/deployment_iscsi.xml" rel="nofollow" target="_blank">Edit source document</a></li></ul><div class="side-title">Share this page</div><ul class="share"><li><a id="_share-fb" href="#" title="Facebook"> </a></li><li><a id="_share-in" href="#" title="LinkedIn"> </a></li><li><a id="_share-tw" href="#" title="Twitter"> </a></li><li><a id="_share-mail" href="#" title="E-Mail"> </a></li><li><a id="_print-button" href="#" title="Print this page"> </a></li></ul> </aside></main><footer id="_footer"><div class="growth-inhibitor"><div class="copy"><span class="copy__rights">© SUSE
                 2022</span></div></div></footer></body></html>