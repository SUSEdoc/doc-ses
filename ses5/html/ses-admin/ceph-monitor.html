<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes"/><title>Determining Cluster State | Administration Guide | SUSE Enterprise Storage 5.5 (SES 5 &amp; SES 5.5)</title><link rel="stylesheet" type="text/css" href="static/css/style.css"/>
<meta name="title" content="Determining Cluster State | SES 5.5 (SES 5 &amp; SES 5.5)"/>
<meta name="description" content="When you have a running cluster, you may use the ceph tool to monitor it. Determining the cluster state typically involves checking the status of Ceph OSDs, Ce…"/>
<meta name="product-name" content="SUSE Enterprise Storage"/>
<meta name="product-number" content="5.5 (SES 5 &amp; SES 5.5)"/>
<meta name="book-title" content="Administration Guide"/>
<meta name="chapter-title" content="Chapter 4. Determining Cluster State"/>
<meta name="tracker-url" content="https://bugzilla.suse.com/enter_bug.cgi"/>
<meta name="tracker-type" content="bsc"/>
<meta name="tracker-bsc-assignee" content="tbazant@suse.com"/>
<meta name="tracker-bsc-component" content="Documentation"/>
<meta name="tracker-bsc-product" content="SUSE Enterprise Storage 5"/>
<meta property="og:title" content="Determining Cluster State | SES 5.5 (SES 5 &amp; SES 5.5)"/>
<meta property="og:description" content="When you have a running cluster, you may use the ceph tool to monitor it. Determining the cluster state typically involves checking the status of Ceph OSDs, Ce…"/>
<meta property="og:type" content="article"/>
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Determining Cluster State | SES 5.5 (SES 5 &amp; SES 5.5)"/>
<meta name="twitter:description" content="When you have a running cluster, you may use the ceph tool to monitor it. Determining the cluster state typically involves checking the status of Ceph OSDs, Ce…"/>
<link rel="prev" href="ceph-operating-services.html" title="Chapter 3. Operating Ceph Services"/><link rel="next" href="monitoring-alerting.html" title="Chapter 5. Monitoring and Alerting"/>
<script type="text/javascript">

if ( window.location.protocol.toLowerCase() != 'file:' ) {
  document.write('<link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css"></link>');
};

</script><noscript><link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css"/></noscript><script src="static/js/jquery-1.10.2.min.js" type="text/javascript"> </script><script src="static/js/script.js" type="text/javascript"> </script><script src="static/js/highlight.min.js" type="text/javascript"> </script><script>

$(document).ready(function() {
  $('.verbatim-wrap.highlight').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});
hljs.configure({
  useBR: false
});

</script></head><body class="draft wide offline js-off" onload="$('#betawarn-button-wrap').toggle();if (document.cookie.length > 0) {if (document.cookie.indexOf('betawarn=closed') != -1){$('#betawarn').toggle()}};"><div id="betawarn" style="position:fixed;bottom:0;z-index:9025;background-color:#FDE8E8;padding:1em;margin-left:10%;margin-right:10%;display:block;border-top:.75em solid #E11;width:80%"><p style="color:#333;margin:1em 0;padding:0;">This is a draft document that was built and uploaded automatically. It may document beta software and be incomplete or even incorrect. <strong>Use this document at your own risk.</strong></p> <div id="betawarn-button-wrap" style="display:none;margin:0;padding:0;"><a href="#" onclick="$('#betawarn').toggle();var d=new Date();d.setTime(d.getTime()+(0.5*24*60*60*1000));document.cookie='betawarn=closed; expires='+d.toUTCString()+'; path=/'; return false;" style="color:#333;text-decoration:underline;float:left;margin-top:.5em;padding:1em;display:block;background-color:#FABEBE;">I understand this is a draft</a></div></div><div class="bypass-block"><a href="#_content">Jump to content</a><a href="#_bottom-pagination">Jump to page navigation: previous page [access key p]/next page [access key n]</a></div><header id="_mainnav"><div class="growth-inhibitor"><img src="static/images/logo.svg" alt="Logo" class="logo"/></div></header><div class="crumbs"><div class="growth-inhibitor"><a class="crumb" href="index.html">Administration Guide</a><span> / </span><a class="crumb" href="part-operate.html">Operating a Cluster</a><span> / </span><a class="crumb" href="ceph-monitor.html">Determining Cluster State</a></div></div><main id="_content"><nav id="_side-toc-overall" class="side-toc"><div class="side-title">Administration Guide</div><ol><li><a href="bk01pr01.html" class=" "><span class="title-number"> </span><span class="title-name">About This Guide</span></a></li><li><a href="part-cluster-managment.html" class="has-children "><span class="title-number">I </span><span class="title-name">Cluster Management</span></a><ol><li><a href="storage-salt-cluster.html" class=" "><span class="title-number">1 </span><span class="title-name">Salt Cluster Administration</span></a></li></ol></li><li class="active"><a href="part-operate.html" class="has-children you-are-here"><span class="title-number">II </span><span class="title-name">Operating a Cluster</span></a><ol><li><a href="cha-ceph-operating.html" class=" "><span class="title-number">2 </span><span class="title-name">Introduction</span></a></li><li><a href="ceph-operating-services.html" class=" "><span class="title-number">3 </span><span class="title-name">Operating Ceph Services</span></a></li><li><a href="ceph-monitor.html" class=" you-are-here"><span class="title-number">4 </span><span class="title-name">Determining Cluster State</span></a></li><li><a href="monitoring-alerting.html" class=" "><span class="title-number">5 </span><span class="title-name">Monitoring and Alerting</span></a></li><li><a href="cha-storage-cephx.html" class=" "><span class="title-number">6 </span><span class="title-name">Authentication with <code class="systemitem">cephx</code></span></a></li><li><a href="cha-storage-datamgm.html" class=" "><span class="title-number">7 </span><span class="title-name">Stored Data Management</span></a></li><li><a href="ceph-pools.html" class=" "><span class="title-number">8 </span><span class="title-name">Managing Storage Pools</span></a></li><li><a href="ceph-rbd.html" class=" "><span class="title-number">9 </span><span class="title-name">RADOS Block Device</span></a></li><li><a href="cha-ceph-erasure.html" class=" "><span class="title-number">10 </span><span class="title-name">Erasure Coded Pools</span></a></li><li><a href="cha-ceph-tiered.html" class=" "><span class="title-number">11 </span><span class="title-name">Cache Tiering</span></a></li><li><a href="cha-ceph-configuration.html" class=" "><span class="title-number">12 </span><span class="title-name">Ceph Cluster Configuration</span></a></li></ol></li><li><a href="part-dataccess.html" class="has-children "><span class="title-number">III </span><span class="title-name">Accessing Cluster Data</span></a><ol><li><a href="cha-ceph-gw.html" class=" "><span class="title-number">13 </span><span class="title-name">Ceph Object Gateway</span></a></li><li><a href="cha-ceph-iscsi.html" class=" "><span class="title-number">14 </span><span class="title-name">Ceph iSCSI Gateway</span></a></li><li><a href="cha-ceph-cephfs.html" class=" "><span class="title-number">15 </span><span class="title-name">Clustered File System</span></a></li><li><a href="cha-ceph-nfsganesha.html" class=" "><span class="title-number">16 </span><span class="title-name">NFS Ganesha: Export Ceph Data via NFS</span></a></li></ol></li><li><a href="part-gui.html" class="has-children "><span class="title-number">IV </span><span class="title-name">Managing Cluster with GUI Tools</span></a><ol><li><a href="ceph-oa.html" class=" "><span class="title-number">17 </span><span class="title-name">openATTIC</span></a></li></ol></li><li><a href="part-virt.html" class="has-children "><span class="title-number">V </span><span class="title-name">Integration with Virtualization Tools</span></a><ol><li><a href="cha-ceph-libvirt.html" class=" "><span class="title-number">18 </span><span class="title-name">Using <code class="systemitem">libvirt</code> with Ceph</span></a></li><li><a href="cha-ceph-kvm.html" class=" "><span class="title-number">19 </span><span class="title-name">Ceph as a Back-end for QEMU KVM Instance</span></a></li></ol></li><li><a href="part-troubleshooting.html" class="has-children "><span class="title-number">VI </span><span class="title-name">FAQs, Tips and Troubleshooting</span></a><ol><li><a href="storage-tips.html" class=" "><span class="title-number">20 </span><span class="title-name">Hints and Tips</span></a></li><li><a href="storage-faqs.html" class=" "><span class="title-number">21 </span><span class="title-name">Frequently Asked Questions</span></a></li><li><a href="storage-troubleshooting.html" class=" "><span class="title-number">22 </span><span class="title-name">Troubleshooting</span></a></li></ol></li><li><a href="gloss-storage-glossary.html" class=" "><span class="title-number"> </span><span class="title-name">Glossary</span></a></li><li><a href="app-stage1-custom.html" class=" "><span class="title-number">A </span><span class="title-name">DeepSea Stage 1 Custom Example</span></a></li><li><a href="app-alerting-default.html" class=" "><span class="title-number">B </span><span class="title-name">Default Alerts for SUSE Enterprise Storage</span></a></li><li><a href="app-storage-manual-inst.html" class=" "><span class="title-number">C </span><span class="title-name">Example Procedure of Manual Ceph Installation</span></a></li><li><a href="ap-adm-docupdate.html" class=" "><span class="title-number">D </span><span class="title-name">Documentation Updates</span></a></li> </ol> </nav><button id="_open-side-toc-overall" title="Contents"> </button><article class="documentation"><button id="_unfold-side-toc-page">On this page</button><section class="chapter" id="ceph-monitor" data-id-title="Determining Cluster State"><div class="titlepage"><div><div class="version-info">Applies to  <span class="productname">SUSE Enterprise Storage</span> <span class="productnumber">5.5 (SES 5 &amp; SES 5.5)</span></div><div><h2 class="title"><span class="title-number">4 </span><span class="title-name">Determining Cluster State</span> <a title="Permalink" class="permalink" href="ceph-monitor.html#">#</a></h2></div></div></div><p>
  When you have a running cluster, you may use the <code class="command">ceph</code> tool
  to monitor it. Determining the cluster state typically involves checking the
  status of Ceph OSDs, Ceph Monitors, placement groups and Metadata Servers.
 </p><div id="id-1.3.4.4.4" data-id-title="Interactive Mode" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg"/><h6>Tip: Interactive Mode</h6><p>
   To run the <code class="command">ceph</code> tool in an interactive mode, type
   <code class="command">ceph</code> at the command line with no arguments. The
   interactive mode is more convenient if you are going to enter more
   <code class="command">ceph</code> commands in a row. For example:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph
ceph&gt; health
ceph&gt; status
ceph&gt; quorum_status
ceph&gt; mon_status</pre></div></div><section class="sect1" id="monitor-status" data-id-title="Checking a Clusters Status"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">4.1 </span><span class="title-name">Checking a Cluster's Status</span> <a title="Permalink" class="permalink" href="ceph-monitor.html#monitor-status">#</a></h2></div></div></div><p>
   To check a cluster's status, execute the following:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph status</pre></div><p>
   or
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph -s</pre></div><p>
   In interactive mode, type <code class="command">status</code> and press
   <span class="keycap">Enter</span>.
  </p><div class="verbatim-wrap"><pre class="screen">ceph&gt; status</pre></div><p>
   Ceph will print the cluster status. For example, a tiny Ceph cluster
   consisting of one monitor and two OSDs may print the following:
  </p><div class="verbatim-wrap"><pre class="screen">cluster b370a29d-9287-4ca3-ab57-3d824f65e339
 health HEALTH_OK
 monmap e1: 1 mons at {ceph1=10.0.0.8:6789/0}, election epoch 2, quorum 0 ceph1
 osdmap e63: 2 osds: 2 up, 2 in
  pgmap v41332: 952 pgs, 20 pools, 17130 MB data, 2199 objects
        115 GB used, 167 GB / 297 GB avail
               1 active+clean+scrubbing+deep
             951 active+clean</pre></div></section><section class="sect1" id="monitor-health" data-id-title="Checking Cluster Health"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">4.2 </span><span class="title-name">Checking Cluster Health</span> <a title="Permalink" class="permalink" href="ceph-monitor.html#monitor-health">#</a></h2></div></div></div><p>
   After you start your cluster and before you start reading and/or writing
   data, check your cluster's health:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph health
HEALTH_WARN 10 pgs degraded; 100 pgs stuck unclean; 1 mons down, quorum 0,2 \
node-1,node-2,node-3</pre></div><div id="id-1.3.4.4.6.4" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg"/><h6>Tip</h6><p>
    If you specified non-default locations for your configuration or keyring,
    you may specify their locations:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph -c <em class="replaceable">/path/to/conf</em> -k <em class="replaceable">/path/to/keyring</em> health</pre></div></div><p>
   The Ceph cluster returns one of the following health codes:
  </p><div class="variablelist"><dl class="variablelist"><dt id="id-1.3.4.4.6.6.1"><span class="term">OSD_DOWN</span></dt><dd><p>
      One or more OSDs are marked down. The OSD daemon may have been stopped,
      or peer OSDs may be unable to reach the OSD over the network. Common
      causes include a stopped or crashed daemon, a down host, or a network
      outage.
     </p><p>
      Verify the host is healthy, the daemon is started, and network is
      functioning. If the daemon has crashed, the daemon log file
      (<code class="filename">/var/log/ceph/ceph-osd.*</code>) may contain debugging
      information.
     </p></dd><dt id="id-1.3.4.4.6.6.2"><span class="term">OSD_<em class="replaceable">crush type</em>_DOWN, for example OSD_HOST_DOWN</span></dt><dd><p>
      All the OSDs within a particular CRUSH subtree are marked down, for
      example all OSDs on a host.
     </p></dd><dt id="id-1.3.4.4.6.6.3"><span class="term">OSD_ORPHAN</span></dt><dd><p>
      An OSD is referenced in the CRUSH map hierarchy but does not exist. The
      OSD can be removed from the CRUSH hierarchy with:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph osd crush rm osd.<em class="replaceable">ID</em></pre></div></dd><dt id="id-1.3.4.4.6.6.4"><span class="term">OSD_OUT_OF_ORDER_FULL</span></dt><dd><p>
      The usage thresholds for <span class="emphasis"><em>backfillfull</em></span> (defaults to
      0.90), <span class="emphasis"><em>nearfull</em></span> (defaults to 0.85),
      <span class="emphasis"><em>full</em></span> (defaults to 0.95), and/or
      <span class="emphasis"><em>failsafe_full</em></span> are not ascending. In particular, we
      expect <span class="emphasis"><em>backfillfull</em></span> &lt;
      <span class="emphasis"><em>nearfull</em></span>, <span class="emphasis"><em>nearfull</em></span> &lt;
      <span class="emphasis"><em>full</em></span>, and <span class="emphasis"><em>full</em></span> &lt;
      <span class="emphasis"><em>failsafe_full</em></span>.
     </p><p>
      To read the current values, run:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph health detail
HEALTH_ERR 1 full osd(s); 1 backfillfull osd(s); 1 nearfull osd(s)
osd.3 is full at 97%
osd.4 is backfill full at 91%
osd.2 is near full at 87%</pre></div><p>
      The thresholds can be adjusted with the following commands:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph osd set-backfillfull-ratio <em class="replaceable">ratio</em>
<code class="prompt user">cephadm &gt; </code>ceph osd set-nearfull-ratio <em class="replaceable">ratio</em>
<code class="prompt user">cephadm &gt; </code>ceph osd set-full-ratio <em class="replaceable">ratio</em></pre></div></dd><dt id="id-1.3.4.4.6.6.5"><span class="term">OSD_FULL</span></dt><dd><p>
      One or more OSDs has exceeded the <span class="emphasis"><em>full</em></span> threshold and
      is preventing the cluster from servicing writes. Usage by pool can be
      checked with:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph df</pre></div><p>
      The currently defined <span class="emphasis"><em>full</em></span> ratio can be seen with:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph osd dump | grep full_ratio</pre></div><p>
      A short-term workaround to restore write availability is to raise the
      full threshold by a small amount:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph osd set-full-ratio <em class="replaceable">ratio</em></pre></div><p>
      Add new storage to the cluster by deploying more OSDs, or delete existing
      data in order to free up space.
     </p></dd><dt id="id-1.3.4.4.6.6.6"><span class="term">OSD_BACKFILLFULL</span></dt><dd><p>
      One or more OSDs has exceeded the <span class="emphasis"><em>backfillfull</em></span>
      threshold, which prevents data from being allowed to rebalance to this
      device. This is an early warning that rebalancing may not be able to
      complete and that the cluster is approaching full. Usage by pool can be
      checked with:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph df</pre></div></dd><dt id="id-1.3.4.4.6.6.7"><span class="term">OSD_NEARFULL</span></dt><dd><p>
      One or more OSDs has exceeded the <span class="emphasis"><em>nearfull</em></span>
      threshold. This is an early warning that the cluster is approaching full.
      Usage by pool can be checked with:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph df</pre></div></dd><dt id="id-1.3.4.4.6.6.8"><span class="term">OSDMAP_FLAGS</span></dt><dd><p>
      One or more cluster flags of interest has been set. With the exception of
      <span class="emphasis"><em>full</em></span>, these flags can be set or cleared with:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph osd set <em class="replaceable">flag</em>
<code class="prompt user">cephadm &gt; </code>ceph osd unset <em class="replaceable">flag</em></pre></div><p>
      These flags include:
     </p><div class="variablelist"><dl class="variablelist"><dt id="id-1.3.4.4.6.6.8.2.4.1"><span class="term">full</span></dt><dd><p>
         The cluster is flagged as full and cannot service writes.
        </p></dd><dt id="id-1.3.4.4.6.6.8.2.4.2"><span class="term">pauserd, pausewr</span></dt><dd><p>
         Paused reads or writes.
        </p></dd><dt id="id-1.3.4.4.6.6.8.2.4.3"><span class="term">noup</span></dt><dd><p>
         OSDs are not allowed to start.
        </p></dd><dt id="id-1.3.4.4.6.6.8.2.4.4"><span class="term">nodown</span></dt><dd><p>
         OSD failure reports are being ignored, such that the monitors will not
         mark OSDs <span class="emphasis"><em>down</em></span>.
        </p></dd><dt id="id-1.3.4.4.6.6.8.2.4.5"><span class="term">noin</span></dt><dd><p>
         OSDs that were previously marked <span class="emphasis"><em>out</em></span> will not be
         marked back <span class="emphasis"><em>in</em></span> when they start.
        </p></dd><dt id="id-1.3.4.4.6.6.8.2.4.6"><span class="term">noout</span></dt><dd><p>
         <span class="emphasis"><em>Down</em></span> OSDs will not automatically be marked
         <span class="emphasis"><em>out</em></span> after the configured interval.
        </p></dd><dt id="id-1.3.4.4.6.6.8.2.4.7"><span class="term">nobackfill, norecover, norebalance</span></dt><dd><p>
         Recovery or data rebalancing is suspended.
        </p></dd><dt id="id-1.3.4.4.6.6.8.2.4.8"><span class="term">noscrub, nodeep_scrub</span></dt><dd><p>
         Scrubbing (see <a class="xref" href="cha-storage-datamgm.html#scrubbing" title="7.5. Scrubbing">Section 7.5, “Scrubbing”</a>) is disabled.
        </p></dd><dt id="id-1.3.4.4.6.6.8.2.4.9"><span class="term">notieragent</span></dt><dd><p>
         Cache tiering activity is suspended.
        </p></dd></dl></div></dd><dt id="id-1.3.4.4.6.6.9"><span class="term">OSD_FLAGS</span></dt><dd><p>
      One or more OSDs has a per-OSD flag of interest set. These flags include:
     </p><div class="variablelist"><dl class="variablelist"><dt id="id-1.3.4.4.6.6.9.2.2.1"><span class="term">noup</span></dt><dd><p>
         OSD is not allowed to start.
        </p></dd><dt id="id-1.3.4.4.6.6.9.2.2.2"><span class="term">nodown</span></dt><dd><p>
         Failure reports for this OSD will be ignored.
        </p></dd><dt id="id-1.3.4.4.6.6.9.2.2.3"><span class="term">noin</span></dt><dd><p>
         If this OSD was previously marked <span class="emphasis"><em>out</em></span>
         automatically after a failure, it will not be marked
         <span class="emphasis"><em>in</em></span> when it starts.
        </p></dd><dt id="id-1.3.4.4.6.6.9.2.2.4"><span class="term">noout</span></dt><dd><p>
         If this OSD is down, it will not be automatically marked
         <span class="emphasis"><em>out</em></span> after the configured interval.
        </p></dd></dl></div><p>
      Per-OSD flags can be set and cleared with:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph osd add-<em class="replaceable">flag</em> <em class="replaceable">osd-ID</em>
<code class="prompt user">cephadm &gt; </code>ceph osd rm-<em class="replaceable">flag</em> <em class="replaceable">osd-ID</em></pre></div></dd><dt id="id-1.3.4.4.6.6.10"><span class="term">OLD_CRUSH_TUNABLES</span></dt><dd><p>
      The CRUSH Map is using very old settings and should be updated. The
      oldest tunables that can be used (that is the oldest client version that
      can connect to the cluster) without triggering this health warning is
      determined by the <code class="option">mon_crush_min_required_version</code>
      configuration option.
     </p></dd><dt id="id-1.3.4.4.6.6.11"><span class="term">OLD_CRUSH_STRAW_CALC_VERSION</span></dt><dd><p>
      The CRUSH Map is using an older, non-optimal method for calculating
      intermediate weight values for straw buckets. The CRUSH Map should be
      updated to use the newer method (<code class="option">straw_calc_version</code>=1).
     </p></dd><dt id="id-1.3.4.4.6.6.12"><span class="term">CACHE_POOL_NO_HIT_SET</span></dt><dd><p>
      One or more cache pools is not configured with a hit set to track usage,
      which prevents the tiering agent from identifying cold objects to flush
      and evict from the cache. Hit sets can be configured on the cache pool
      with:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph osd pool set <em class="replaceable">poolname</em> hit_set_type <em class="replaceable">type</em>
<code class="prompt user">cephadm &gt; </code>ceph osd pool set <em class="replaceable">poolname</em> hit_set_period <em class="replaceable">period-in-seconds</em>
<code class="prompt user">cephadm &gt; </code>ceph osd pool set <em class="replaceable">poolname</em> hit_set_count <em class="replaceable">number-of-hitsets</em>
<code class="prompt user">cephadm &gt; </code>ceph osd pool set <em class="replaceable">poolname</em> hit_set_fpp <em class="replaceable">target-false-positive-rate</em></pre></div><p>
      For more information on cache tiering, see
      <a class="xref" href="cha-ceph-tiered.html" title="Chapter 11. Cache Tiering">Chapter 11, <em>Cache Tiering</em></a>.
     </p></dd><dt id="id-1.3.4.4.6.6.13"><span class="term">OSD_NO_SORTBITWISE</span></dt><dd><p>
      No pre-luminous v12 OSDs are running but the <code class="option">sortbitwise</code>
      flag has not been set. You need to set the <code class="option">sortbitwise</code>
      flag before luminous v12 or newer OSDs can start:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph osd set sortbitwise</pre></div></dd><dt id="id-1.3.4.4.6.6.14"><span class="term">POOL_FULL</span></dt><dd><p>
      One or more pools has reached its quota and is no longer allowing writes.
      You can set pool quotas and usage with:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph df detail</pre></div><p>
      You can either raise the pool quota with
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph osd pool set-quota <em class="replaceable">poolname</em> max_objects <em class="replaceable">num-objects</em>
<code class="prompt user">cephadm &gt; </code>ceph osd pool set-quota <em class="replaceable">poolname</em> max_bytes <em class="replaceable">num-bytes</em></pre></div><p>
      or delete some existing data to reduce usage.
     </p></dd><dt id="id-1.3.4.4.6.6.15"><span class="term">PG_AVAILABILITY</span></dt><dd><p>
      Data availability is reduced, meaning that the cluster is unable to
      service potential read or write requests for some data in the cluster.
      Specifically, one or more PGs is in a state that does not allow IO
      requests to be serviced. Problematic PG states include
      <span class="emphasis"><em>peering</em></span>, <span class="emphasis"><em>stale</em></span>,
      <span class="emphasis"><em>incomplete</em></span>, and the lack of
      <span class="emphasis"><em>active</em></span> (if those conditions do not clear quickly).
      Detailed information about which PGs are affected is available from:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph health detail</pre></div><p>
      In most cases the root cause is that one or more OSDs is currently down.
      The state of specific problematic PGs can be queried with:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph tell <em class="replaceable">pgid</em> query</pre></div></dd><dt id="id-1.3.4.4.6.6.16"><span class="term">PG_DEGRADED</span></dt><dd><p>
      Data redundancy is reduced for some data, meaning the cluster does not
      have the desired number of replicas for all data (for replicated pools)
      or erasure code fragments (for erasure coded pools). Specifically, one or
      more PGs have either the <span class="emphasis"><em>degraded</em></span> or
      <span class="emphasis"><em>undersized</em></span> flag set (there are not enough instances
      of that placement group in the cluster), or have not had the
      <span class="emphasis"><em>clean</em></span> flag set for some time. Detailed information
      about which PGs are affected is available from:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph health detail</pre></div><p>
      In most cases the root cause is that one or more OSDs is currently down.
      The state of specific problematic PGs can be queried with:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph tell <em class="replaceable">pgid</em> query</pre></div></dd><dt id="id-1.3.4.4.6.6.17"><span class="term">PG_DEGRADED_FULL</span></dt><dd><p>
      Data redundancy may be reduced or at risk for some data because of a lack
      of free space in the cluster. Specifically, one or more PGs has the
      <span class="emphasis"><em>backfill_toofull</em></span> or
      <span class="emphasis"><em>recovery_toofull</em></span> flag set, meaning that the cluster
      is unable to migrate or recover data because one or more OSDs is above
      the <span class="emphasis"><em>backfillfull</em></span> threshold.
     </p></dd><dt id="id-1.3.4.4.6.6.18"><span class="term">PG_DAMAGED</span></dt><dd><p>
      Data scrubbing (see <a class="xref" href="cha-storage-datamgm.html#scrubbing" title="7.5. Scrubbing">Section 7.5, “Scrubbing”</a>) has discovered some
      problems with data consistency in the cluster. Specifically, one or more
      PGs has the <span class="emphasis"><em>inconsistent</em></span> or
      <span class="emphasis"><em>snaptrim_error</em></span> flag is set, indicating an earlier
      scrub operation found a problem, or that the <span class="emphasis"><em>repair</em></span>
      flag is set, meaning a repair for such an inconsistency is currently in
      progress.
     </p></dd><dt id="id-1.3.4.4.6.6.19"><span class="term">OSD_SCRUB_ERRORS</span></dt><dd><p>
      Recent OSD scrubs have uncovered inconsistencies.
     </p></dd><dt id="id-1.3.4.4.6.6.20"><span class="term">CACHE_POOL_NEAR_FULL</span></dt><dd><p>
      A cache tier pool is nearly full. Full in this context is determined by
      the <span class="emphasis"><em>target_max_bytes</em></span> and
      <span class="emphasis"><em>target_max_objects</em></span> properties on the cache pool.
      When the pool reaches the target threshold, write requests to the pool
      may block while data is flushed and evicted from the cache, a state that
      normally leads to very high latencies and poor performance. The cache
      pool target size can be adjusted with:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph osd pool set <em class="replaceable">cache-pool-name</em> target_max_bytes <em class="replaceable">bytes</em>
<code class="prompt user">cephadm &gt; </code>ceph osd pool set <em class="replaceable">cache-pool-name</em> target_max_objects <em class="replaceable">objects</em></pre></div><p>
      Normal cache flush and evict activity may also be throttled because of
      reduced availability or performance of the base tier, or overall cluster
      load.
     </p><p>
      Find more information about cache tiering in
      <a class="xref" href="cha-ceph-tiered.html" title="Chapter 11. Cache Tiering">Chapter 11, <em>Cache Tiering</em></a>.
     </p></dd><dt id="id-1.3.4.4.6.6.21"><span class="term">TOO_FEW_PGS</span></dt><dd><p>
      The number of PGs in use is below the configurable threshold of
      <code class="option">mon_pg_warn_min_per_osd</code> PGs per OSD. This can lead to
      suboptimal distribution and balance of data across the OSDs in the
      cluster reduce overall performance.
     </p><p>
      See
      <a class="link" href="http://docs.ceph.com/docs/master/rados/operations/placement-groups/" target="_blank">Placement
      Groups</a> for details on calculating an appropriate number of
      placement groups for your pool.
     </p></dd><dt id="id-1.3.4.4.6.6.22"><span class="term">TOO_MANY_PGS</span></dt><dd><p>
      The number of PGs in use is above the configurable threshold of
      <code class="option">mon_pg_warn_max_per_osd</code> PGs per OSD. This can lead to
      higher memory usage for OSD daemons, slower peering after cluster state
      changes (for example OSD restarts, additions, or removals), and higher
      load on the Ceph Managers and Ceph Monitors.
     </p><p>
      While the <code class="option">pg_num</code> value for existing pools cannot be
      reduced. The <code class="option">pgp_num</code> value can. This effectively
      collocates some PGs on the same sets of OSDs, mitigating some of the
      negative impacts described above. The <code class="option">pgp_num</code> value can
      be adjusted with:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph osd pool set <em class="replaceable">pool</em> pgp_num <em class="replaceable">value</em></pre></div></dd><dt id="id-1.3.4.4.6.6.23"><span class="term">SMALLER_PGP_NUM</span></dt><dd><p>
      One or more pools has a <code class="option">pgp_num</code> value less than
      <code class="option">pg_num</code>. This is normally an indication that the PG count
      was increased without also increasing the placement behavior. This is
      normally resolved by setting <code class="option">pgp_num</code> to match
      <code class="option">pg_num</code>, triggering the data migration, with:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph osd pool set <em class="replaceable">pool</em> pgp_num <em class="replaceable">pg_num_value</em></pre></div></dd><dt id="id-1.3.4.4.6.6.24"><span class="term">MANY_OBJECTS_PER_PG</span></dt><dd><p>
      One or more pools have an average number of objects per PG that is
      significantly higher than the overall cluster average. The specific
      threshold is controlled by the
      <code class="option">mon_pg_warn_max_object_skew</code> configuration value. This is
      usually an indication that the pool(s) containing most of the data in the
      cluster have too few PGs, and/or that other pools that do not contain as
      much data have too many PGs. The threshold can be raised to silence the
      health warning by adjusting the
      <code class="option">mon_pg_warn_max_object_skew</code> configuration option on the
      monitors.
     </p></dd><dt id="id-1.3.4.4.6.6.25"><span class="term">POOL_APP_NOT_ENABLED¶</span></dt><dd><p>
      A pool exists that contains one or more objects but has not been tagged
      for use by a particular application. Resolve this warning by labeling the
      pool for use by an application. For example, if the pool is used by RBD:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>rbd pool init <em class="replaceable">pool_name</em></pre></div><p>
      If the pool is being used by a custom application 'foo', you can also
      label it using the low-level command:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph osd pool application enable foo</pre></div></dd><dt id="id-1.3.4.4.6.6.26"><span class="term">POOL_FULL</span></dt><dd><p>
      One or more pools have reached (or is very close to reaching) its quota.
      The threshold to trigger this error condition is controlled by the
      <code class="option">mon_pool_quota_crit_threshold</code> configuration option. Pool
      quotas can be adjusted up or down (or removed) with:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph osd pool set-quota <em class="replaceable">pool</em> max_bytes <em class="replaceable">bytes</em>
<code class="prompt user">cephadm &gt; </code>ceph osd pool set-quota <em class="replaceable">pool</em> max_objects <em class="replaceable">objects</em></pre></div><p>
      Setting the quota value to 0 will disable the quota.
     </p></dd><dt id="id-1.3.4.4.6.6.27"><span class="term">POOL_NEAR_FULL</span></dt><dd><p>
      One or more pools are approaching their quota. The threshold to trigger
      this warning condition is controlled by the
      <code class="option">mon_pool_quota_warn_threshold</code> configuration option. Pool
      quotas can be adjusted up or down (or removed) with:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph osd osd pool set-quota <em class="replaceable">pool</em> max_bytes <em class="replaceable">bytes</em>
<code class="prompt user">cephadm &gt; </code>ceph osd osd pool set-quota <em class="replaceable">pool</em> max_objects <em class="replaceable">objects</em></pre></div><p>
      Setting the quota value to 0 will disable the quota.
     </p></dd><dt id="id-1.3.4.4.6.6.28"><span class="term">OBJECT_MISPLACED</span></dt><dd><p>
      One or more objects in the cluster are not stored on the node where the
      cluster wants it. This is an indication that data migration caused by a
      recent cluster change has not yet completed. Misplaced data is not a
      dangerous condition in itself. Data consistency is never at risk, and old
      copies of objects are never removed until the desired number of new
      copies (in the desired locations) are present.
     </p></dd><dt id="id-1.3.4.4.6.6.29"><span class="term">OBJECT_UNFOUND</span></dt><dd><p>
      One or more objects in the cluster cannot be found. Specifically, the
      OSDs know that a new or updated copy of an object should exist, but a
      copy of that version of the object has not been found on OSDs that are
      currently online. Read or write requests to the 'unfound' objects will be
      blocked. Ideally, a down OSD can be brought back online that has the more
      recent copy of the unfound object. Candidate OSDs can be identified from
      the peering state for the PG(s) responsible for the unfound object:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph tell <em class="replaceable">pgid</em> query</pre></div></dd><dt id="id-1.3.4.4.6.6.30"><span class="term">REQUEST_SLOW</span></dt><dd><p>
      One or more OSD requests is taking a long time to process. This can be an
      indication of extreme load, a slow storage device, or a software bug. You
      can query the request queue on the OSD(s) in question with the following
      command executed from the OSD host:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph daemon osd.<em class="replaceable">id</em> ops</pre></div><p>
      You can see a summary of the slowest recent requests:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph daemon osd.<em class="replaceable">id</em> dump_historic_ops</pre></div><p>
      You can find the location of an OSD with:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph osd find osd.<em class="replaceable">id</em></pre></div></dd><dt id="id-1.3.4.4.6.6.31"><span class="term">REQUEST_STUCK</span></dt><dd><p>
      One or more OSD requests have been blocked for a longer time, for example
      4096 seconds. This is an indication that either the cluster has been
      unhealthy for an extended period of time (for example not enough running
      OSDs or inactive PGs) or there is some internal problem with the OSD.
     </p></dd><dt id="id-1.3.4.4.6.6.32"><span class="term">PG_NOT_SCRUBBED</span></dt><dd><p>
      One or more PGs have not been scrubbed (see <a class="xref" href="cha-storage-datamgm.html#scrubbing" title="7.5. Scrubbing">Section 7.5, “Scrubbing”</a>)
      recently. PGs are normally scrubbed every
      <code class="option">mon_scrub_interval</code> seconds, and this warning triggers
      when <code class="option">mon_warn_not_scrubbed</code> such intervals have elapsed
      without a scrub. PGs will not scrub if they are not flagged as clean,
      which may happen if they are misplaced or degraded (see PG_AVAILABILITY
      and PG_DEGRADED above). You can manually initiate a scrub of a clean PG
      with:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph pg scrub <em class="replaceable">pgid</em></pre></div></dd><dt id="id-1.3.4.4.6.6.33"><span class="term">PG_NOT_DEEP_SCRUBBED</span></dt><dd><p>
      One or more PGs has not been deep scrubbed (see
      <a class="xref" href="cha-storage-datamgm.html#scrubbing" title="7.5. Scrubbing">Section 7.5, “Scrubbing”</a>) recently. PGs are normally scrubbed every
      <code class="option">osd_deep_mon_scrub_interval</code> seconds, and this warning
      triggers when <code class="option">mon_warn_not_deep_scrubbed</code> seconds have
      elapsed without a scrub. PGs will not (deep)scrub if they are not flagged
      as clean, which may happen if they are misplaced or degraded (see
      PG_AVAILABILITY and PG_DEGRADED above). You can manually initiate a scrub
      of a clean PG with:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph pg deep-scrub <em class="replaceable">pgid</em></pre></div></dd></dl></div></section><section class="sect1" id="monitor-watch" data-id-title="Watching a Cluster"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">4.3 </span><span class="title-name">Watching a Cluster</span> <a title="Permalink" class="permalink" href="ceph-monitor.html#monitor-watch">#</a></h2></div></div></div><p>
   You can find the immediate state of the cluster using <code class="command">ceph
   -s</code>. For example, a tiny Ceph cluster consisting of one monitor,
   and two OSDs may print the following when a workload is running:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph -s
cluster:
  id:     ea4cf6ce-80c6-3583-bb5e-95fa303c893f
  health: HEALTH_WARN
          too many PGs per OSD (408 &gt; max 300)

services:
  mon: 3 daemons, quorum ses5min1,ses5min3,ses5min2
  mgr: ses5min1(active), standbys: ses5min3, ses5min2
  mds: cephfs-1/1/1 up  {0=ses5min3=up:active}
  osd: 4 osds: 4 up, 4 in
  rgw: 1 daemon active

data:
  pools:   8 pools, 544 pgs
  objects: 253 objects, 3821 bytes
  usage:   6252 MB used, 13823 MB / 20075 MB avail
  pgs:     544 active+clean</pre></div><p>
   The output provides the following information:
  </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
     Cluster ID
    </p></li><li class="listitem"><p>
     Cluster health status
    </p></li><li class="listitem"><p>
     The monitor map epoch and the status of the monitor quorum
    </p></li><li class="listitem"><p>
     The OSD map epoch and the status of OSDs
    </p></li><li class="listitem"><p>
     The status of Ceph Managers.
    </p></li><li class="listitem"><p>
     The status of Object Gateways.
    </p></li><li class="listitem"><p>
     The placement group map version
    </p></li><li class="listitem"><p>
     The number of placement groups and pools
    </p></li><li class="listitem"><p>
     The <span class="emphasis"><em>notional</em></span> amount of data stored and the number of
     objects stored; and,
    </p></li><li class="listitem"><p>
     The total amount of data stored.
    </p></li></ul></div><div id="id-1.3.4.4.7.6" data-id-title="How Ceph Calculates Data Usage" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg"/><h6>Tip: How Ceph Calculates Data Usage</h6><p>
    The <code class="literal">used</code> value reflects the actual amount of raw storage
    used. The <code class="literal">xxx GB / xxx GB</code> value means the amount
    available (the lesser number) of the overall storage capacity of the
    cluster. The notional number reflects the size of the stored data before it
    is replicated, cloned or snapshot. Therefore, the amount of data actually
    stored typically exceeds the notional amount stored, because Ceph creates
    replicas of the data and may also use storage capacity for cloning and
    snapshotting.
   </p></div><p>
   Other commands that display immediate status information are:
  </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
     <code class="command">ceph pg stat</code>
    </p></li><li class="listitem"><p>
     <code class="command">ceph osd pool stats</code>
    </p></li><li class="listitem"><p>
     <code class="command">ceph df</code>
    </p></li><li class="listitem"><p>
     <code class="command">ceph df detail</code>
    </p></li></ul></div><p>
   To get the information updated in real time, put any of these commands
   (including <code class="command">ceph -s</code>) as an argument of the
   <code class="command">watch</code> command:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">root # </code>watch -n 10 'ceph -s'</pre></div><p>
   Press <span class="keycap">Ctrl</span><span class="key-connector">–</span><span class="keycap">C</span>
   when you are tired of watching.
  </p></section><section class="sect1" id="monitor-stats" data-id-title="Checking a Clusters Usage Stats"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">4.4 </span><span class="title-name">Checking a Cluster's Usage Stats</span> <a title="Permalink" class="permalink" href="ceph-monitor.html#monitor-stats">#</a></h2></div></div></div><p>
   To check a cluster’s data usage and distribution among pools, use the
   <code class="command">ceph df</code> command. To get more details, use <code class="command">ceph
   df detail</code>.
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph df
GLOBAL:
    SIZE       AVAIL      RAW USED     %RAW USED
    65886G     45826G        7731M            16
POOLS:
    NAME         ID     USED      %USED     MAX AVAIL     OBJECTS
    data         1      1726M        10        17676G        1629
    rbd          4      5897M        27        22365G        3547
    ecpool       6        69M       0.2        35352G          31
[...]</pre></div><p>
   The <code class="literal">GLOBAL</code> section of the output provides an overview of
   the amount of storage your cluster uses for your data.
  </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
     <code class="literal">SIZE</code>: The overall storage capacity of the cluster.
    </p></li><li class="listitem"><p>
     <code class="literal">AVAIL</code>: The amount of free space available in the
     cluster.
    </p></li><li class="listitem"><p>
     <code class="literal">RAW USED</code>: The amount of raw storage used.
    </p></li><li class="listitem"><p>
     <code class="literal">% RAW USED</code>: The percentage of raw storage used. Use
     this number in conjunction with the <code class="literal">full ratio</code> and
     <code class="literal">near full ratio</code> to ensure that you are not reaching
     your cluster’s capacity. See
     <a class="link" href="http://docs.ceph.com/docs/master/rados/configuration/mon-config-ref#storage-capacit" target="_blank">Storage
     Capacity</a> for additional details.
    </p><div id="id-1.3.4.4.8.5.4.2" data-id-title="Cluster Fill Level" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><h6>Note: Cluster Fill Level</h6><p>
      When a raw storage fill level is getting close to 100%, you need to add
      new storage to the cluster. A higher usage may lead to single full OSDs
      and cluster health problems.
     </p><p>
      Use the command <code class="command">ceph osd df tree</code> to list the fill
      level of all OSDs.
     </p></div></li></ul></div><p>
   The <code class="literal">POOLS</code> section of the output provides a list of pools
   and the notional usage of each pool. The output from this section
   <span class="emphasis"><em>does not</em></span> reflect replicas, clones or snapshots. For
   example, if you store an object with 1MB of data, the notional usage will be
   1MB, but the actual usage may be 2MB or more depending on the number of
   replicas, clones and snapshots.
  </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
     <code class="literal">NAME</code>: The name of the pool.
    </p></li><li class="listitem"><p>
     <code class="literal">ID</code>: The pool ID.
    </p></li><li class="listitem"><p>
     <code class="literal">USED</code>: The notional amount of data stored in kilobytes,
     unless the number appends M for megabytes or G for gigabytes.
    </p></li><li class="listitem"><p>
     <code class="literal">%USED</code>: The notional percentage of storage used per
     pool.
    </p></li><li class="listitem"><p>
     <code class="literal">MAX AVAIL</code>: The maximum available space in the given
     pool.
    </p></li><li class="listitem"><p>
     <code class="literal">OBJECTS</code>: The notional number of objects stored per
     pool.
    </p></li></ul></div><div id="id-1.3.4.4.8.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><h6>Note</h6><p>
    The numbers in the POOLS section are notional. They are not inclusive of
    the number of replicas, snapshots or clones. As a result, the sum of the
    USED and %USED amounts will not add up to the RAW USED and %RAW USED
    amounts in the %GLOBAL section of the output.
   </p></div></section><section class="sect1" id="monitor-osdstatus" data-id-title="Checking OSD Status"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">4.5 </span><span class="title-name">Checking OSD Status</span> <a title="Permalink" class="permalink" href="ceph-monitor.html#monitor-osdstatus">#</a></h2></div></div></div><p>
   You can check OSDs to ensure they are up and on by executing:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph osd stat</pre></div><p>
   or
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph osd dump</pre></div><p>
   You can also view OSDs according to their position in the CRUSH map.
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph osd tree</pre></div><p>
   Ceph will print a CRUSH tree with a host, its OSDs, whether they are up
   and their weight.
  </p><div class="verbatim-wrap"><pre class="screen"># id    weight  type name       up/down reweight
-1      3       pool default
-3      3               rack mainrack
-2      3                       host osd-host
0       1                               osd.0   up      1
1       1                               osd.1   up      1
2       1                               osd.2   up      1</pre></div></section><section class="sect1" id="storage-bp-monitoring-fullosd" data-id-title="Checking for Full OSDs"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">4.6 </span><span class="title-name">Checking for Full OSDs</span> <a title="Permalink" class="permalink" href="ceph-monitor.html#storage-bp-monitoring-fullosd">#</a></h2></div></div></div><p>
   Ceph prevents you from writing to a full OSD so that you do not lose data.
   In an operational cluster, you should receive a warning when your cluster is
   getting near its full ratio. The <code class="command">mon osd full ratio</code>
   defaults to 0.95, or 95% of capacity before it stops clients from writing
   data. The <code class="command">mon osd nearfull ratio</code> defaults to 0.85, or 85%
   of capacity, when it generates a health warning.
  </p><p>
   Full OSD nodes will be reported by <code class="command">ceph health</code>:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph health
  HEALTH_WARN 1 nearfull osds
  osd.2 is near full at 85%</pre></div><p>
   or
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph health
  HEALTH_ERR 1 nearfull osds, 1 full osds
  osd.2 is near full at 85%
  osd.3 is full at 97%</pre></div><p>
   The best way to deal with a full cluster is to add new OSD hosts/disks
   allowing the cluster to redistribute data to the newly available storage.
  </p><div id="id-1.3.4.4.10.8" data-id-title="Preventing Full OSDs" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg"/><h6>Tip: Preventing Full OSDs</h6><p>
    After an OSD becomes full—it uses 100% of its disk space—it
    will normally crash quickly without warning. Following are a few tips to
    remember when administering OSD nodes.
   </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
      Each OSD's disk space (usually mounted under
      <code class="filename">/var/lib/ceph/osd/osd-{1,2..}</code>) needs to be placed on
      a dedicated underlying disk or partition.
     </p></li><li class="listitem"><p>
      Check the Ceph configuration files and make sure that Ceph does not
      store its log file to the disks/partitions dedicated for use by OSDs.
     </p></li><li class="listitem"><p>
      Make sure that no other process writes to the disks/partitions dedicated
      for use by OSDs.
     </p></li></ul></div></div></section><section class="sect1" id="monitor-monstatus" data-id-title="Checking Monitor Status"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">4.7 </span><span class="title-name">Checking Monitor Status</span> <a title="Permalink" class="permalink" href="ceph-monitor.html#monitor-monstatus">#</a></h2></div></div></div><p>
   After you start the cluster and before first reading and/or writing data,
   check the Ceph Monitors quorum status. When the cluster is already serving
   requests, check the Ceph Monitors status periodically to ensure that they are
   running.
  </p><p>
   To display the monitor map, execute the following:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph mon stat</pre></div><p>
   or
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph mon dump</pre></div><p>
   To check the quorum status for the monitor cluster, execute the following:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph quorum_status</pre></div><p>
   Ceph will return the quorum status. For example, a Ceph cluster
   consisting of three monitors may return the following:
  </p><div class="verbatim-wrap"><pre class="screen">{ "election_epoch": 10,
  "quorum": [
        0,
        1,
        2],
  "monmap": { "epoch": 1,
      "fsid": "444b489c-4f16-4b75-83f0-cb8097468898",
      "modified": "2011-12-12 13:28:27.505520",
      "created": "2011-12-12 13:28:27.505520",
      "mons": [
            { "rank": 0,
              "name": "a",
              "addr": "192.168.1.10:6789\/0"},
            { "rank": 1,
              "name": "b",
              "addr": "192.168.1.11:6789\/0"},
            { "rank": 2,
              "name": "c",
              "addr": "192.168.1.12:6789\/0"}
           ]
    }
}</pre></div></section><section class="sect1" id="monitor-pgroupstatus" data-id-title="Checking Placement Group States"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">4.8 </span><span class="title-name">Checking Placement Group States</span> <a title="Permalink" class="permalink" href="ceph-monitor.html#monitor-pgroupstatus">#</a></h2></div></div></div><p>
   Placement groups map objects to OSDs. When you monitor your placement
   groups, you will want them to be <code class="literal">active</code> and
   <code class="literal">clean</code>. For a detailed discussion, refer to
   <a class="link" href="http://docs.ceph.com/docs/master/rados/operations/monitoring-osd-pg" target="_blank">Monitoring
   OSDs and Placement Groups.</a>
  </p></section><section class="sect1" id="monitor-adminsocket" data-id-title="Using the Admin Socket"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">4.9 </span><span class="title-name">Using the Admin Socket</span> <a title="Permalink" class="permalink" href="ceph-monitor.html#monitor-adminsocket">#</a></h2></div></div></div><p>
   The Ceph admin socket allows you to query a daemon via a socket interface.
   By default, Ceph sockets reside under <code class="filename">/var/run/ceph</code>.
   To access a daemon via the admin socket, log in to the host running the
   daemon and use the following command:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph --admin-daemon /var/run/ceph/<em class="replaceable">socket-name</em></pre></div><p>
   To view the available admin socket commands, execute the following command:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ceph --admin-daemon /var/run/ceph/<em class="replaceable">socket-name</em> help</pre></div><p>
   The admin socket command enables you to show and set your configuration at
   runtime. Refer to
   <a class="link" href="http://docs.ceph.com/docs/master/rados/configuration/ceph-conf#ceph-runtime-config" target="_blank">Viewing
   a Configuration at Runtime</a>for details.
  </p><p>
   Additionally, you can set configuration values at runtime directly (the
   admin socket bypasses the monitor, unlike <code class="command">ceph tell</code>
   <em class="replaceable">daemon-type</em>.<em class="replaceable">id</em>
   injectargs, which relies on the monitor but does not require you to log in
   directly to the host in question).
  </p></section></section><nav class="bottom-pagination"><div><a class="pagination-link prev" href="ceph-operating-services.html"><span class="pagination-relation">Previous</span><span class="pagination-label"><span class="title-number">Chapter 3 </span>Operating Ceph Services</span></a> </div><div><a class="pagination-link next" href="monitoring-alerting.html"><span class="pagination-relation">Next</span><span class="pagination-label"><span class="title-number">Chapter 5 </span>Monitoring and Alerting</span></a> </div></nav></article><aside id="_side-toc-page" class="side-toc"><div class="side-title">On this page</div><div class="toc"><ul><li><span class="sect1"><a href="ceph-monitor.html#monitor-status"><span class="title-number">4.1 </span><span class="title-name">Checking a Cluster's Status</span></a></span></li><li><span class="sect1"><a href="ceph-monitor.html#monitor-health"><span class="title-number">4.2 </span><span class="title-name">Checking Cluster Health</span></a></span></li><li><span class="sect1"><a href="ceph-monitor.html#monitor-watch"><span class="title-number">4.3 </span><span class="title-name">Watching a Cluster</span></a></span></li><li><span class="sect1"><a href="ceph-monitor.html#monitor-stats"><span class="title-number">4.4 </span><span class="title-name">Checking a Cluster's Usage Stats</span></a></span></li><li><span class="sect1"><a href="ceph-monitor.html#monitor-osdstatus"><span class="title-number">4.5 </span><span class="title-name">Checking OSD Status</span></a></span></li><li><span class="sect1"><a href="ceph-monitor.html#storage-bp-monitoring-fullosd"><span class="title-number">4.6 </span><span class="title-name">Checking for Full OSDs</span></a></span></li><li><span class="sect1"><a href="ceph-monitor.html#monitor-monstatus"><span class="title-number">4.7 </span><span class="title-name">Checking Monitor Status</span></a></span></li><li><span class="sect1"><a href="ceph-monitor.html#monitor-pgroupstatus"><span class="title-number">4.8 </span><span class="title-name">Checking Placement Group States</span></a></span></li><li><span class="sect1"><a href="ceph-monitor.html#monitor-adminsocket"><span class="title-number">4.9 </span><span class="title-name">Using the Admin Socket</span></a></span></li></ul></div><div class="side-title">Give feedback</div><ul class="feedback" id="_give-feedback"><li><a id="_feedback-reportbug" href="#" rel="nofollow" target="_blank">Report an issue</a></li><li><a id="_feedback-editurl" href="https://github.com/SUSE/doc-ses/edit/maintenance/ses5/xml/admin_operating_monitor.xml" rel="nofollow" target="_blank">Edit source document</a></li></ul><div class="side-title">Share this page</div><ul class="share"><li><a id="_share-fb" href="#" title="Facebook"> </a></li><li><a id="_share-in" href="#" title="LinkedIn"> </a></li><li><a id="_share-tw" href="#" title="Twitter"> </a></li><li><a id="_share-mail" href="#" title="E-Mail"> </a></li><li><a id="_print-button" href="#" title="Print this page"> </a></li></ul> </aside></main><footer id="_footer"><div class="growth-inhibitor"><div class="copy"><span class="copy__rights">© SUSE
                 2022</span></div></div></footer></body></html>