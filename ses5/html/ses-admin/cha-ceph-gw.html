<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes"/><title>Ceph Object Gateway | Administration Guide | SUSE Enterprise Storage 5.5 (SES 5 &amp; SES 5.5)</title><link rel="stylesheet" type="text/css" href="static/css/style.css"/>
<meta name="title" content="Ceph Object Gateway | SES 5.5 (SES 5 &amp; SES 5.5)"/>
<meta name="description" content="This chapter introduces details about administration tasks related to Object Gateway, such as checking status of the service, managing accounts, multisite gate…"/>
<meta name="product-name" content="SUSE Enterprise Storage"/>
<meta name="product-number" content="5.5 (SES 5 &amp; SES 5.5)"/>
<meta name="book-title" content="Administration Guide"/>
<meta name="chapter-title" content="Chapter 13. Ceph Object Gateway"/>
<meta name="tracker-url" content="https://bugzilla.suse.com/enter_bug.cgi"/>
<meta name="tracker-type" content="bsc"/>
<meta name="tracker-bsc-assignee" content="tbazant@suse.com"/>
<meta name="tracker-bsc-component" content="Documentation"/>
<meta name="tracker-bsc-product" content="SUSE Enterprise Storage 5"/>
<meta property="og:title" content="Ceph Object Gateway | SES 5.5 (SES 5 &amp; SES 5.5)"/>
<meta property="og:description" content="This chapter introduces details about administration tasks related to Object Gateway, such as checking status of the service, managing accounts, multisite gate…"/>
<meta property="og:type" content="article"/>
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Ceph Object Gateway | SES 5.5 (SES 5 &amp; SES 5.5)"/>
<meta name="twitter:description" content="This chapter introduces details about administration tasks related to Object Gateway, such as checking status of the service, managing accounts, multisite gate…"/>
<link rel="prev" href="part-dataccess.html" title="Part III. Accessing Cluster Data"/><link rel="next" href="cha-ceph-iscsi.html" title="Chapter 14. Ceph iSCSI Gateway"/>
<script type="text/javascript">

if ( window.location.protocol.toLowerCase() != 'file:' ) {
  document.write('<link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css"></link>');
};

</script><noscript><link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css"/></noscript><script src="static/js/jquery-1.10.2.min.js" type="text/javascript"> </script><script src="static/js/script.js" type="text/javascript"> </script><script src="static/js/highlight.min.js" type="text/javascript"> </script><script>

$(document).ready(function() {
  $('.verbatim-wrap.highlight').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});
hljs.configure({
  useBR: false
});

</script></head><body class="draft wide offline js-off" onload="$('#betawarn-button-wrap').toggle();if (document.cookie.length > 0) {if (document.cookie.indexOf('betawarn=closed') != -1){$('#betawarn').toggle()}};"><div id="betawarn" style="position:fixed;bottom:0;z-index:9025;background-color:#FDE8E8;padding:1em;margin-left:10%;margin-right:10%;display:block;border-top:.75em solid #E11;width:80%"><p style="color:#333;margin:1em 0;padding:0;">This is a draft document that was built and uploaded automatically. It may document beta software and be incomplete or even incorrect. <strong>Use this document at your own risk.</strong></p> <div id="betawarn-button-wrap" style="display:none;margin:0;padding:0;"><a href="#" onclick="$('#betawarn').toggle();var d=new Date();d.setTime(d.getTime()+(0.5*24*60*60*1000));document.cookie='betawarn=closed; expires='+d.toUTCString()+'; path=/'; return false;" style="color:#333;text-decoration:underline;float:left;margin-top:.5em;padding:1em;display:block;background-color:#FABEBE;">I understand this is a draft</a></div></div><div class="bypass-block"><a href="#_content">Jump to content</a><a href="#_bottom-pagination">Jump to page navigation: previous page [access key p]/next page [access key n]</a></div><header id="_mainnav"><div class="growth-inhibitor"><img src="static/images/logo.svg" alt="Logo" class="logo"/></div></header><div class="crumbs"><div class="growth-inhibitor"><a class="crumb" href="index.html">Administration Guide</a><span> / </span><a class="crumb" href="part-dataccess.html">Accessing Cluster Data</a><span> / </span><a class="crumb" href="cha-ceph-gw.html">Ceph Object Gateway</a></div></div><main id="_content"><nav id="_side-toc-overall" class="side-toc"><div class="side-title">Administration Guide</div><ol><li><a href="bk01pr01.html" class=" "><span class="title-number"> </span><span class="title-name">About This Guide</span></a></li><li><a href="part-cluster-managment.html" class="has-children "><span class="title-number">I </span><span class="title-name">Cluster Management</span></a><ol><li><a href="storage-salt-cluster.html" class=" "><span class="title-number">1 </span><span class="title-name">Salt Cluster Administration</span></a></li></ol></li><li><a href="part-operate.html" class="has-children "><span class="title-number">II </span><span class="title-name">Operating a Cluster</span></a><ol><li><a href="cha-ceph-operating.html" class=" "><span class="title-number">2 </span><span class="title-name">Introduction</span></a></li><li><a href="ceph-operating-services.html" class=" "><span class="title-number">3 </span><span class="title-name">Operating Ceph Services</span></a></li><li><a href="ceph-monitor.html" class=" "><span class="title-number">4 </span><span class="title-name">Determining Cluster State</span></a></li><li><a href="monitoring-alerting.html" class=" "><span class="title-number">5 </span><span class="title-name">Monitoring and Alerting</span></a></li><li><a href="cha-storage-cephx.html" class=" "><span class="title-number">6 </span><span class="title-name">Authentication with <code class="systemitem">cephx</code></span></a></li><li><a href="cha-storage-datamgm.html" class=" "><span class="title-number">7 </span><span class="title-name">Stored Data Management</span></a></li><li><a href="ceph-pools.html" class=" "><span class="title-number">8 </span><span class="title-name">Managing Storage Pools</span></a></li><li><a href="ceph-rbd.html" class=" "><span class="title-number">9 </span><span class="title-name">RADOS Block Device</span></a></li><li><a href="cha-ceph-erasure.html" class=" "><span class="title-number">10 </span><span class="title-name">Erasure Coded Pools</span></a></li><li><a href="cha-ceph-tiered.html" class=" "><span class="title-number">11 </span><span class="title-name">Cache Tiering</span></a></li><li><a href="cha-ceph-configuration.html" class=" "><span class="title-number">12 </span><span class="title-name">Ceph Cluster Configuration</span></a></li></ol></li><li class="active"><a href="part-dataccess.html" class="has-children you-are-here"><span class="title-number">III </span><span class="title-name">Accessing Cluster Data</span></a><ol><li><a href="cha-ceph-gw.html" class=" you-are-here"><span class="title-number">13 </span><span class="title-name">Ceph Object Gateway</span></a></li><li><a href="cha-ceph-iscsi.html" class=" "><span class="title-number">14 </span><span class="title-name">Ceph iSCSI Gateway</span></a></li><li><a href="cha-ceph-cephfs.html" class=" "><span class="title-number">15 </span><span class="title-name">Clustered File System</span></a></li><li><a href="cha-ceph-nfsganesha.html" class=" "><span class="title-number">16 </span><span class="title-name">NFS Ganesha: Export Ceph Data via NFS</span></a></li></ol></li><li><a href="part-gui.html" class="has-children "><span class="title-number">IV </span><span class="title-name">Managing Cluster with GUI Tools</span></a><ol><li><a href="ceph-oa.html" class=" "><span class="title-number">17 </span><span class="title-name">openATTIC</span></a></li></ol></li><li><a href="part-virt.html" class="has-children "><span class="title-number">V </span><span class="title-name">Integration with Virtualization Tools</span></a><ol><li><a href="cha-ceph-libvirt.html" class=" "><span class="title-number">18 </span><span class="title-name">Using <code class="systemitem">libvirt</code> with Ceph</span></a></li><li><a href="cha-ceph-kvm.html" class=" "><span class="title-number">19 </span><span class="title-name">Ceph as a Back-end for QEMU KVM Instance</span></a></li></ol></li><li><a href="part-troubleshooting.html" class="has-children "><span class="title-number">VI </span><span class="title-name">FAQs, Tips and Troubleshooting</span></a><ol><li><a href="storage-tips.html" class=" "><span class="title-number">20 </span><span class="title-name">Hints and Tips</span></a></li><li><a href="storage-faqs.html" class=" "><span class="title-number">21 </span><span class="title-name">Frequently Asked Questions</span></a></li><li><a href="storage-troubleshooting.html" class=" "><span class="title-number">22 </span><span class="title-name">Troubleshooting</span></a></li></ol></li><li><a href="gloss-storage-glossary.html" class=" "><span class="title-number"> </span><span class="title-name">Glossary</span></a></li><li><a href="app-stage1-custom.html" class=" "><span class="title-number">A </span><span class="title-name">DeepSea Stage 1 Custom Example</span></a></li><li><a href="app-alerting-default.html" class=" "><span class="title-number">B </span><span class="title-name">Default Alerts for SUSE Enterprise Storage</span></a></li><li><a href="app-storage-manual-inst.html" class=" "><span class="title-number">C </span><span class="title-name">Example Procedure of Manual Ceph Installation</span></a></li><li><a href="ap-adm-docupdate.html" class=" "><span class="title-number">D </span><span class="title-name">Documentation Updates</span></a></li> </ol> </nav><button id="_open-side-toc-overall" title="Contents"> </button><article class="documentation"><button id="_unfold-side-toc-page">On this page</button><section class="chapter" id="cha-ceph-gw" data-id-title="Ceph Object Gateway"><div class="titlepage"><div><div class="version-info">Applies to  <span class="productname">SUSE Enterprise Storage</span> <span class="productnumber">5.5 (SES 5 &amp; SES 5.5)</span></div><div><h2 class="title"><span class="title-number">13 </span><span class="title-name">Ceph Object Gateway</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#">#</a></h2></div></div></div><p>
  This chapter introduces details about administration tasks related to Object Gateway,
  such as checking status of the service, managing accounts, multisite
  gateways, or LDAP authentication.
 </p><section class="sect1" id="sec-ceph-rgw-limits" data-id-title="Object Gateway Restrictions and Naming Limitations"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">13.1 </span><span class="title-name">Object Gateway Restrictions and Naming Limitations</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#sec-ceph-rgw-limits">#</a></h2></div></div></div><p>
   Following is a list of important Object Gateway limits:
  </p><section class="sect2" id="ogw-limits-bucket" data-id-title="Bucket Limitations"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">13.1.1 </span><span class="title-name">Bucket Limitations</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ogw-limits-bucket">#</a></h3></div></div></div><p>
    When approaching Object Gateway via the S3 API, bucket names are limited to
    DNS-compliant names with a dash character '-' allowed. When approaching
    Object Gateway via the Swift API, you may use any combination of UTF-8 supported
    characters except for a slash character '/'. The maximum length of a bucket
    name is 255 characters. Bucket names must be unique.
   </p><div id="id-1.3.5.2.4.3.3" data-id-title="Use DNS-compliant Bucket Names" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg"/><h6>Tip: Use DNS-compliant Bucket Names</h6><p>
     Although you may use any UTF-8 based bucket name via the Swift API, it
     is recommended to name buckets with regard to the S3 naming limitations to
     avoid problems accessing the same bucket via the S3 API.
    </p></div></section><section class="sect2" id="ogw-limits-object" data-id-title="Stored Object Limitations"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">13.1.2 </span><span class="title-name">Stored Object Limitations</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ogw-limits-object">#</a></h3></div></div></div><div class="variablelist"><dl class="variablelist"><dt id="id-1.3.5.2.4.4.2.1"><span class="term">Maximum number of object per user</span></dt><dd><p>
       No restriction by default (limited by ~ 2^63).
      </p></dd><dt id="id-1.3.5.2.4.4.2.2"><span class="term">Maximum number of object per bucket</span></dt><dd><p>
       No restriction by default (limited by ~ 2^63).
      </p></dd><dt id="id-1.3.5.2.4.4.2.3"><span class="term">Maximum size of an object to upload / store</span></dt><dd><p>
       Single uploads are restricted to 5GB. Use multipart for larger object
       sizes. The maximum number of multipart chunks is 10000.
      </p></dd></dl></div></section><section class="sect2" id="ogw-limits-http" data-id-title="HTTP Header Limitations"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">13.1.3 </span><span class="title-name">HTTP Header Limitations</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ogw-limits-http">#</a></h3></div></div></div><p>
    HTTP header and request limitation depend on the Web front-end used. The
    default CivetWeb restricts the number of HTTP headers to 64 headers, and
    the size of the HTTP header to 16kB.
   </p></section></section><section class="sect1" id="ogw-deploy" data-id-title="Deploying the Object Gateway"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">13.2 </span><span class="title-name">Deploying the Object Gateway</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ogw-deploy">#</a></h2></div></div></div><p>
   The recommended way of deploying the Ceph Object Gateway is via the DeepSea
   infrastructure by adding the relevant <code class="literal">role-rgw [...]</code>
   line(s) into the <code class="filename">policy.cfg</code> file on the Salt master, and
   running required DeepSea stages.
  </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
     To include the Object Gateway during the Ceph cluster deployment process, refer
     to <span class="intraxref">Book “Deployment Guide”, Chapter 4 “Deploying with DeepSea/Salt”, Section 4.3 “Cluster Deployment”</span> and
     <span class="intraxref">Book “Deployment Guide”, Chapter 4 “Deploying with DeepSea/Salt”, Section 4.5.1 “The <code class="filename">policy.cfg</code> File”</span>.
    </p></li><li class="listitem"><p>
     To add the Object Gateway role to an already deployed cluster, refer to
     <a class="xref" href="storage-salt-cluster.html#salt-adding-services" title="1.2. Adding New Roles to Nodes">Section 1.2, “Adding New Roles to Nodes”</a>.
    </p></li></ul></div></section><section class="sect1" id="ceph-rgw-operating" data-id-title="Operating the Object Gateway Service"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">13.3 </span><span class="title-name">Operating the Object Gateway Service</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-operating">#</a></h2></div></div></div><p>
   Object Gateway service is operated with the <code class="command">systemctl</code> command. You
   need to have <code class="systemitem">root</code> privileges to operate the Object Gateway service. Note that
   <em class="replaceable">gateway_host</em> is the host name of the server whose
   Object Gateway instance you need to operate.
  </p><p>
   The following subcommands are supported for the Object Gateway service:
  </p><div class="variablelist"><dl class="variablelist"><dt id="id-1.3.5.2.6.4.1"><span class="term">systemctl status ceph-radosgw@rgw.<em class="replaceable">gateway_host</em></span></dt><dd><p>
      Prints the status information of the service.
     </p></dd><dt id="id-1.3.5.2.6.4.2"><span class="term">systemctl start ceph-radosgw@rgw.<em class="replaceable">gateway_host</em></span></dt><dd><p>
      Starts the service if it is not already running.
     </p></dd><dt id="id-1.3.5.2.6.4.3"><span class="term">systemctl restart ceph-radosgw@rgw.<em class="replaceable">gateway_host</em></span></dt><dd><p>
      Restarts the service.
     </p></dd><dt id="id-1.3.5.2.6.4.4"><span class="term">systemctl stop ceph-radosgw@rgw.<em class="replaceable">gateway_host</em></span></dt><dd><p>
      Stops the running service.
     </p></dd><dt id="id-1.3.5.2.6.4.5"><span class="term">systemctl enable ceph-radosgw@rgw.<em class="replaceable">gateway_host</em></span></dt><dd><p>
      Enables the service so that it is automatically started on system
      start-up.
     </p></dd><dt id="id-1.3.5.2.6.4.6"><span class="term">systemctl disable ceph-radosgw@rgw.<em class="replaceable">gateway_host</em></span></dt><dd><p>
      Disables the service so that it is not automatically started on system
      start-up.
     </p></dd></dl></div></section><section class="sect1" id="sec-ceph-rgw-configuration" data-id-title="Configuration Parameters"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">13.4 </span><span class="title-name">Configuration Parameters</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#sec-ceph-rgw-configuration">#</a></h2></div></div></div><p>
   You can influence the Object Gateway behavior by a number of options in the
   <code class="filename">ceph.conf</code> file under the section named
  </p><div class="verbatim-wrap"><pre class="screen">[client.radosgw.<em class="replaceable">INSTANCE_NAME</em>]</pre></div><p>
   If an option is not specified, its default value is used. A complete list of
   the Object Gateway options follows:
  </p><div class="variablelist"><div class="variablelist-title-wrap"><h6 class="variablelist-title"><span class="title-name">General Settings </span><a title="Permalink" class="permalink" href="cha-ceph-gw.html#id-1.3.5.2.7.5">#</a></h6></div><dl class="variablelist"><dt id="id-1.3.5.2.7.5.2"><span class="term">rgw frontends</span></dt><dd><p>
      Configures the HTTP front end(s). Specify multiple front ends in a
      comma-delimited list. Each front end configuration may include a list of
      options separated by spaces, where each option is in the form
      “key=value” or “key”. Default is
     </p><div class="verbatim-wrap"><pre class="screen">rgw frontends = civetweb port=7480</pre></div><div id="id-1.3.5.2.7.5.2.2.3" data-id-title="tcp_nodelay" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><h6>Note: <code class="option">tcp_nodelay</code></h6><p>
       This option may affect the transfer rate of sending TCP packets,
       depending on the data chunk sizes. If set to '1', the socket option will
       disable Nagle's algorithm on the connection. Therefore packets will be
       sent as soon as possible instead of waiting for a full buffer or timeout
       to occur.
      </p></div></dd><dt id="id-1.3.5.2.7.5.3"><span class="term">rgw data</span></dt><dd><p>
      Sets the location of the data files for the Object Gateway. Default is
      <code class="filename">/var/lib/ceph/radosgw/<em class="replaceable">CLUSTER_ID</em></code>.
     </p></dd><dt id="id-1.3.5.2.7.5.4"><span class="term">rgw enable apis</span></dt><dd><p>
      Enables the specified APIs. Default is 's3, swift, swift_auth, admin All
      APIs'.
     </p></dd><dt id="id-1.3.5.2.7.5.5"><span class="term">rgw cache enabled</span></dt><dd><p>
      Enables or disables the Object Gateway cache. Default is 'true'.
     </p></dd><dt id="id-1.3.5.2.7.5.6"><span class="term">rgw cache lru size</span></dt><dd><p>
      The number of entries in the Object Gateway cache. Default is 10000.
     </p></dd><dt id="id-1.3.5.2.7.5.7"><span class="term">rgw socket path</span></dt><dd><p>
      The socket path for the domain socket.
      <code class="option">FastCgiExternalServer</code> uses this socket. If you do not
      specify a socket path, the Object Gateway will not run as an external server. The
      path you specify here needs to be the same as the path specified in the
      <code class="filename">rgw.conf</code> file.
     </p></dd><dt id="id-1.3.5.2.7.5.8"><span class="term">rgw fcgi socket backlog</span></dt><dd><p>
      The socket backlog for fcgi. Default is 1024.
     </p></dd><dt id="id-1.3.5.2.7.5.9"><span class="term">rgw host</span></dt><dd><p>
      The host for the Object Gateway instance. It can be an IP address or a hostname.
      Default is 0.0.0.0
     </p></dd><dt id="id-1.3.5.2.7.5.10"><span class="term">rgw port</span></dt><dd><p>
      The port number where the instance listens for requests. If not
      specified, the Object Gateway runs external FastCGI.
     </p></dd><dt id="id-1.3.5.2.7.5.11"><span class="term">rgw dns name</span></dt><dd><p>
      The DNS name of the served domain.
     </p></dd><dt id="id-1.3.5.2.7.5.12"><span class="term">rgw script uri</span></dt><dd><p>
      The alternative value for the SCRIPT_URI if not set in the request.
     </p></dd><dt id="id-1.3.5.2.7.5.13"><span class="term">rgw request uri</span></dt><dd><p>
      The alternative value for the REQUEST_URI if not set in the request.
     </p></dd><dt id="id-1.3.5.2.7.5.14"><span class="term">rgw print continue</span></dt><dd><p>
      Enable 100-continue if it is operational. Default is 'true'.
     </p></dd><dt id="id-1.3.5.2.7.5.15"><span class="term">rgw remote addr param</span></dt><dd><p>
      The remote address parameter. For example, the HTTP field containing the
      remote address, or the X-Forwarded-For address if a reverse proxy is
      operational. Default is REMOTE_ADDR.
     </p></dd><dt id="id-1.3.5.2.7.5.16"><span class="term">rgw op thread timeout</span></dt><dd><p>
      The timeout in seconds for open threads. Default is 600.
     </p></dd><dt id="id-1.3.5.2.7.5.17"><span class="term">rgw op thread suicide timeout</span></dt><dd><p>
      The time timeout in seconds before the Object Gateway process dies. Disabled if
      set to 0 (default).
     </p></dd><dt id="id-1.3.5.2.7.5.18"><span class="term">rgw thread pool size</span></dt><dd><p>
      Number of threads for the CivetWeb server. Increase to a higher value if
      you need to serve more requests. Defaults to 100 threads.
     </p></dd><dt id="id-1.3.5.2.7.5.19"><span class="term">rgw num rados handles</span></dt><dd><p>
      The number of RADOS cluster handles

      for Object Gateway. Having a configurable number of RADOS handles results in
      significant performance boost for all types of workloads. Each Object Gateway
      worker thread now gets to pick a RADOS handle for its lifetime. Default
      is 1.
     </p></dd><dt id="id-1.3.5.2.7.5.20"><span class="term">rgw num control oids</span></dt><dd><p>
      The number of notification objects used for cache synchronization between
      different rgw instances. Default is 8.
     </p></dd><dt id="id-1.3.5.2.7.5.21"><span class="term">rgw init timeout</span></dt><dd><p>
      The number of seconds before the Object Gateway gives up on initialization.
      Default is 30.
     </p></dd><dt id="id-1.3.5.2.7.5.22"><span class="term">rgw mime types file</span></dt><dd><p>
      The path and location of the MIME types. Used for Swift auto-detection of
      object types. Default is <code class="filename">/etc/mime.types</code>.
     </p></dd><dt id="id-1.3.5.2.7.5.23"><span class="term">rgw gc max objs</span></dt><dd><p>
      The maximum number of objects that may be handled by garbage collection
      in one garbage collection processing cycle. Default is 32.
     </p></dd><dt id="id-1.3.5.2.7.5.24"><span class="term">rgw gc obj min wait</span></dt><dd><p>
      The minimum wait time before the object may be removed and handled by
      garbage collection processing. Default is 2 * 3600.
     </p></dd><dt id="id-1.3.5.2.7.5.25"><span class="term">rgw gc processor max time</span></dt><dd><p>
      The maximum time between the beginning of two consecutive garbage
      collection processing cycles. Default is 3600.
     </p></dd><dt id="id-1.3.5.2.7.5.26"><span class="term">rgw gc processor period</span></dt><dd><p>
      The cycle time for garbage collection processing. Default is 3600.
     </p></dd><dt id="id-1.3.5.2.7.5.27"><span class="term">rgw s3 success create obj status</span></dt><dd><p>
      The alternate success status response for <code class="literal">create-obj</code>.
      Default is 0.
     </p></dd><dt id="id-1.3.5.2.7.5.28"><span class="term">rgw resolve cname</span></dt><dd><p>
      Whether the Object Gateway should use DNS CNAME record of the request host name
      field (if host name is not equal to the Object Gateway DNS name). Default is
      'false'.
     </p></dd><dt id="id-1.3.5.2.7.5.29"><span class="term">rgw obj stripe size</span></dt><dd><p>
      The size of an object stripe for Object Gateway objects. Default is 4 &lt;&lt; 20.
     </p></dd><dt id="id-1.3.5.2.7.5.30"><span class="term">rgw extended http attrs</span></dt><dd><p>
      Add a new set of attributes that can be set on an entity (for example a
      user, a bucket or an object). These extra attributes can be set through
      HTTP header fields when putting the entity or modifying it using POST
      method. If set, these attributes will return as HTTP fields when
      requesting GET/HEAD on the entity. Default is 'content_foo, content_bar,
      x-foo-bar'.
     </p></dd><dt id="id-1.3.5.2.7.5.31"><span class="term">rgw exit timeout secs</span></dt><dd><p>
      Number of seconds to wait for a process before exiting unconditionally.
      Default is 120.
     </p></dd><dt id="id-1.3.5.2.7.5.32"><span class="term">rgw get obj window size</span></dt><dd><p>
      The window size in bytes for a single object request. Default is '16
      &lt;&lt; 20'.
     </p></dd><dt id="id-1.3.5.2.7.5.33"><span class="term">rgw get obj max req size</span></dt><dd><p>
      The maximum request size of a single GET operation sent to the Ceph
      Storage Cluster. Default is 4 &lt;&lt; 20.
     </p></dd><dt id="id-1.3.5.2.7.5.34"><span class="term">rgw relaxed s3 bucket names</span></dt><dd><p>
      Enables relaxed S3 bucket names rules for US region buckets. Default is
      'false'.
     </p></dd><dt id="id-1.3.5.2.7.5.35"><span class="term">rgw list buckets max chunk</span></dt><dd><p>
      The maximum number of buckets to retrieve in a single operation when
      listing user buckets. Default is 1000.
     </p></dd><dt id="id-1.3.5.2.7.5.36"><span class="term">rgw override bucket index max shards</span></dt><dd><p>
      Represents the number of shards for the bucket index object. Setting 0
      (default) indicates there is no sharding. It is not recommended to set a
      value too large (for example 1000) as it increases the cost for bucket
      listing. This variable should be set in the client or global sections so
      that it is automatically applied to <code class="command">radosgw-admin</code>
      commands.
     </p></dd><dt id="id-1.3.5.2.7.5.37"><span class="term">rgw curl wait timeout ms</span></dt><dd><p>
      The timeout in milliseconds for certain <code class="command">curl</code> calls.
      Default is 1000.
     </p></dd><dt id="id-1.3.5.2.7.5.38"><span class="term">rgw copy obj progress</span></dt><dd><p>
      Enables output of object progress during long copy operations. Default is
      'true'.
     </p></dd><dt id="id-1.3.5.2.7.5.39"><span class="term">rgw copy obj progress every bytes</span></dt><dd><p>
      The minimum bytes between copy progress output. Default is 1024 * 1024.
     </p></dd><dt id="id-1.3.5.2.7.5.40"><span class="term">rgw admin entry</span></dt><dd><p>
      The entry point for an admin request URL. Default is 'admin'.
     </p></dd><dt id="id-1.3.5.2.7.5.41"><span class="term">rgw content length compat</span></dt><dd><p>
      Enable compatibility handling of FCGI requests with both CONTENT_LENGTH
      AND HTTP_CONTENT_LENGTH set. Default is 'false'.
     </p></dd><dt id="id-1.3.5.2.7.5.42"><span class="term">rgw bucket quota ttl</span></dt><dd><p>
      The amount of time in seconds that cached quota information is trusted.
      After this timeout, the quota information will be re-fetched from the
      cluster. Default is 600.
     </p></dd><dt id="id-1.3.5.2.7.5.43"><span class="term">rgw user quota bucket sync interval</span></dt><dd><p>
      The amount of time in seconds for which the bucket quota information is
      accumulated before syncing to the cluster. During this time, other Object Gateway
      instances will not see the changes in the bucket quota stats related to
      operations on this instance. Default is 180.
     </p></dd><dt id="id-1.3.5.2.7.5.44"><span class="term">rgw user quota sync interval</span></dt><dd><p>
      The amount of time in seconds for which user quota information is
      accumulated before syncing to the cluster. During this time, other Object Gateway
      instances will not see the changes in the user quota stats related to
      operations on this instance. Default is 180.
     </p></dd><dt id="id-1.3.5.2.7.5.45"><span class="term">rgw bucket default quota max objects</span></dt><dd><p>
      Default maximum number of objects per bucket. It is set on new users if
      no other quota is specified, and has no effect on existing users. This
      variable should be set in the client or global sections so that it is
      automatically applied to <code class="command">radosgw-admin</code> commands.
      Default is -1.
     </p></dd><dt id="id-1.3.5.2.7.5.46"><span class="term">rgw bucket default quota max size</span></dt><dd><p>
      Default maximum capacity per bucket in bytes. It is set on new users if
      no other quota is specified, and has no effect on existing users. Default
      is -1.
     </p></dd><dt id="id-1.3.5.2.7.5.47"><span class="term">rgw user default quota max objects</span></dt><dd><p>
      Default maximum number of objects for a user. This includes all objects
      in all buckets owned by the user. It is set on new users if no other
      quota is specified, and has no effect on existing users. Default is -1.
     </p></dd><dt id="id-1.3.5.2.7.5.48"><span class="term">rgw user default quota max size</span></dt><dd><p>
      The value for user maximum size quota in bytes set on new users if no
      other quota is specified. It has no effect on existing users. Default is
      -1.
     </p></dd><dt id="id-1.3.5.2.7.5.49"><span class="term">rgw verify ssl</span></dt><dd><p>
      Verify SSL certificates while making requests. Default is 'true'.
     </p></dd><dt id="id-1.3.5.2.7.5.50"><span class="term">rgw max chunk size</span></dt><dd><p>
      Maximum size of a chunk of data that will be read in a single operation.
      Increasing the value to 4MB (4194304) will provide better performance
      when processing large objects. Default is 128kB (131072).
     </p></dd></dl></div><div class="variablelist"><div class="variablelist-title-wrap"><h6 class="variablelist-title"><span class="title-name">Multisite Settings </span><a title="Permalink" class="permalink" href="cha-ceph-gw.html#id-1.3.5.2.7.6">#</a></h6></div><dl class="variablelist"><dt id="id-1.3.5.2.7.6.2"><span class="term">rgw zone</span></dt><dd><p>
      The name of the zone for the gateway instance. If no zone is set, a
      cluster-wide default can be configured with the <code class="command">radosgw-admin
      zone default</code> command.
     </p></dd><dt id="id-1.3.5.2.7.6.3"><span class="term">rgw zonegroup</span></dt><dd><p>
      The name of the zonegroup for the gateway instance. If no zonegroup is
      set, a cluster-wide default can be configured with the
      <code class="command">radosgw-admin zonegroup default</code> command.
     </p></dd><dt id="id-1.3.5.2.7.6.4"><span class="term">rgw realm</span></dt><dd><p>
      The name of the realm for the gateway instance. If no realm is set, a
      cluster-wide default can be configured with the<code class="command">radosgw-admin
      realm default</code> command.
     </p></dd><dt id="id-1.3.5.2.7.6.5"><span class="term">rgw run sync thread</span></dt><dd><p>
      If there are other zones in the realm to synchronize from, spawn threads
      to handle the synchronization of data and metadata. Default is 'true'.
     </p></dd><dt id="id-1.3.5.2.7.6.6"><span class="term">rgw data log window</span></dt><dd><p>
      The data log entries window in seconds. Default is 30/
     </p></dd><dt id="id-1.3.5.2.7.6.7"><span class="term">rgw data log changes size</span></dt><dd><p>
      The number of in-memory entries to hold for the data changes log. Default
      is 1000.
     </p></dd><dt id="id-1.3.5.2.7.6.8"><span class="term">rgw data log obj prefix</span></dt><dd><p>
      The object name prefix for the data log. Default is 'data_log'.
     </p></dd><dt id="id-1.3.5.2.7.6.9"><span class="term">rgw data log num shards</span></dt><dd><p>
      The number of shards (objects) on which to keep the data changes log.
      Default is 128.
     </p></dd><dt id="id-1.3.5.2.7.6.10"><span class="term">rgw md log max shards</span></dt><dd><p>
      The maximum number of shards for the metadata log. Default is 64.
     </p></dd></dl></div><div class="variablelist"><div class="variablelist-title-wrap"><h6 class="variablelist-title"><span class="title-name">Swift Settings </span><a title="Permalink" class="permalink" href="cha-ceph-gw.html#id-1.3.5.2.7.7">#</a></h6></div><dl class="variablelist"><dt id="id-1.3.5.2.7.7.2"><span class="term">rgw enforce swift acls</span></dt><dd><p>
      Enforces the Swift Access Control List (ACL) settings. Default is 'true'.
     </p></dd><dt id="id-1.3.5.2.7.7.3"><span class="term">rgw swift token expiration</span></dt><dd><p>
      The time in seconds for expiring a Swift token. Default is 24 * 3600.
     </p></dd><dt id="id-1.3.5.2.7.7.4"><span class="term">rgw swift url</span></dt><dd><p>
      The URL for the Ceph Object Gateway Swift API.
     </p></dd><dt id="id-1.3.5.2.7.7.5"><span class="term">rgw swift url prefix</span></dt><dd><p>
      The URL prefix for the Swift StorageURL that goes in front of the
      “/v1” part. This allows to run several Gateway instances on the same
      host. For compatibility, setting this configuration variable to empty
      causes the default “/swift” to be used. Use explicit prefix “/”
      to start StorageURL at the root.
     </p><div id="id-1.3.5.2.7.7.5.2.2" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.svg"/><h6>Warning</h6><p>
       Setting this option to “/” will not work if S3 API is enabled. Keep
       in mind that disabling S3 will make impossible to deploy the Object Gateway in
       the multisite configuration!
      </p></div></dd><dt id="id-1.3.5.2.7.7.6"><span class="term">rgw swift auth url</span></dt><dd><p>
      Default URL for verifying v1 authentication tokens when the internal
      Swift authentication is not used.
     </p></dd><dt id="id-1.3.5.2.7.7.7"><span class="term">rgw swift auth entry</span></dt><dd><p>
      The entry point for a Swift authentication URL. Default is 'auth'.
     </p></dd><dt id="id-1.3.5.2.7.7.8"><span class="term">rgw swift versioning enabled</span></dt><dd><p>
      Enables the Object Versioning of OpenStack Object Storage API. This
      allows clients to put the <code class="literal">X-Versions-Location</code>
      attribute on containers that should be versioned. The attribute specifies
      the name of container storing archived versions. It must be owned by the
      same user that the versioned container due to access control verification
      - ACLs are <span class="emphasis"><em>not</em></span> taken into consideration. Those
      containers cannot be versioned by the S3 object versioning mechanism.
      Default is 'false'.
     </p></dd></dl></div><div class="variablelist"><div class="variablelist-title-wrap"><h6 class="variablelist-title"><span class="title-name">Logging Settings </span><a title="Permalink" class="permalink" href="cha-ceph-gw.html#id-1.3.5.2.7.8">#</a></h6></div><dl class="variablelist"><dt id="id-1.3.5.2.7.8.2"><span class="term">rgw log nonexistent bucket</span></dt><dd><p>
      Enables the Object Gateway to log a request for a non-existent bucket. Default is
      'false'.
     </p></dd><dt id="id-1.3.5.2.7.8.3"><span class="term">rgw log object name</span></dt><dd><p>
      The logging format for an object name. See the manual page <code class="command">man 1
      date</code> for details about format specifiers. Default is
      '%Y-%m-%d-%H-%i-%n'.
     </p></dd><dt id="id-1.3.5.2.7.8.4"><span class="term">rgw log object name utc</span></dt><dd><p>
      Whether a logged object name includes a UTC time. If set to 'false'
      (default), it uses the local time.
     </p></dd><dt id="id-1.3.5.2.7.8.5"><span class="term">rgw usage max shards</span></dt><dd><p>
      The maximum number of shards for usage logging. Default is 32.
     </p></dd><dt id="id-1.3.5.2.7.8.6"><span class="term">rgw usage max user shards</span></dt><dd><p>
      The maximum number of shards used for a single user’s usage logging.
      Default is 1.
     </p></dd><dt id="id-1.3.5.2.7.8.7"><span class="term">rgw enable ops log</span></dt><dd><p>
      Enable logging for each successful Object Gateway operation. Default is 'false'.
     </p></dd><dt id="id-1.3.5.2.7.8.8"><span class="term">rgw enable usage log</span></dt><dd><p>
      Enable the usage log. Default is 'false'.
     </p></dd><dt id="id-1.3.5.2.7.8.9"><span class="term">rgw ops log rados</span></dt><dd><p>
      Whether the operations log should be written to the Ceph Storage Cluster
      back end. Default is 'true'.
     </p></dd><dt id="id-1.3.5.2.7.8.10"><span class="term">rgw ops log socket path</span></dt><dd><p>
      The Unix domain socket for writing operations logs.
     </p></dd><dt id="id-1.3.5.2.7.8.11"><span class="term">rgw ops log data backlog</span></dt><dd><p>
      The maximum data backlog data size for operations logs written to a Unix
      domain socket. Default is 5 &lt;&lt; 20.
     </p></dd><dt id="id-1.3.5.2.7.8.12"><span class="term">rgw usage log flush threshold</span></dt><dd><p>
      The number of dirty merged entries in the usage log before flushing
      synchronously. Default is 1024.
     </p></dd><dt id="id-1.3.5.2.7.8.13"><span class="term">rgw usage log tick interval</span></dt><dd><p>
      Flush pending usage log data every 'n' seconds. Default is 30.
     </p></dd><dt id="id-1.3.5.2.7.8.14"><span class="term">rgw log http headers</span></dt><dd><p>
      Comma-delimited list of HTTP headers to include in log entries. Header
      names are case insensitive, and use the full header name with words
      separated by underscores. For example 'http_x_forwarded_for,
      http_x_special_k'.
     </p></dd><dt id="id-1.3.5.2.7.8.15"><span class="term">rgw intent log object name</span></dt><dd><p>
      The logging format for the intent log object name. See the manual page
      <code class="command">man 1 date</code> for details about format specifiers.
      Default is '%Y-%m-%d-%i-%n'.
     </p></dd><dt id="id-1.3.5.2.7.8.16"><span class="term">rgw intent log object name utc</span></dt><dd><p>
      Whether the intent log object name includes a UTC time. If set to 'false'
      (default), it uses the local time.
     </p></dd></dl></div><div class="variablelist"><div class="variablelist-title-wrap"><h6 class="variablelist-title"><span class="title-name">Keystone Settings </span><a title="Permalink" class="permalink" href="cha-ceph-gw.html#id-1.3.5.2.7.9">#</a></h6></div><dl class="variablelist"><dt id="id-1.3.5.2.7.9.2"><span class="term">rgw keystone url</span></dt><dd><p>
      The URL for the Keystone server.
     </p></dd><dt id="id-1.3.5.2.7.9.3"><span class="term">rgw keystone api version</span></dt><dd><p>
      The version (2 or 3) of OpenStack Identity API that should be used for
      communication with the Keystone server. Default is 2.
     </p></dd><dt id="id-1.3.5.2.7.9.4"><span class="term">rgw keystone admin domain</span></dt><dd><p>
      The name of the OpenStack domain with the administrator privilege when
      using OpenStack Identity API v3.
     </p></dd><dt id="id-1.3.5.2.7.9.5"><span class="term">rgw keystone admin project</span></dt><dd><p>
      The name of the OpenStack project with the administrator privilege when
      using OpenStack Identity API v3. If not set, the value of the
      <code class="command">rgw keystone admin tenant</code> will be used instead.
     </p></dd><dt id="id-1.3.5.2.7.9.6"><span class="term">rgw keystone admin token</span></dt><dd><p>
      The Keystone administrator token (shared secret). In the Object Gateway,
      authentication with the administrator token has priority over
      authentication with the administrator credentials (options <code class="option">rgw
      keystone admin user</code>, <code class="option">rgw keystone admin
      password</code>, <code class="option">rgw keystone admin tenant</code>,
      <code class="option">rgw keystone admin project</code>, and <code class="option">rgw keystone
      admin domain</code>). Administrator token feature is considered as
      deprecated.
     </p></dd><dt id="id-1.3.5.2.7.9.7"><span class="term">rgw keystone admin tenant</span></dt><dd><p>
      The name of the OpenStack tenant with the administrator privilege
      (Service Tenant) when using OpenStack Identity API v2.
     </p></dd><dt id="id-1.3.5.2.7.9.8"><span class="term">rgw keystone admin user</span></dt><dd><p>
      The name of the OpenStack user with the administrator privilege for
      Keystone authentication (Service User) when using OpenStack Identity API
      v2.
     </p></dd><dt id="id-1.3.5.2.7.9.9"><span class="term">rgw keystone admin password</span></dt><dd><p>
      The password for the OpenStack administrator user when using OpenStack
      Identity API v2.
     </p></dd><dt id="id-1.3.5.2.7.9.10"><span class="term">rgw keystone accepted roles</span></dt><dd><p>
      The roles required to serve requests. Default is 'Member, admin'.
     </p></dd><dt id="id-1.3.5.2.7.9.11"><span class="term">rgw keystone token cache size</span></dt><dd><p>
      The maximum number of entries in each Keystone token cache. Default is
      10000.
     </p></dd><dt id="id-1.3.5.2.7.9.12"><span class="term">rgw keystone revocation interval</span></dt><dd><p>
      The number of seconds between token revocation checks. Default is 15 *
      60.
     </p></dd><dt id="id-1.3.5.2.7.9.13"><span class="term">rgw keystone verify ssl</span></dt><dd><p>
      Verify SSL certificates while making token requests to keystone. Default
      is 'true'.
     </p></dd></dl></div><section class="sect2" id="sec-ceph-rgw-configuration-notes" data-id-title="Additional Notes"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">13.4.1 </span><span class="title-name">Additional Notes</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#sec-ceph-rgw-configuration-notes">#</a></h3></div></div></div><div class="variablelist"><dl class="variablelist"><dt id="id-1.3.5.2.7.10.2.1"><span class="term">rgw dns name</span></dt><dd><p>
       If the parameter <code class="literal">rgw dns name</code> is added to the
       <code class="filename">ceph.conf</code>, make sure that the S3 client is
       configured to direct requests at the endpoint specified by <code class="literal">rgw
       dns name</code>.
      </p></dd></dl></div></section></section><section class="sect1" id="ceph-rgw-access" data-id-title="Managing Object Gateway Access"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">13.5 </span><span class="title-name">Managing Object Gateway Access</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-access">#</a></h2></div></div></div><p>
   You can communicate with Object Gateway using either S3- or Swift-compatible
   interface. S3 interface is compatible with a large subset of the Amazon S3
   RESTful API. Swift interface is compatible with a large subset of the
   OpenStack Swift API.
  </p><p>
   Both interfaces require you to create a specific user, and install the
   relevant client software to communicate with the gateway using the user's
   secret key.
  </p><section class="sect2" id="accessing-ragos-gateway" data-id-title="Accessing Object Gateway"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">13.5.1 </span><span class="title-name">Accessing Object Gateway</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#accessing-ragos-gateway">#</a></h3></div></div></div><section class="sect3" id="id-1.3.5.2.8.4.2" data-id-title="S3 Interface Access"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">13.5.1.1 </span><span class="title-name">S3 Interface Access</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#id-1.3.5.2.8.4.2">#</a></h4></div></div></div><p>
     To access the S3 interface, you need a REST client.
     <code class="command">S3cmd</code> is a command line S3 client. You can find it in
     the
     <a class="link" href="https://build.opensuse.org/package/show/Cloud:Tools/s3cmd" target="_blank">OpenSUSE
     Build Service</a>. The repository contains versions for both SUSE Linux Enterprise and
     openSUSE based distributions.
    </p><p>
     If you want to test your access to the S3 interface, you can also write a
     small a Python script. The script will connect to Object Gateway, create a new
     bucket, and list all buckets. The values for
     <code class="option">aws_access_key_id</code> and
     <code class="option">aws_secret_access_key</code> are taken from the values of
     <code class="option">access_key</code> and <code class="option">secret_key</code> returned by
     the <code class="command">radosgw_admin</code> command from
     <a class="xref" href="cha-ceph-gw.html#adding-s3-swift-users" title="13.5.2.1. Adding S3 and Swift Users">Section 13.5.2.1, “Adding S3 and Swift Users”</a>.
    </p><div class="procedure"><div class="procedure-contents"><ol class="procedure" type="1"><li class="step"><p>
       Install the <code class="systemitem">python-boto</code> package:
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">root # </code>zypper in python-boto</pre></div></li><li class="step"><p>
       Create a new Python script called <code class="filename">s3test.py</code> with
       the following content:
       
      </p><div class="verbatim-wrap"><pre class="screen">import boto
import boto.s3.connection
access_key = '11BS02LGFB6AL6H1ADMW'
secret_key = 'vzCEkuryfn060dfee4fgQPqFrncKEIkh3ZcdOANY'
conn = boto.connect_s3(
aws_access_key_id = access_key,
aws_secret_access_key = secret_key,
host = '{hostname}',
is_secure=False,
calling_format = boto.s3.connection.OrdinaryCallingFormat(),
)
bucket = conn.create_bucket('my-new-bucket')
for bucket in conn.get_all_buckets():
  print "{name}\t{created}".format(
  name = bucket.name,
  created = bucket.creation_date,
  )</pre></div><p>
       Replace <code class="literal">{hostname}</code> with the host name of the host
       where you configured Object Gateway service, for example
       <code class="literal">gateway_host</code>.
      </p></li><li class="step"><p>
       Run the script:
      </p><div class="verbatim-wrap"><pre class="screen">python s3test.py</pre></div><p>
       The script outputs something like the following:
      </p><div class="verbatim-wrap"><pre class="screen">my-new-bucket 2015-07-22T15:37:42.000Z</pre></div></li></ol></div></div></section><section class="sect3" id="id-1.3.5.2.8.4.3" data-id-title="Swift Interface Access"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">13.5.1.2 </span><span class="title-name">Swift Interface Access</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#id-1.3.5.2.8.4.3">#</a></h4></div></div></div><p>
     To access Object Gateway via Swift interface, you need the <code class="command">swift</code>
     command line client. Its manual page <code class="command">man 1 swift</code> tells
     you more about its command line options.
    </p><p>
     The package is included in the 'Public Cloud' module for SUSE Linux Enterprise 12 SP3.
     Before installing the package, you need to activate the module and refresh
     the software repository:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">root # </code>SUSEConnect -p sle-module-public-cloud/12/x86_64
sudo zypper refresh</pre></div><p>
     To install the <code class="command">swift</code> command, run the following:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">root # </code>zypper in python-swiftclient</pre></div><p>
     The swift access uses the following syntax:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>swift -A http://<em class="replaceable">IP_ADDRESS</em>/auth/1.0 \
-U example_user:swift -K '<em class="replaceable">swift_secret_key</em>' list</pre></div><p>
     Replace <em class="replaceable">IP_ADDRESS</em> with the IP address of the
     gateway server, and <em class="replaceable">swift_secret_key</em> with its
     value from the output of the <code class="command">radosgw-admin key create</code>
     command executed for the <code class="systemitem">swift</code> user in
     <a class="xref" href="cha-ceph-gw.html#adding-s3-swift-users" title="13.5.2.1. Adding S3 and Swift Users">Section 13.5.2.1, “Adding S3 and Swift Users”</a>.
    </p><p>
     For example:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>swift -A http://gateway.example.com/auth/1.0 -U example_user:swift \
-K 'r5wWIxjOCeEO7DixD1FjTLmNYIViaC6JVhi3013h' list</pre></div><p>
     The output is:
    </p><div class="verbatim-wrap"><pre class="screen">my-new-bucket</pre></div></section></section><section class="sect2" id="s3-swift-accounts-managment" data-id-title="Managing S3 and Swift Accounts"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">13.5.2 </span><span class="title-name">Managing S3 and Swift Accounts</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#s3-swift-accounts-managment">#</a></h3></div></div></div><section class="sect3" id="adding-s3-swift-users" data-id-title="Adding S3 and Swift Users"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">13.5.2.1 </span><span class="title-name">Adding S3 and Swift Users</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#adding-s3-swift-users">#</a></h4></div></div></div><p>
     You need to create a user, access key and secret to enable end users to
     interact with the gateway. There are two types of users: a
     <span class="emphasis"><em>user</em></span> and <span class="emphasis"><em>subuser</em></span>. While
     <span class="emphasis"><em>users</em></span> are used when interacting with the S3
     interface, <span class="emphasis"><em>subusers</em></span> are users of the Swift
     interface. Each subuser is associated to a user.
    </p><p>
     Users can also be added via the DeepSea file
     <code class="filename">rgw.sls</code>. For an example, see
     <a class="xref" href="cha-ceph-nfsganesha.html#ceph-nfsganesha-customrole-rgw-multiusers" title="16.3.1. Different Object Gateway Users for NFS Ganesha">Section 16.3.1, “Different Object Gateway Users for NFS Ganesha”</a>.
    </p><p>
     To create a Swift user, follow the steps:
    </p><div class="procedure"><div class="procedure-contents"><ol class="procedure" type="1"><li class="step"><p>
       To create a Swift user—which is a <span class="emphasis"><em>subuser</em></span>
       in our terminology—you need to create the associated
       <span class="emphasis"><em>user</em></span> first.
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin user create --uid=<em class="replaceable">username</em> \
 --display-name="<em class="replaceable">display-name</em>" --email=<em class="replaceable">email</em></pre></div><p>
       For example:
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin user create \
   --uid=example_user \
   --display-name="Example User" \
   --email=penguin@example.com</pre></div></li><li class="step"><p>
       To create a subuser (Swift interface) for the user, you must specify
       the user ID (--uid=<em class="replaceable">username</em>), a subuser ID,
       and the access level for the subuser.
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin subuser create --uid=<em class="replaceable">uid</em> \
 --subuser=<em class="replaceable">uid</em> \
 --access=[ <em class="replaceable">read | write | readwrite | full</em> ]</pre></div><p>
       For example:
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin subuser create --uid=example_user \
 --subuser=example_user:swift --access=full</pre></div></li><li class="step"><p>
       Generate a secret key for the user.
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin key create \
   --gen-secret \
   --subuser=example_user:swift \
   --key-type=swift</pre></div></li><li class="step"><p>
       Both commands will output JSON-formatted data showing the user state.
       Notice the following lines, and remember the
       <code class="literal">secret_key</code> value:
      </p><div class="verbatim-wrap"><pre class="screen">"swift_keys": [
   { "user": "example_user:swift",
     "secret_key": "r5wWIxjOCeEO7DixD1FjTLmNYIViaC6JVhi3013h"}],</pre></div></li></ol></div></div><p>
     When accessing Object Gateway through the S3 interface you need to create a S3 user
     by running:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin user create --uid=<em class="replaceable">username</em> \
 --display-name="<em class="replaceable">display-name</em>" --email=<em class="replaceable">email</em></pre></div><p>
     For example:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin user create \
   --uid=example_user \
   --display-name="Example User" \
   --email=penguin@example.com</pre></div><p>
     The command also creates the user's access and secret key. Check its
     output for <code class="literal">access_key</code> and <code class="literal">secret_key</code>
     keywords and their values:
    </p><div class="verbatim-wrap"><pre class="screen">[...]
 "keys": [
       { "user": "example_user",
         "access_key": "11BS02LGFB6AL6H1ADMW",
         "secret_key": "vzCEkuryfn060dfee4fgQPqFrncKEIkh3ZcdOANY"}],
 [...]</pre></div></section><section class="sect3" id="removing-s3-swift-users" data-id-title="Removing S3 and Swift Users"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">13.5.2.2 </span><span class="title-name">Removing S3 and Swift Users</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#removing-s3-swift-users">#</a></h4></div></div></div><p>
     The procedure for deleting users is similar for S3 and Swift users. But
     in case of Swift users you may need to delete the user including its
     subusers.
    </p><p>
     To remove a S3 or Swift user (including all its subusers), specify
     <code class="option">user rm</code> and the user ID in the following command:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin user rm --uid=example_user</pre></div><p>
     To remove a subuser, specify <code class="option">subuser rm</code> and the subuser
     ID.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin subuser rm --uid=example_user:swift</pre></div><p>
     You can make use of the following options:
    </p><div class="variablelist"><dl class="variablelist"><dt id="id-1.3.5.2.8.5.3.8.1"><span class="term">--purge-data</span></dt><dd><p>
        Purges all data associated to the user ID.
       </p></dd><dt id="id-1.3.5.2.8.5.3.8.2"><span class="term">--purge-keys</span></dt><dd><p>
        Purges all keys associated to the user ID.
       </p></dd></dl></div><div id="id-1.3.5.2.8.5.3.9" data-id-title="Removing a Subuser" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg"/><h6>Tip: Removing a Subuser</h6><p>
      When you remove a subuser, you are removing access to the Swift
      interface. The user will remain in the system.
     </p></div></section><section class="sect3" id="changing-s3-swift-users-password" data-id-title="Changing S3 and Swift User Access and Secret Keys"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">13.5.2.3 </span><span class="title-name">Changing S3 and Swift User Access and Secret Keys</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#changing-s3-swift-users-password">#</a></h4></div></div></div><p>
     The <code class="literal">access_key</code> and <code class="literal">secret_key</code>
     parameters identify the Object Gateway user when accessing the gateway. Changing
     the existing user keys is the same as creating new ones, as the old keys
     get overwritten.
    </p><p>
     For S3 users, run the following:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin key create --uid=<em class="replaceable">example_user</em> --key-type=s3 --gen-access-key --gen-secret</pre></div><p>
     For Swift users, run the following:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin key create --subuser=<em class="replaceable">example_user</em>:swift --key-type=swift --gen-secret</pre></div><div class="variablelist"><dl class="variablelist"><dt id="id-1.3.5.2.8.5.4.7.1"><span class="term"><code class="option">--key-type=<em class="replaceable">type</em></code></span></dt><dd><p>
        Specifies the type of key. Either <code class="literal">swift</code> or
        <code class="literal">s3</code>.
       </p></dd><dt id="id-1.3.5.2.8.5.4.7.2"><span class="term"><code class="option">--gen-access-key</code></span></dt><dd><p>
        Generates a random access key (for S3 user by default).
       </p></dd><dt id="id-1.3.5.2.8.5.4.7.3"><span class="term"><code class="option">--gen-secret</code></span></dt><dd><p>
        Generates a random secret key.
       </p></dd><dt id="id-1.3.5.2.8.5.4.7.4"><span class="term"><code class="option">--secret=<em class="replaceable">key</em></code></span></dt><dd><p>
        Specifies a secret key, for example manually generated.
       </p></dd></dl></div></section><section class="sect3" id="user-quota-managment" data-id-title="User Quota Management"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">13.5.2.4 </span><span class="title-name">User Quota Management</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#user-quota-managment">#</a></h4></div></div></div><p>
     The Ceph Object Gateway enables you to set quotas on users and buckets owned by
     users. Quotas include the maximum number of objects in a bucket and the
     maximum storage size in megabytes.
    </p><p>
     Before you enable a user quota, you first need to set its parameters:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin quota set --quota-scope=user --uid=<em class="replaceable">example_user</em> \
 --max-objects=1024 --max-size=1024</pre></div><div class="variablelist"><dl class="variablelist"><dt id="id-1.3.5.2.8.5.5.5.1"><span class="term"><code class="option">--max-objects</code></span></dt><dd><p>
        Specifies the maximum number of objects. A negative value disables the
        check.
       </p></dd><dt id="id-1.3.5.2.8.5.5.5.2"><span class="term"><code class="option">--max-size</code></span></dt><dd><p>
        Specifies the maximum number of bytes. A negative value disables the
        check.
       </p></dd><dt id="id-1.3.5.2.8.5.5.5.3"><span class="term"><code class="option">--quota-scope</code></span></dt><dd><p>
        Sets the scope for the quota. The options are <code class="literal">bucket</code>
        and <code class="literal">user</code>. Bucket quotas apply to buckets a user
        owns. User quotas apply to a user.
       </p></dd></dl></div><p>
     Once you set a user quota, you may enable it:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin quota enable --quota-scope=user --uid=<em class="replaceable">example_user</em></pre></div><p>
     To disable a quota:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin quota disable --quota-scope=user --uid=<em class="replaceable">example_user</em></pre></div><p>
     To list quota settings:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin user info --uid=<em class="replaceable">example_user</em></pre></div><p>
     To update quota statistics:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin user stats --uid=<em class="replaceable">example_user</em> --sync-stats</pre></div></section></section></section><section class="sect1" id="ceph-rgw-https" data-id-title="Enabling HTTPS/SSL for Object Gateways"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">13.6 </span><span class="title-name">Enabling HTTPS/SSL for Object Gateways</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-https">#</a></h2></div></div></div><p>
   To enable the default Object Gateway role to communicate securely using SSL, you need
   to either have a CA-issued certificate, or create a self-signed one—
   not both. There are two ways to configure Object Gateway with HTTPS enabled: a simple
   way that makes use of the default settings, and an advanced way that lets you
   fine-tune HTTPS related settings.
  </p><section class="sect2" id="ogw-selfcert" data-id-title="Create a Self-Signed Certificate"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">13.6.1 </span><span class="title-name">Create a Self-Signed Certificate</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ogw-selfcert">#</a></h3></div></div></div><p>
    By default, DeepSea expects the certificate file in
    <code class="filename">/srv/salt/ceph/rgw/cert/rgw.pem</code> on the Salt master. It
    will then distribute the certificate to
    <code class="filename">/etc/ceph/rgw.pem</code> on the Salt minion with the Object Gateway
    role, where Ceph reads it.
   </p><p>
    The following procedure describes how to generate a self-signed SSL
    certificate on the Salt master node.
   </p><div class="procedure"><div class="procedure-contents"><div id="id-1.3.5.2.9.3.4.1" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><h6>Note</h6><p>
         If you have a valid certificated signed by a CA, proceed to Step 3.
       </p></div><ol class="procedure" type="1"><li class="step"><p>
      If you need your Object Gateway to be known by additional subject identities, add
      them to the <code class="option">subjectAltName</code> option in the
      <code class="literal">[v3_req]</code> section of the
      <code class="filename">/etc/ssl/openssl.cnf</code> file:
     </p><div class="verbatim-wrap"><pre class="screen">[...]
[ v3_req ]
subjectAltName = DNS:server1.example.com DNS:server2.example.com
[...]</pre></div><div id="id-1.3.5.2.9.3.4.2.3" data-id-title="IP Addresses in subjectAltName" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg"/><h6>Tip: IP Addresses in <code class="option">subjectAltName</code></h6><p>
       To use IP addresses instead of domain names in the
       <code class="option">subjectAltName</code> option, replace the example line with
       the following:
      </p><div class="verbatim-wrap"><pre class="screen">subjectAltName = IP:10.0.0.10 IP:10.0.0.11</pre></div></div></li><li class="step"><p>
      Create the key and the certificate using <code class="command">openssl</code>.
      Enter all data you need to include in your certificate. We recommend
      entering the FQDN as the common name. Before signing the certificate,
      verify that 'X509v3 Subject Alternative Name:' is included in requested
      extensions, and that the resulting certificate has "X509v3 Subject
      Alternative Name:" set.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">root@master # </code>openssl req -x509 -nodes -days 1095 \
 -newkey rsa:4096 -keyout rgw.key -out /srv/salt/ceph/rgw/cert/rgw.pem</pre></div></li><li class="step"><p>
      Append the files to the <code class="filename">rgw.pem</code>. For example:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">root@master # </code>cat rgw.key &gt;&gt; /srv/salt/ceph/rgw/cert/rgw.pem</pre></div></li></ol></div></div></section><section class="sect2" id="ogw-ssl-simple" data-id-title="Simple HTTPS Configuration"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">13.6.2 </span><span class="title-name">Simple HTTPS Configuration</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ogw-ssl-simple">#</a></h3></div></div></div><p>
    By default, Ceph on the Object Gateway node reads the
    <code class="filename">/etc/ceph/rgw.pem</code> certificate, and uses port 443 for
    secure SSL communication. If you do not need to change these values, follow
    these steps:
   </p><div class="procedure"><div class="procedure-contents"><ol class="procedure" type="1"><li class="step"><p>
      Edit <code class="filename">/srv/pillar/ceph/stack/global.yml</code> and add the
      following line:
     </p><div class="verbatim-wrap"><pre class="screen">rgw_init: default-ssl</pre></div></li><li class="step"><p>
      Copy the default Object Gateway SSL configuration to the
      <code class="filename">ceph.conf.d</code> subdirectory:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">root@master # </code>cp /srv/salt/ceph/configuration/files/rgw-ssl.conf \
 /srv/salt/ceph/configuration/files/ceph.conf.d/rgw.conf</pre></div></li><li class="step"><p>
      Run DeepSea Stages 2, 3, and 4 to apply the changes:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">root@master # </code>salt-run state.orch ceph.stage.2
<code class="prompt user">root@master # </code>salt-run state.orch ceph.stage.3
<code class="prompt user">root@master # </code>salt-run state.orch ceph.stage.4</pre></div></li></ol></div></div></section><section class="sect2" id="ogw-ssl-advanced" data-id-title="Advanced HTTPS Configuration"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">13.6.3 </span><span class="title-name">Advanced HTTPS Configuration</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ogw-ssl-advanced">#</a></h3></div></div></div><p>
    If you need to change the default values for SSL settings of the Object Gateway,
    follow these steps:
   </p><div class="procedure"><div class="procedure-contents"><ol class="procedure" type="1"><li class="step"><p>
      Edit <code class="filename">/srv/pillar/ceph/stack/global.yml</code> and add the
      following line:
     </p><div class="verbatim-wrap"><pre class="screen">rgw_init: default-ssl</pre></div></li><li class="step"><p>
      Copy the default Object Gateway SSL configuration to the
      <code class="filename">ceph.conf.d</code> subdirectory:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">root@master # </code>cp /srv/salt/ceph/configuration/files/rgw-ssl.conf \
 /srv/salt/ceph/configuration/files/ceph.conf.d/rgw.conf</pre></div></li><li class="step"><p>
      Edit
      <code class="filename">/srv/salt/ceph/configuration/files/ceph.conf.d/rgw.conf</code>
      and change the default options, such as port number or path to the SSL
      certificate, to reflect your setup.
     </p></li><li class="step"><p>
      Run DeepSea Stage 3 and 4 to apply the changes:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">root@master # </code>salt-run state.orch ceph.stage.3
<code class="prompt user">root@master # </code>salt-run state.orch ceph.stage.4</pre></div></li></ol></div></div><div id="rgw-civetweb-multiport" data-id-title="Binding to Multiple Ports" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg"/><h6>Tip: Binding to Multiple Ports</h6><p>
     The CivetWeb server can bind to multiple ports. This is useful if you need
     to access a single Object Gateway instance with both SSL and non-SSL connections.
     When specifying the ports, separate their numbers by a plus sign '+'. A
     two-port configuration line example follows:
    </p><div class="verbatim-wrap"><pre class="screen">[client.{{ client }}]
rgw_frontends = civetweb port=80+443s ssl_certificate=/etc/ceph/rgw.pem</pre></div></div></section></section><section class="sect1" id="ceph-rgw-sync" data-id-title="Sync Modules"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">13.7 </span><span class="title-name">Sync Modules</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-sync">#</a></h2></div></div></div><p>
   The <span class="emphasis"><em>multisite</em></span> functionality of Object Gateway introduced in
   Jewel allows to create multiple zones and mirror data and metadata between
   them. <span class="emphasis"><em>Sync Modules</em></span> are built atop of the multisite
   framework that allows for forwarding data and metadata to a different
   external tier. A sync module allows for a set of actions to be performed
   whenever a change in data occurs (metadata ops like bucket or user creation
   etc. are also regarded as changes in data). As the rgw multisite changes are
   eventually consistent at remote sites, changes are propagated
   asynchronously. This would allow for unlocking use cases such as backing up
   the object storage to an external cloud cluster or a custom backup solution
   using tape drives, indexing metadata in Elasticsearch etc.
  </p><section class="sect2" id="ceph-rgw-sync-zones" data-id-title="Synchronizing Zones"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">13.7.1 </span><span class="title-name">Synchronizing Zones</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-sync-zones">#</a></h3></div></div></div><p>
    A sync module configuration is local to a zone. The sync module determines
    whether the zone exports data or can only consume data that was modified in
    another zone. As of luminous the supported sync plug-ins are
    <code class="literal">elasticsearch</code>, <code class="literal">rgw</code>, which is the
    default sync plug-in that synchronizes data between the zones and
    <code class="literal">log</code> which is a trivial sync plug-in that logs the
    metadata operation that happens in the remote zones. The following sections
    are written with the example of a zone using
    <code class="literal">elasticsearch</code> sync module. The process would be similar
    for configuring any other sync plug-in.
   </p><div id="id-1.3.5.2.10.3.3" data-id-title="Default Sync Plugin" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><h6>Note: Default Sync Plugin</h6><p>
     <code class="literal">rgw</code> is the default sync plug-in and there is no need to
     explicitly configure this.
    </p></div><section class="sect3" id="ceph-rgw-sync-zones-req" data-id-title="Requirements and Assumptions"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">13.7.1.1 </span><span class="title-name">Requirements and Assumptions</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-sync-zones-req">#</a></h4></div></div></div><p>
     Let us assume a simple multisite configuration as described in
     <a class="xref" href="cha-ceph-gw.html#ceph-rgw-fed" title="13.11. Multisite Object Gateways">Section 13.11, “Multisite Object Gateways”</a> consisting of the 2 zones
     <code class="literal">us-east</code> and <code class="literal">us-west</code>. Now we add a
     third zone <code class="literal">us-east-es</code> which is a zone that only
     processes metadata from the other sites. This zone can be in the same or a
     different Ceph cluster than <code class="literal">us-east</code>. This zone would
     only consume metadata from other zones and Object Gateways in this zone will not
     serve any end user requests directly.
    </p></section><section class="sect3" id="ceph-rgw-sync-zones-configure" data-id-title="Configuring Sync Modules"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">13.7.1.2 </span><span class="title-name">Configuring Sync Modules</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-sync-zones-configure">#</a></h4></div></div></div><div class="procedure"><div class="procedure-contents"><ol class="procedure" type="1"><li class="step"><p>
       Create the third zone similar to the ones described in
       <a class="xref" href="cha-ceph-gw.html#ceph-rgw-fed" title="13.11. Multisite Object Gateways">Section 13.11, “Multisite Object Gateways”</a>, for example
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code><code class="command">radosgw-admin</code> zone create --rgw-zonegroup=us --rgw-zone=us-east-es \
--access-key={system-key} --secret={secret} --endpoints=http://rgw-es:80</pre></div></li><li class="step"><p>
       A sync module can be configured for this zone via the following
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code><code class="command">radosgw-admin</code> zone modify --rgw-zone={zone-name} --tier-type={tier-type} \
--tier-config={set of key=value pairs}</pre></div></li><li class="step"><p>
       For example in the <code class="literal">elasticsearch</code> sync module
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code><code class="command">radosgw-admin</code> zone modify --rgw-zone={zone-name} --tier-type=elasticsearch \
--tier-config=endpoint=http://localhost:9200,num_shards=10,num_replicas=1</pre></div><p>
       For the various supported tier-config options refer to
       <a class="xref" href="cha-ceph-gw.html#ceph-rgw-sync-elastic" title="13.7.2. Storing Metadata in Elasticsearch">Section 13.7.2, “Storing Metadata in Elasticsearch”</a>.
      </p></li><li class="step"><p>
       Finally update the period
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code><code class="command">radosgw-admin</code> period update --commit</pre></div></li><li class="step"><p>
       Now start the radosgw in the zone
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">root # </code><code class="command">systemctl</code> start ceph-radosgw@rgw.`hostname -s`
<code class="prompt user">root # </code><code class="command">systemctl</code> enable ceph-radosgw@rgw.`hostname -s`</pre></div></li></ol></div></div></section></section><section class="sect2" id="ceph-rgw-sync-elastic" data-id-title="Storing Metadata in Elasticsearch"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">13.7.2 </span><span class="title-name">Storing Metadata in Elasticsearch</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-sync-elastic">#</a></h3></div></div></div><p>
    This sync module writes the metadata from other zones to Elasticsearch. As
    of luminous this is JSON of data fields we currently store in
    Elasticsearch.
   </p><div class="verbatim-wrap"><pre class="screen">{
  "_index" : "rgw-gold-ee5863d6",
  "_type" : "object",
  "_id" : "34137443-8592-48d9-8ca7-160255d52ade.34137.1:object1:null",
  "_score" : 1.0,
  "_source" : {
    "bucket" : "testbucket123",
    "name" : "object1",
    "instance" : "null",
    "versioned_epoch" : 0,
    "owner" : {
      "id" : "user1",
      "display_name" : "user1"
    },
    "permissions" : [
      "user1"
    ],
    "meta" : {
      "size" : 712354,
      "mtime" : "2017-05-04T12:54:16.462Z",
      "etag" : "7ac66c0f148de9519b8bd264312c4d64"
    }
  }
}</pre></div><section class="sect3" id="ceph-rgw-sync-elastic-config" data-id-title="Elasticsearch Tier Type Configuration Parameters"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">13.7.2.1 </span><span class="title-name">Elasticsearch Tier Type Configuration Parameters</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-sync-elastic-config">#</a></h4></div></div></div><div class="variablelist"><dl class="variablelist"><dt id="id-1.3.5.2.10.4.4.2.1"><span class="term">endpoint</span></dt><dd><p>
        Specifies the Elasticsearch server endpoint to access.
       </p></dd><dt id="id-1.3.5.2.10.4.4.2.2"><span class="term">num_shards</span></dt><dd><p>
        <span class="emphasis"><em>(integer)</em></span> The number of shards that Elasticsearch
        will be configured with on data sync initialization. Note that this
        cannot be changed after initialization. Any change here requires
        rebuild of the Elasticsearch index and reinitialization of the data
        sync process.
       </p></dd><dt id="id-1.3.5.2.10.4.4.2.3"><span class="term">num_replicas</span></dt><dd><p>
        <span class="emphasis"><em>(integer)</em></span> The number of the replicas that
        Elasticsearch will be configured with on data sync initialization.
       </p></dd><dt id="id-1.3.5.2.10.4.4.2.4"><span class="term">explicit_custom_meta</span></dt><dd><p>
        <span class="emphasis"><em>(true | false)</em></span> Specifies whether all user custom
        metadata will be indexed, or whether user will need to configure (at
        the bucket level) what customer metadata entries should be indexed.
        This is false by default
       </p></dd><dt id="id-1.3.5.2.10.4.4.2.5"><span class="term">index_buckets_list</span></dt><dd><p>
        <span class="emphasis"><em>(comma separated list of strings)</em></span> If empty, all
        buckets will be indexed. Otherwise, only buckets specified here will be
        indexed. It is possible to provide bucket prefixes (for example
        'foo*'), or bucket suffixes (for example '*bar').
       </p></dd><dt id="id-1.3.5.2.10.4.4.2.6"><span class="term">approved_owners_list</span></dt><dd><p>
        <span class="emphasis"><em>(comma separated list of strings)</em></span> If empty,
        buckets of all owners will be indexed (subject to other restrictions),
        otherwise, only buckets owned by specified owners will be indexed.
        Suffixes and prefixes can also be provided.
       </p></dd><dt id="id-1.3.5.2.10.4.4.2.7"><span class="term">override_index_path</span></dt><dd><p>
        <span class="emphasis"><em>(string)</em></span> if not empty, this string will be used as
        the Elasticsearch index path. Otherwise the index path will be
        determined and generated on sync initialization.
       </p></dd></dl></div></section><section class="sect3" id="ceph-rgw-sync-elastic-query" data-id-title="Metadata Queries"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">13.7.2.2 </span><span class="title-name">Metadata Queries</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-sync-elastic-query">#</a></h4></div></div></div><p>
     Since the Elasticsearch cluster now stores object metadata, it is
     important that the Elasticsearch endpoint is not exposed to the public and
     only accessible to the cluster administrators. For exposing metadata
     queries to the end user itself this poses a problem since we'd want the
     user to only query their metadata and not of any other users, this would
     require the Elasticsearch cluster to authenticate users in a way similar
     to RGW does which poses a problem.
    </p><p>
     As of Luminous RGW in the metadata master zone can now service end user
     requests. This allows for not exposing the Elasticsearch endpoint in
     public and also solves the authentication and authorization problem since
     RGW itself can authenticate the end user requests. For this purpose RGW
     introduces a new query in the bucket APIs that can service Elasticsearch
     requests. All these requests must be sent to the metadata master zone.
    </p><div class="variablelist"><dl class="variablelist"><dt id="id-1.3.5.2.10.4.5.4.1"><span class="term">Get an Elasticsearch Query</span></dt><dd><div class="verbatim-wrap"><pre class="screen">GET /<em class="replaceable">BUCKET</em>?query={query-expr}</pre></div><p>
        request params:
       </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
          max-keys: max number of entries to return
         </p></li><li class="listitem"><p>
          marker: pagination marker
         </p></li></ul></div><div class="verbatim-wrap"><pre class="screen">expression := [(]&lt;arg&gt; &lt;op&gt; &lt;value&gt; [)][&lt;and|or&gt; ...]</pre></div><p>
        op is one of the following: &lt;, &lt;=, ==, &gt;=, &gt;
       </p><p>
        For example:
       </p><div class="verbatim-wrap"><pre class="screen">GET /?query=name==foo</pre></div><p>
        Will return all the indexed keys that user has read permission to, and
        are named 'foo'. The output will be a list of keys in XML that is
        similar to the S3 list buckets response.
       </p></dd><dt id="id-1.3.5.2.10.4.5.4.2"><span class="term">Configure custom metadata fields</span></dt><dd><p>
        Define which custom metadata entries should be indexed (under the
        specified bucket), and what are the types of these keys. If explicit
        custom metadata indexing is configured, this is needed so that rgw will
        index the specified custom metadata values. Otherwise it is needed in
        cases where the indexed metadata keys are of a type other than string.
       </p><div class="verbatim-wrap"><pre class="screen">POST /<em class="replaceable">BUCKET</em>?mdsearch
x-amz-meta-search: &lt;key [; type]&gt; [, ...]</pre></div><p>
        Multiple metadata fields must be comma separated, a type can be forced
        for a field with a `;`. The currently allowed types are
        string(default), integer and date, for example, if you want to index a
        custom object metadata x-amz-meta-year as int, x-amz-meta-date as type
        date and x-amz-meta-title as string, you would do
       </p><div class="verbatim-wrap"><pre class="screen">POST /mybooks?mdsearch
x-amz-meta-search: x-amz-meta-year;int, x-amz-meta-release-date;date, x-amz-meta-title;string</pre></div></dd><dt id="id-1.3.5.2.10.4.5.4.3"><span class="term">Delete custom metadata configuration</span></dt><dd><p>
        Delete custom metadata bucket configuration.
       </p><div class="verbatim-wrap"><pre class="screen">DELETE /<em class="replaceable">BUCKET</em>?mdsearch</pre></div></dd><dt id="id-1.3.5.2.10.4.5.4.4"><span class="term">Get custom metadata configuration</span></dt><dd><p>
        Retrieve custom metadata bucket configuration.
       </p><div class="verbatim-wrap"><pre class="screen">GET /<em class="replaceable">BUCKET</em>?mdsearch</pre></div></dd></dl></div></section></section></section><section class="sect1" id="ceph-rgw-ldap" data-id-title="LDAP Authentication"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">13.8 </span><span class="title-name">LDAP Authentication</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-ldap">#</a></h2></div></div></div><p>
   Apart from the default local user authentication, Object Gateway can use LDAP server
   services to authenticate users as well.
  </p><section class="sect2" id="ceph-rgw-ldap-how-works" data-id-title="Authentication Mechanism"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">13.8.1 </span><span class="title-name">Authentication Mechanism</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-ldap-how-works">#</a></h3></div></div></div><p>
    The Object Gateway extracts the user's LDAP credentials from a token. A search
    filter is constructed from the user name. The Object Gateway uses the configured
    service account to search the directory for a matching entry. If an entry
    is found, the Object Gateway attempts to bind to the found distinguished name with
    the password from the token. If the credentials are valid, the bind will
    succeed, and the Object Gateway grants access.
   </p><p>
    You can limit the allowed users by setting the base for the search to a
    specific organizational unit or by specifying a custom search filter, for
    example requiring specific group membership, custom object classes, or
    attributes.
   </p></section><section class="sect2" id="ceph-rgw-ldap-reqs" data-id-title="Requirements"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">13.8.2 </span><span class="title-name">Requirements</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-ldap-reqs">#</a></h3></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
      <span class="emphasis"><em>LDAP or Active Directory</em></span>: A running LDAP instance
      accessible by the Object Gateway.
     </p></li><li class="listitem"><p>
      <span class="emphasis"><em>Service account</em></span>: LDAP credentials to be used by the
      Object Gateway with search permissions.
     </p></li><li class="listitem"><p>
      <span class="emphasis"><em>User account</em></span>: At least one user account in the LDAP
      directory.
     </p></li></ul></div><div id="id-1.3.5.2.11.4.3" data-id-title="Do Not Overlap LDAP and Local Users" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.svg"/><h6>Important: Do Not Overlap LDAP and Local Users</h6><p>
     You should not use the same user names for local users and for users being
     authenticated by using LDAP. The Object Gateway cannot distinguish them and it
     treats them as the same user.
    </p></div><div id="id-1.3.5.2.11.4.4" data-id-title="Sanity Checks" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg"/><h6>Tip: Sanity Checks</h6><p>
     Use the <code class="command">ldapsearch</code> utility to verify the service
     account or the LDAP connection. For example:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>ldapsearch -x -D "uid=ceph,ou=system,dc=example,dc=com" -W \
-H ldaps://example.com -b "ou=users,dc=example,dc=com" 'uid=*' dn</pre></div><p>
     Make sure to use the same LDAP parameters as in the Ceph configuration
     file to eliminate possible problems.
    </p></div></section><section class="sect2" id="ceph-rgw-ldap-config" data-id-title="Configure Object Gateway to Use LDAP Authentication"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">13.8.3 </span><span class="title-name">Configure Object Gateway to Use LDAP Authentication</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-ldap-config">#</a></h3></div></div></div><p>
    The following parameters in the <code class="filename">/etc/ceph/ceph.conf</code>
    configuration file are related to the LDAP authentication:
   </p><div class="variablelist"><dl class="variablelist"><dt id="id-1.3.5.2.11.5.3.1"><span class="term"><code class="option">rgw_ldap_uri</code></span></dt><dd><p>
       Specifies the LDAP server to use. Make sure to use the
       <code class="literal">ldaps://<em class="replaceable">fqdn</em>:<em class="replaceable">port</em></code>
       parameter to avoid transmitting the plain text credentials openly.
      </p></dd><dt id="id-1.3.5.2.11.5.3.2"><span class="term"><code class="option">rgw_ldap_binddn</code></span></dt><dd><p>
       The Distinguished Name (DN) of the service account used by the Object Gateway.
      </p></dd><dt id="id-1.3.5.2.11.5.3.3"><span class="term"><code class="option">rgw_ldap_secret</code></span></dt><dd><p>
       The password for the service account.
      </p></dd><dt id="id-1.3.5.2.11.5.3.4"><span class="term">rgw_ldap_searchdn</span></dt><dd><p>
       Specifies the base in the directory information tree for searching
       users. This might be your users organizational unit or some more
       specific Organizational Unit (OU).
      </p></dd><dt id="id-1.3.5.2.11.5.3.5"><span class="term"><code class="option">rgw_ldap_dnattr</code></span></dt><dd><p>
       The attribute being used in the constructed search filter to match a
       user name. Depending on your Directory Information Tree (DIT) this would
       probably be <code class="literal">uid</code> or <code class="literal">cn</code>.
      </p></dd><dt id="id-1.3.5.2.11.5.3.6"><span class="term"><code class="option">rgw_search_filter</code></span></dt><dd><p>
       If not specified, the Object Gateway automatically constructs the search filter
       with the <code class="option">rgw_ldap_dnattr</code> setting. Use this parameter to
       narrow the list of allowed users in very flexible ways. Consult
       <a class="xref" href="cha-ceph-gw.html#ceph-rgw-ldap-filter" title="13.8.4. Using a Custom Search Filter to Limit User Access">Section 13.8.4, “Using a Custom Search Filter to Limit User Access”</a> for details.
      </p></dd></dl></div></section><section class="sect2" id="ceph-rgw-ldap-filter" data-id-title="Using a Custom Search Filter to Limit User Access"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">13.8.4 </span><span class="title-name">Using a Custom Search Filter to Limit User Access</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-ldap-filter">#</a></h3></div></div></div><p>
    There are two ways you can use the <code class="option">rgw_search_filter</code>
    parameter.
   </p><section class="sect3" id="id-1.3.5.2.11.6.3" data-id-title="Partial Filter to Further Limit the Constructed Search Filter"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">13.8.4.1 </span><span class="title-name">Partial Filter to Further Limit the Constructed Search Filter</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#id-1.3.5.2.11.6.3">#</a></h4></div></div></div><p>
     An example of a partial filter:
    </p><div class="verbatim-wrap"><pre class="screen">"objectclass=inetorgperson"</pre></div><p>
     The Object Gateway will generate the search filter as usual with the user name from
     the token and the value of <code class="option">rgw_ldap_dnattr</code>. The
     constructed filter is then combined with the partial filter from the
     <code class="option">rgw_search_filter</code> attribute. Depending on the user name
     and the settings the final search filter may become:
    </p><div class="verbatim-wrap"><pre class="screen">"(&amp;(uid=hari)(objectclass=inetorgperson))"</pre></div><p>
     In that case, user 'hari' will only be granted access if he is found in
     the LDAP directory, has an object class of 'inetorgperson', and did
     specify a valid password.
    </p></section><section class="sect3" id="id-1.3.5.2.11.6.4" data-id-title="Complete Filter"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">13.8.4.2 </span><span class="title-name">Complete Filter</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#id-1.3.5.2.11.6.4">#</a></h4></div></div></div><p>
     A complete filter must contain a <code class="option">USERNAME</code> token which
     will be substituted with the user name during the authentication attempt.
     The <code class="option">rgw_ldap_dnattr</code> parameter is not used anymore in this
     case. For example, to limit valid users to a specific group, use the
     following filter:
    </p><div class="verbatim-wrap"><pre class="screen">"(&amp;(uid=USERNAME)(memberOf=cn=ceph-users,ou=groups,dc=mycompany,dc=com))"</pre></div><div id="id-1.3.5.2.11.6.4.4" data-id-title="memberOf Attribute" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><h6>Note: <code class="literal">memberOf</code> Attribute</h6><p>
      Using the <code class="literal">memberOf</code> attribute in LDAP searches requires
      server side support from you specific LDAP server implementation.
     </p></div></section></section><section class="sect2" id="ceph-rgw-ldap-token" data-id-title="Generating an Access Token for LDAP authentication"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">13.8.5 </span><span class="title-name">Generating an Access Token for LDAP authentication</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-ldap-token">#</a></h3></div></div></div><p>
    The <code class="command">radosgw-token</code> utility generates the access token
    based on the LDAP user name and password. It outputs a base-64 encoded
    string which is the actual access token. Use your favorite S3 client (refer
    to <a class="xref" href="cha-ceph-gw.html#accessing-ragos-gateway" title="13.5.1. Accessing Object Gateway">Section 13.5.1, “Accessing Object Gateway”</a>) and specify the token as the
    access key and use an empty secret key.
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>export RGW_ACCESS_KEY_ID="<em class="replaceable">username</em>"
<code class="prompt user">cephadm &gt; </code>export RGW_SECRET_ACCESS_KEY="<em class="replaceable">password</em>"
<code class="prompt user">cephadm &gt; </code>radosgw-token --encode --ttype=ldap</pre></div><div id="id-1.3.5.2.11.7.4" data-id-title="Clear Text Credentials" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.svg"/><h6>Important: Clear Text Credentials</h6><p>
     The access token is a base-64 encoded JSON structure and contains the LDAP
     credentials as a clear text.
    </p></div><div id="id-1.3.5.2.11.7.5" data-id-title="Active Directory" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><h6>Note: Active Directory</h6><p>
     For Active Directory, use the <code class="option">--ttype=ad</code> parameter.
    </p></div></section></section><section class="sect1" id="ogw-bucket-sharding" data-id-title="Bucket Index Sharding"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">13.9 </span><span class="title-name">Bucket Index Sharding</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ogw-bucket-sharding">#</a></h2></div></div></div><p>
   The Object Gateway stores bucket index data in an index pool, which defaults to
   <code class="literal">.rgw.buckets.index</code>. If you put too many (hundreds of
   thousands) objects into a single bucket and the quota for maximum number of
   objects per bucket (<code class="option">rgw bucket default quota max objects</code>)
   is not set, the performance of the index pool may degrade. <span class="emphasis"><em>Bucket
   index sharding</em></span> prevents such performance decreases and allows a
   high number of objects per bucket.
  </p><section class="sect2" id="ogw-bucket-reshard" data-id-title="Bucket Index Resharding"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">13.9.1 </span><span class="title-name">Bucket Index Resharding</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ogw-bucket-reshard">#</a></h3></div></div></div><p>
    If a bucket has grown large and its initial configuration is not sufficient
    anymore, the bucket's index pool needs to be resharded. You can either use
    automatic online bucket index resharding (refer to
    <a class="xref" href="cha-ceph-gw.html#ogw-bucket-sharding-dyn" title="13.9.1.1. Dynamic Resharding">Section 13.9.1.1, “Dynamic Resharding”</a>, or reshard the bucket index
    offline manually (refer to <a class="xref" href="cha-ceph-gw.html#ogw-bucket-sharding-re" title="13.9.1.2. Manual Resharding">Section 13.9.1.2, “Manual Resharding”</a>.
   </p><section class="sect3" id="ogw-bucket-sharding-dyn" data-id-title="Dynamic Resharding"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">13.9.1.1 </span><span class="title-name">Dynamic Resharding</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ogw-bucket-sharding-dyn">#</a></h4></div></div></div><p>
     Since SUSE Enterprise Storage 5.5, we support online bucket resharding. It detects if
     the number of objects per bucket reaches a certain threshold, and
     automatically increases the number of shards used by the bucket index.
     This process reduces the number of entries in each bucket index shard.
    </p><p>
     The detection process runs:
    </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
       When new objects are added to the bucket.
      </p></li><li class="listitem"><p>
       In a background process that periodically scans all the buckets. This is
       needed in order to deal with existing buckets that are not being
       updated.
      </p></li></ul></div><p>
     A bucket that requires resharding is added to the
     <code class="option">reshard_log</code> queue and will be scheduled to be resharded
     later. The reshard threads run in the background and execute the scheduled
     resharding, one at a time.
    </p><div class="variablelist"><div class="variablelist-title-wrap"><h6 class="variablelist-title"><span class="title-name">Configuring Dynamic Resharding </span><a title="Permalink" class="permalink" href="cha-ceph-gw.html#id-1.3.5.2.12.3.3.6">#</a></h6></div><dl class="variablelist"><dt id="id-1.3.5.2.12.3.3.6.2"><span class="term"><code class="option">rgw_dynamic_resharding</code></span></dt><dd><p>
        Enables or disables dynamic bucket index resharding. Possible values
        are 'true' or 'false'. Defaults to 'true'.
       </p></dd><dt id="id-1.3.5.2.12.3.3.6.3"><span class="term"><code class="option">rgw_reshard_num_logs</code></span></dt><dd><p>
        Number of shards for the resharding log. Defaults to 16.
       </p></dd><dt id="id-1.3.5.2.12.3.3.6.4"><span class="term"><code class="option">rgw_reshard_bucket_lock_duration</code></span></dt><dd><p>
        Duration of lock on the bucket object during resharding. Defaults to
        120 seconds.
       </p></dd><dt id="id-1.3.5.2.12.3.3.6.5"><span class="term"><code class="option">rgw_max_objs_per_shard</code></span></dt><dd><p>
        Maximum number of objects per bucket index shard. Defaults to 100000
        objects.
       </p></dd><dt id="id-1.3.5.2.12.3.3.6.6"><span class="term"><code class="option">rgw_reshard_thread_interval</code></span></dt><dd><p>
        Maximum time between rounds of reshard thread processing. Defaults to
        600 seconds.
       </p></dd></dl></div><div id="id-1.3.5.2.12.3.3.7" data-id-title="Multisite Configurations" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.svg"/><h6>Important: Multisite Configurations</h6><p>
      Dynamic resharding is not supported in multisite environment. It is
      disabled by default since Ceph 12.2.2, but we recommend you to double
      check the setting.
     </p></div><div class="variablelist"><div class="variablelist-title-wrap"><h6 class="variablelist-title"><span class="title-name">Commands to Administer the Resharding Process </span><a title="Permalink" class="permalink" href="cha-ceph-gw.html#id-1.3.5.2.12.3.3.8">#</a></h6></div><dl class="variablelist"><dt id="id-1.3.5.2.12.3.3.8.2"><span class="term">Add a bucket to the resharding queue:</span></dt><dd><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin reshard add \
 --bucket <em class="replaceable">BUCKET_NAME</em> \
 --num-shards <em class="replaceable">NEW_NUMBER_OF_SHARDS</em></pre></div></dd><dt id="id-1.3.5.2.12.3.3.8.3"><span class="term">List resharding queue:</span></dt><dd><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin reshard list</pre></div></dd><dt id="id-1.3.5.2.12.3.3.8.4"><span class="term">Process / schedule a bucket resharding:</span></dt><dd><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin reshard process</pre></div></dd><dt id="id-1.3.5.2.12.3.3.8.5"><span class="term">Display the bucket resharding status:</span></dt><dd><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin reshard status --bucket <em class="replaceable">BUCKET_NAME</em></pre></div></dd><dt id="id-1.3.5.2.12.3.3.8.6"><span class="term">Cancel pending bucket resharding:</span></dt><dd><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin reshard cancel --bucket <em class="replaceable">BUCKET_NAME</em></pre></div></dd></dl></div></section><section class="sect3" id="ogw-bucket-sharding-re" data-id-title="Manual Resharding"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">13.9.1.2 </span><span class="title-name">Manual Resharding</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ogw-bucket-sharding-re">#</a></h4></div></div></div><p>
     Dynamic resharding mentioned in <a class="xref" href="cha-ceph-gw.html#ogw-bucket-sharding-dyn" title="13.9.1.1. Dynamic Resharding">Section 13.9.1.1, “Dynamic Resharding”</a>
     is supported only for simple Object Gateway configurations. For multisite
     configurations, use manual resharding described in this section.
    </p><p>
     To reshard the bucket index manually offline, use the following command:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin bucket reshard</pre></div><p>
     The <code class="command">bucket reshard</code> command performs the following:
    </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
       Creates a new set of bucket index objects for the specified object.
      </p></li><li class="listitem"><p>
       Spreads all objects entries of these index objects.
      </p></li><li class="listitem"><p>
       Creates a new bucket instance.
      </p></li><li class="listitem"><p>
       Links the new bucket instance with the bucket so that all new index
       operations go through the new bucket indexes.
      </p></li><li class="listitem"><p>
       Prints the old and the new bucket ID to the standard output.
      </p></li></ul></div><div class="procedure" id="id-1.3.5.2.12.3.4.7" data-id-title="Resharding the Bucket Index Pool"><div class="procedure-title-wrap"><h6 class="procedure-title"><span class="title-number">Procedure 13.1: </span><span class="title-name">Resharding the Bucket Index Pool </span><a title="Permalink" class="permalink" href="cha-ceph-gw.html#id-1.3.5.2.12.3.4.7">#</a></h6></div><div class="procedure-contents"><ol class="procedure" type="1"><li class="step"><p>
       Make sure that all operations to the bucket are stopped.
      </p></li><li class="step"><p>
       Back up the original bucket index:
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin bi list \
 --bucket=<em class="replaceable">BUCKET_NAME</em> \
 &gt; <em class="replaceable">BUCKET_NAME</em>.list.backup</pre></div></li><li class="step"><p>
       Reshard the bucket index:
      </p><div class="verbatim-wrap"><pre class="screen"> <code class="prompt user">cephadm &gt; </code>radosgw-admin reshard \
 --bucket=<em class="replaceable">BUCKET_NAME</em> \
 --num-shards=<em class="replaceable">NEW_SHARDS_NUMBER</em></pre></div><div id="id-1.3.5.2.12.3.4.7.4.3" data-id-title="Old Bucket ID" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg"/><h6>Tip: Old Bucket ID</h6><p>
        As part of its output, this command also prints the new and the old
        bucket ID. Note the old bucket ID down; you will need it to purge the
        old bucket index objects.
       </p></div></li><li class="step"><p>
       Verify that the objects are listed correctly by comparing the old bucket
       index listing with the new one. Then purge the old bucket index objects:
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin bi purge
 --bucket=<em class="replaceable">BUCKET_NAME</em>
 --bucket-id=<em class="replaceable">OLD_BUCKET_ID</em></pre></div></li></ol></div></div></section></section><section class="sect2" id="ogw-bucket-sharding-new" data-id-title="Bucket Index Sharding for New Buckets"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">13.9.2 </span><span class="title-name">Bucket Index Sharding for New Buckets</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ogw-bucket-sharding-new">#</a></h3></div></div></div><p>
    There are two options that affect bucket index sharding:
   </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
      Use the <code class="option">rgw_override_bucket_index_max_shards</code> option for
      simple configurations.
     </p></li><li class="listitem"><p>
      Use the <code class="option">bucket_index_max_shards</code> option for multisite
      configurations.
     </p></li></ul></div><p>
    Setting the options to <code class="literal">0</code> disables bucket index sharding.
    A value greater than <code class="literal">0</code> enables bucket index sharding and
    sets the maximum number of shards.
   </p><p>
    The following formula helps you calculate the recommended number of shards:
   </p><div class="verbatim-wrap"><pre class="screen">number_of_objects_expected_in_a_bucket / 100000</pre></div><p>
    Be aware that the maximum number of shards is 7877.
   </p><section class="sect3" id="id-1.3.5.2.12.4.8" data-id-title="Simple Configurations"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">13.9.2.1 </span><span class="title-name">Simple Configurations</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#id-1.3.5.2.12.4.8">#</a></h4></div></div></div><div class="procedure"><div class="procedure-contents"><ol class="procedure" type="1"><li class="step"><p>
       Open the Ceph configuration file and add or modify the following
       option:
      </p><div class="verbatim-wrap"><pre class="screen">rgw_override_bucket_index_max_shards = 12</pre></div><div id="id-1.3.5.2.12.4.8.2.1.3" data-id-title="All or One Object Gateway Instances" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg"/><h6>Tip: All or One Object Gateway Instances</h6><p>
        To configure bucket index sharding for all instances of the Object Gateway,
        include <code class="option">rgw_override_bucket_index_max_shards</code> in the
        <code class="literal">[global]</code> section.
       </p><p>
        To configure bucket index sharding only for a particular instance of
        the Object Gateway, include
        <code class="option">rgw_override_bucket_index_max_shards</code> in the related
        instance section.
       </p></div></li><li class="step"><p>
       Restart the Object Gateway. See <a class="xref" href="cha-ceph-gw.html#ceph-rgw-operating" title="13.3. Operating the Object Gateway Service">Section 13.3, “Operating the Object Gateway Service”</a> for more
       details.
      </p></li></ol></div></div></section><section class="sect3" id="id-1.3.5.2.12.4.9" data-id-title="Multisite Configurations"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">13.9.2.2 </span><span class="title-name">Multisite Configurations</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#id-1.3.5.2.12.4.9">#</a></h4></div></div></div><p>
     Multisite configurations can have a different index pool to manage
     failover. To configure a consistent shard count for zones in one zone
     group, set the <code class="option">bucket_index_max_shards</code> option in the zone
     group's configuration:
    </p><div class="procedure"><div class="procedure-contents"><ol class="procedure" type="1"><li class="step"><p>
       Export the zone group configuration to the
       <code class="filename">zonegroup.json</code> file:
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin zonegroup get &gt; zonegroup.json</pre></div></li><li class="step"><p>
       Edit the <code class="filename">zonegroup.json</code> file and set the
       <code class="option">bucket_index_max_shards</code> option for each named zone.
      </p></li><li class="step"><p>
       Reset the zone group:
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin zonegroup set &lt; zonegroup.json</pre></div></li><li class="step"><p>
       Update the period:
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin period update --commit</pre></div></li></ol></div></div></section></section></section><section class="sect1" id="ogw-keystone" data-id-title="Integrating OpenStack Keystone"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">13.10 </span><span class="title-name">Integrating OpenStack Keystone</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ogw-keystone">#</a></h2></div></div></div><p>
   OpenStack Keystone is an identity service for the OpenStack product. You can
   integrate the Object Gateway with Keystone to set up a gateway that accepts a
   Keystone authentication token. A user authorized by Keystone to access
   the gateway will be verified on the Ceph Object Gateway side and automatically created if
   needed. The Object Gateway queries Keystone periodically for a list of revoked
   tokens.
  </p><section class="sect2" id="ogw-keystone-ostack" data-id-title="Configuring OpenStack"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">13.10.1 </span><span class="title-name">Configuring OpenStack</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ogw-keystone-ostack">#</a></h3></div></div></div><p>
    Before configuring the Ceph Object Gateway, you need to configure the OpenStack Keystone to
    enable the Swift service and point it to the Ceph Object Gateway:
   </p><div class="procedure"><div class="procedure-contents"><ol class="procedure" type="1"><li class="step"><p>
      <span class="emphasis"><em>Set the Swift service.</em></span> To use OpenStack to validate
      Swift users, first create the Swift service:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>openstack service create \
 --name=swift \
 --description="Swift Service" \
 object-store</pre></div></li><li class="step"><p>
      <span class="emphasis"><em>Set the endpoints.</em></span> After you create the Swift
      service, point to the Ceph Object Gateway. Replace
      <em class="replaceable">REGION_NAME</em> with the name of the gateway’s
      zone group name or region name.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>openstack endpoint create --region <em class="replaceable">REGION_NAME</em> \
 --publicurl   "http://radosgw.example.com:8080/swift/v1" \
 --adminurl    "http://radosgw.example.com:8080/swift/v1" \
 --internalurl "http://radosgw.example.com:8080/swift/v1" \
 swift</pre></div></li><li class="step"><p>
      <span class="emphasis"><em>Verify the settings.</em></span> After you create the Swift
      service and set the endpoints, show the endpoints to verify that all the
      settings are correct.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>openstack endpoint show object-store</pre></div></li></ol></div></div></section><section class="sect2" id="ogw-keystone-ogw" data-id-title="Configuring the Ceph Object Gateway"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">13.10.2 </span><span class="title-name">Configuring the Ceph Object Gateway</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ogw-keystone-ogw">#</a></h3></div></div></div><section class="sect3" id="id-1.3.5.2.13.4.2" data-id-title="Configure SSL Certificates"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">13.10.2.1 </span><span class="title-name">Configure SSL Certificates</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#id-1.3.5.2.13.4.2">#</a></h4></div></div></div><p>
     The Ceph Object Gateway queries Keystone periodically for a list of revoked tokens.
     These requests are encoded and signed. Keystone may be also configured
     to provide self-signed tokens, which are also encoded and signed. You need
     to configure the gateway so that it can decode and verify these signed
     messages. Therefore, the OpenSSL certificates that Keystone uses to
     create the requests need to be converted to the 'nss db' format:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">root # </code>mkdir /var/ceph/nss
<code class="prompt user">root # </code>openssl x509 -in /etc/keystone/ssl/certs/ca.pem \
 -pubkey | certutil -d /var/ceph/nss -A -n ca -t "TCu,Cu,Tuw"
<code class="systemitem">root</code>openssl x509 -in /etc/keystone/ssl/certs/signing_cert.pem \
 -pubkey | certutil -A -d /var/ceph/nss -n signing_cert -t "P,P,P"</pre></div><p>
     To allow Ceph Object Gateway to interact with OpenStack Keystone, OpenStack Keystone can use a
     self-signed SSL certificate. Either install Keystone’s SSL certificate
     on the node running the Ceph Object Gateway, or alternatively set the value of the
     option <code class="option">rgw keystone verify ssl</code> to 'false'. Setting
     <code class="option">rgw keystone verify ssl</code> to 'false' means that the gateway
     will not attempt to verify the certificate.
    </p></section><section class="sect3" id="id-1.3.5.2.13.4.3" data-id-title="Configure the Object Gateways Options"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">13.10.2.2 </span><span class="title-name">Configure the Object Gateway's Options</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#id-1.3.5.2.13.4.3">#</a></h4></div></div></div><p>
     You can configure Keystone integration using the following options:
    </p><div class="variablelist"><dl class="variablelist"><dt id="id-1.3.5.2.13.4.3.3.1"><span class="term"><code class="option">rgw keystone api version</code></span></dt><dd><p>
        Version of the Keystone API. Valid options are 2 or 3. Defaults to 2.
       </p></dd><dt id="id-1.3.5.2.13.4.3.3.2"><span class="term"><code class="option">rgw keystone url</code></span></dt><dd><p>
        The URL and port number of the administrative RESTful API on the
        Keystone server. Follows the pattern
        <em class="replaceable">SERVER_URL:PORT_NUMBER</em>.
       </p></dd><dt id="id-1.3.5.2.13.4.3.3.3"><span class="term"><code class="option">rgw keystone admin token</code></span></dt><dd><p>
        The token or shared secret that is configured internally in Keystone
        for administrative requests.
       </p></dd><dt id="id-1.3.5.2.13.4.3.3.4"><span class="term"><code class="option">rgw keystone accepted roles</code></span></dt><dd><p>
        The roles required to serve requests. Defaults to 'Member, admin'.
       </p></dd><dt id="id-1.3.5.2.13.4.3.3.5"><span class="term"><code class="option">rgw keystone accepted admin roles</code></span></dt><dd><p>
        The list of roles allowing a user to gain administrative privileges.
       </p></dd><dt id="id-1.3.5.2.13.4.3.3.6"><span class="term"><code class="option">rgw keystone token cache size</code></span></dt><dd><p>
        The maximum number of entries in the Keystone token cache.
       </p></dd><dt id="id-1.3.5.2.13.4.3.3.7"><span class="term"><code class="option">rgw keystone revocation interval</code></span></dt><dd><p>
        The number of seconds before checking revoked tokens. Defaults to 15 *
        60.
       </p></dd><dt id="id-1.3.5.2.13.4.3.3.8"><span class="term"><code class="option">rgw keystone implicit tenants</code></span></dt><dd><p>
        Create new users in their own tenants of the same name. Defaults to
        'false'.
       </p></dd><dt id="id-1.3.5.2.13.4.3.3.9"><span class="term"><code class="option">rgw s3 auth use keystone</code></span></dt><dd><p>
        If set to 'true', the Ceph Object Gateway will authenticate users using Keystone.
        Defaults to 'false'.
       </p></dd><dt id="id-1.3.5.2.13.4.3.3.10"><span class="term"><code class="option">nss db path</code></span></dt><dd><p>
        The path to the NSS database.
       </p></dd></dl></div><p>
     It is also possible to configure the Keystone service tenant, user &amp;
     password for keystone (for v2.0 version of the OpenStack Identity API),
     similar to the way OpenStack services tend to be configured. This way you
     can avoid setting the shared secret <code class="option">rgw keystone admin
     token</code> in the configuration file, which should be disabled in
     production environments. The service tenant credentials should have admin
     privileges, for more details refer to the
     <a class="link" href="https://docs.openstack.org/keystone/latest/#setting-up-projects-users-and-roles" target="_blank">official
     OpenStack Keystone documentation</a>. The related configuration options
     follow:
    </p><div class="variablelist"><dl class="variablelist"><dt id="id-1.3.5.2.13.4.3.5.1"><span class="term"><code class="option">rgw keystone admin user</code></span></dt><dd><p>
        The Keystone administrator user name.
       </p></dd><dt id="id-1.3.5.2.13.4.3.5.2"><span class="term"><code class="option">rgw keystone admin password</code></span></dt><dd><p>
        The keystone administrator user password.
       </p></dd><dt id="id-1.3.5.2.13.4.3.5.3"><span class="term"><code class="option">rgw keystone admin tenant</code></span></dt><dd><p>
        The Keystone version 2.0 administrator user tenant.
       </p></dd></dl></div><p>
     A Ceph Object Gateway user is mapped to a Keystone tenant. A Keystone user has
     different roles assigned to it, possibly on more than a single tenant.
     When the Ceph Object Gateway gets the ticket, it looks at the tenant and the user roles
     that are assigned to that ticket, and accepts or rejects the request
     according to the setting of the <code class="option">rgw keystone accepted
     roles</code> option.
    </p><div id="id-1.3.5.2.13.4.3.7" data-id-title="Mapping to OpenStack Tenants" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg"/><h6>Tip: Mapping to OpenStack Tenants</h6><p>
      Although Swift tenants are mapped to the Object Gateway user by default, they
      can be also mapped to OpenStack tenants via the <code class="option">rgw keystone
      implicit tenants</code> option. This will make containers use the
      tenant namespace instead of the S3 like global namespace that the Object Gateway
      defaults to. We recommend deciding on the mapping method at the planning
      stage to avoid confusion. The reason is that toggling the option later
      affects only newer requests which get mapped under a tenant, while older
      buckets created before still continue to be in a global namespace.
     </p></div><p>
     For version 3 of the OpenStack Identity API, you should replace the
     <code class="option">rgw keystone admin tenant</code> option with:
    </p><div class="variablelist"><dl class="variablelist"><dt id="id-1.3.5.2.13.4.3.9.1"><span class="term"><code class="option">rgw keystone admin domain</code></span></dt><dd><p>
        The Keystone administrator user domain.
       </p></dd><dt id="id-1.3.5.2.13.4.3.9.2"><span class="term"><code class="option">rgw keystone admin project</code></span></dt><dd><p>
        The Keystone administrator user project.
       </p></dd></dl></div></section></section></section><section class="sect1" id="ceph-rgw-fed" data-id-title="Multisite Object Gateways"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">13.11 </span><span class="title-name">Multisite Object Gateways</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-fed">#</a></h2></div></div></div><div class="variablelist"><dl class="variablelist"><dt id="id-1.3.5.2.14.2.1"><span class="term">Zone</span></dt><dd><p>
      A logical grouping of one or more Object Gateway instances. There must be one zone
      designated as the <span class="emphasis"><em>master</em></span> zone in a
      <span class="emphasis"><em>zonegroup</em></span>, which handles all bucket and user
      creation.
     </p></dd><dt id="id-1.3.5.2.14.2.2"><span class="term">Zonegroup</span></dt><dd><p>
      A zonegroup consists of multiple zones. There should be a master
      zonegroup that will handle changes to the system configuration.
     </p></dd><dt id="id-1.3.5.2.14.2.3"><span class="term">Zonegroup map</span></dt><dd><p>
      A configuration structure that holds the map of the entire system, for
      example which zonegroup is the master, relationships between different
      zone groups, and certain configuration options such as storage policies.
     </p></dd><dt id="id-1.3.5.2.14.2.4"><span class="term">Realm</span></dt><dd><p>
      A container for zone groups. This allows for separation of zone groups
      between clusters. It is possible to create multiple realms, making it
      easier to run completely different configurations in the same cluster.
     </p></dd><dt id="id-1.3.5.2.14.2.5"><span class="term">Period</span></dt><dd><p>
      A period holds the configuration structure for the current state of the
      realm. Every period contains a unique ID and an epoch. Every realm has an
      associated current period, holding the current state of configuration of
      the zone groups and storage policies. Any configuration change for a
      non-master zone will increment the period's epoch. Changing the master
      zone to a different zone will trigger the following changes:
     </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
        A new period is generated with a new period ID and epoch of 1.
       </p></li><li class="listitem"><p>
        Realm's current period is updated to point to the newly generated
        period ID.
       </p></li><li class="listitem"><p>
        Realm's epoch is incremented.
       </p></li></ul></div></dd></dl></div><p>
   You can configure each Object Gateway to participate in a federated architecture,
   working in an active zone configuration while allowing for writes to
   non-master zones.
  </p><section class="sect2" id="ceph-rgw-fed-term" data-id-title="Terminology"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">13.11.1 </span><span class="title-name">Terminology</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-fed-term">#</a></h3></div></div></div><p>
    A description of terms specific to a federated architecture follows:
   </p></section><section class="sect2" id="ceph-rgw-fed-intro" data-id-title="Example Cluster Setup"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">13.11.2 </span><span class="title-name">Example Cluster Setup</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-fed-intro">#</a></h3></div></div></div><p>
    In this example, we will focus on creating a single zone group with three
    separate zones, which actively synchronize their data. Two zones belong to
    the same cluster, while the third belongs to a different one. There is no
    synchronization agent involved in mirroring data changes between the
    Object Gateways. This allows for a much simpler configuration scheme and
    active-active configurations. Note that metadata operations—such as
    creating a new user—still need to go through the master zone.
    However, data operations—such as creation of buckets and
    objects—can be handled by any of the zones.
   </p></section><section class="sect2" id="ceph-rgw-fed-keys" data-id-title="System Keys"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">13.11.3 </span><span class="title-name">System Keys</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-fed-keys">#</a></h3></div></div></div><p>
    While configuring zones, Object Gateway expects creation of an S3-compatible system
    user together with their access and secret keys. This allows another Object Gateway
    instance to pull the configuration remotely with the access and secret
    keys. For more information on creating S3 users, see
    <a class="xref" href="cha-ceph-gw.html#adding-s3-swift-users" title="13.5.2.1. Adding S3 and Swift Users">Section 13.5.2.1, “Adding S3 and Swift Users”</a>.
   </p><div id="id-1.3.5.2.14.6.3" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg"/><h6>Tip</h6><p>
     It is useful to generate the access and secret keys before the zone
     creation itself because it makes scripting and use of configuration
     management tools easier later on.
    </p></div><p>
    For the purpose of this example, let us assume that the access and secret
    keys are set in the environment variables:
   </p><div class="verbatim-wrap"><pre class="screen"># SYSTEM_ACCESS_KEY=1555b35654ad1656d805
# SYSTEM_SECRET_KEY=h7GhxuBLTrlhVUyxSPUKUV8r/2EI4ngqJxD7iBdBYLhwluN30JaT3Q==</pre></div><p>
    Generally, access keys consist of 20 alphanumeric characters, while secret
    keys consist of 40 alphanumeric characters (they can contain +/= characters
    as well). You can generate these keys in the command line:
   </p><div class="verbatim-wrap"><pre class="screen"># SYSTEM_ACCESS_KEY=$(cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 20 | head -n 1)
# SYSTEM_SECRET_KEY=$(cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 40 | head -n 1)</pre></div></section><section class="sect2" id="ceph-rgw-fed-naming" data-id-title="Naming Conventions"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">13.11.4 </span><span class="title-name">Naming Conventions</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-fed-naming">#</a></h3></div></div></div><p>
    This example describes the process of setting up a master zone. We will
    assume a zonegroup called <code class="literal">us</code> spanning the United States,
    which will be our master zonegroup. This will contain two zones written in
    a <em class="replaceable">zonegroup</em>-<em class="replaceable">zone</em>
    format. This is our convention only and you can choose a format that you
    prefer. In summary:
   </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
      Master zonegroup: United States <code class="literal">us</code>
     </p></li><li class="listitem"><p>
      Master zone: United States, East Region 1: <code class="literal">us-east-1</code>
     </p></li><li class="listitem"><p>
      Secondary zone: United States, East Region 2:
      <code class="literal">us-east-2</code>
     </p></li><li class="listitem"><p>
      Secondary zone: United States, West Region: <code class="literal">us-west</code>
     </p></li></ul></div><p>
    This will be a part of a larger realm named <code class="literal">gold</code>. The
    <code class="literal">us-east-1</code> and <code class="literal">us-east-2</code> zones are
    part of the same Ceph cluster, <code class="literal">us-east-1</code> being the
    primary one. <code class="literal">us-west</code> is in a different Ceph cluster.
   </p></section><section class="sect2" id="ceph-rgw-fed-pools" data-id-title="Default Pools"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">13.11.5 </span><span class="title-name">Default Pools</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-fed-pools">#</a></h3></div></div></div><p>
    When configured with the appropriate permissions, Object Gateway creates default
    pools on its own. The <code class="literal">pg_num</code> and
    <code class="literal">pgp_num</code> values are taken from the
    <code class="filename">ceph.conf</code> configuration file. Pools related to a zone
    by default follow the convention of
    <em class="replaceable">zone-name</em>.<em class="replaceable">pool-name</em>.
    For example for the <code class="literal">us-east-1</code> zone, it will be the
    following pools:
   </p><div class="verbatim-wrap"><pre class="screen">.rgw.root
us-east-1.rgw.control
us-east-1.rgw.data.root
us-east-1.rgw.gc
us-east-1.rgw.log
us-east-1.rgw.intent-log
us-east-1.rgw.usage
us-east-1.rgw.users.keys
us-east-1.rgw.users.email
us-east-1.rgw.users.swift
us-east-1.rgw.users.uid
us-east-1.rgw.buckets.index
us-east-1.rgw.buckets.data
us-east-1.rgw.meta</pre></div><p>
    These pools can be created in other zones as well, by replacing
    <code class="literal">us-east-1</code> with the appropriate zone name.
   </p></section><section class="sect2" id="ceph-rgw-fed-realm" data-id-title="Creating a Realm"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">13.11.6 </span><span class="title-name">Creating a Realm</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-fed-realm">#</a></h3></div></div></div><p>
    Configure a realm called <code class="literal">gold</code> and make it the default
    realm:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin realm create --rgw-realm=gold --default
{
  "id": "4a367026-bd8f-40ee-b486-8212482ddcd7",
  "name": "gold",
  "current_period": "09559832-67a4-4101-8b3f-10dfcd6b2707",
  "epoch": 1
}</pre></div><p>
    Note that every realm has an ID, which allows for flexibility such as
    renaming the realm later if needed. The <code class="literal">current_period</code>
    changes whenever we change anything in the master zone. The
    <code class="literal">epoch</code> is incremented when there is a change in the
    master zone's configuration which results in a change of the current
    period.
   </p></section><section class="sect2" id="ceph-rgw-fed-deldefzonegrp" data-id-title="Deleting the Default Zonegroup"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">13.11.7 </span><span class="title-name">Deleting the Default Zonegroup</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-fed-deldefzonegrp">#</a></h3></div></div></div><p>
    The default installation of Object Gateway creates the default zonegroup called
    <code class="literal">default</code>. Because we no longer need the default
    zonegroup, remove it.
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin zonegroup delete --rgw-zonegroup=default</pre></div></section><section class="sect2" id="ceph-rgw-fed-createmasterzonegrp" data-id-title="Creating a Master Zonegroup"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">13.11.8 </span><span class="title-name">Creating a Master Zonegroup</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-fed-createmasterzonegrp">#</a></h3></div></div></div><p>
    Create a master zonegroup called <code class="literal">us</code>. The zonegroup will
    manage the zonegroup map and propagate changes to the rest of the system.
    By marking the zonegroup as default, you allow explicitly mentioning the
    rgw-zonegroup switch for later commands.
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin zonegroup create --rgw-zonegroup=us \
--endpoints=http://rgw1:80 --master --default
{
  "id": "d4018b8d-8c0d-4072-8919-608726fa369e",
  "name": "us",
  "api_name": "us",
  "is_master": "true",
  "endpoints": [
      "http:\/\/rgw1:80"
  ],
  "hostnames": [],
  "hostnames_s3website": [],
  "master_zone": "",
  "zones": [],
  "placement_targets": [],
  "default_placement": "",
  "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7"
}</pre></div><p>
    Alternatively, you can mark a zonegroup as default with the following
    command:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin zonegroup default --rgw-zonegroup=us</pre></div></section><section class="sect2" id="ceph-rgw-fed-masterzone" data-id-title="Creating a Master Zone"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">13.11.9 </span><span class="title-name">Creating a Master Zone</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-fed-masterzone">#</a></h3></div></div></div><p>
    Now create a default zone and add it to the default zonegroup. Note that
    you will use this zone for metadata operations such as user creation:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin zone create --rgw-zonegroup=us --rgw-zone=us-east-1 \
--endpoints=http://rgw1:80 --access-key=<em class="replaceable">$SYSTEM_ACCESS_KEY</em> --secret=<em class="replaceable">$SYSTEM_SECRET_KEY</em>
{
  "id": "83859a9a-9901-4f00-aa6d-285c777e10f0",
  "name": "us-east-1",
  "domain_root": "us-east-1/gc.rgw.data.root",
  "control_pool": "us-east-1/gc.rgw.control",
  "gc_pool": "us-east-1/gc.rgw.gc",
  "log_pool": "us-east-1/gc.rgw.log",
  "intent_log_pool": "us-east-1/gc.rgw.intent-log",
  "usage_log_pool": "us-east-1/gc.rgw.usage",
  "user_keys_pool": "us-east-1/gc.rgw.users.keys",
  "user_email_pool": "us-east-1/gc.rgw.users.email",
  "user_swift_pool": "us-east-1/gc.rgw.users.swift",
  "user_uid_pool": "us-east-1/gc.rgw.users.uid",
  "system_key": {
      "access_key": "1555b35654ad1656d804",
      "secret_key": "h7GhxuBLTrlhVUyxSPUKUV8r\/2EI4ngqJxD7iBdBYLhwluN30JaT3Q=="
  },
  "placement_pools": [
      {
          "key": "default-placement",
          "val": {
              "index_pool": "us-east-1/gc.rgw.buckets.index",
              "data_pool": "us-east-1/gc.rgw.buckets.data",
              "data_extra_pool": "us-east-1/gc.rgw.buckets.non-ec",
              "index_type": 0
          }
      }
  ],
  "metadata_heap": "us-east-1/gc.rgw.meta",
  "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7"
}</pre></div><p>
    Note that the <code class="option">--rgw-zonegroup</code> and
    <code class="option">--default</code> switches add the zone to a zonegroup and make it
    the default zone. Alternatively, the same can also be done with the
    following commands:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin zone default --rgw-zone=us-east-1
<code class="prompt user">cephadm &gt; </code>radosgw-admin zonegroup add --rgw-zonegroup=us --rgw-zone=us-east-1</pre></div><section class="sect3" id="ceph-rgw-fed-masterzone-createuser" data-id-title="Creating System Users"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">13.11.9.1 </span><span class="title-name">Creating System Users</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-fed-masterzone-createuser">#</a></h4></div></div></div><p>
     To access zone pools, you need to create a system user. Note that you will
     need these keys when configuring the secondary zone as well.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin user create --uid=zone.user \
--display-name="Zone User" --access-key=<em class="replaceable">$SYSTEM_ACCESS_KEY</em> \
--secret=<em class="replaceable">$SYSTEM_SECRET_KEY</em> --system</pre></div></section><section class="sect3" id="ceph-rgw-fed-masterzone-updateperiod" data-id-title="Update the Period"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">13.11.9.2 </span><span class="title-name">Update the Period</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-fed-masterzone-updateperiod">#</a></h4></div></div></div><p>
     Because you changed the master zone configuration, you need to commit the
     changes for them to take effect in the realm configuration structure.
     Initially, the period looks like this:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin period get
{
  "id": "09559832-67a4-4101-8b3f-10dfcd6b2707", "epoch": 1, "predecessor_uuid": "", "sync_status": [], "period_map":
  {
    "id": "09559832-67a4-4101-8b3f-10dfcd6b2707", "zonegroups": [], "short_zone_ids": []
  }, "master_zonegroup": "", "master_zone": "", "period_config":
  {
     "bucket_quota": {
     "enabled": false, "max_size_kb": -1, "max_objects": -1
     }, "user_quota": {
       "enabled": false, "max_size_kb": -1, "max_objects": -1
     }
  }, "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7", "realm_name": "gold", "realm_epoch": 1
}</pre></div><p>
     Update the period and commit the changes:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin period update --commit
{
  "id": "b5e4d3ec-2a62-4746-b479-4b2bc14b27d1",
  "epoch": 1,
  "predecessor_uuid": "09559832-67a4-4101-8b3f-10dfcd6b2707",
  "sync_status": [ "[...]"
  ],
  "period_map": {
      "id": "b5e4d3ec-2a62-4746-b479-4b2bc14b27d1",
      "zonegroups": [
          {
              "id": "d4018b8d-8c0d-4072-8919-608726fa369e",
              "name": "us",
              "api_name": "us",
              "is_master": "true",
              "endpoints": [
                  "http:\/\/rgw1:80"
              ],
              "hostnames": [],
              "hostnames_s3website": [],
              "master_zone": "83859a9a-9901-4f00-aa6d-285c777e10f0",
              "zones": [
                  {
                      "id": "83859a9a-9901-4f00-aa6d-285c777e10f0",
                      "name": "us-east-1",
                      "endpoints": [
                          "http:\/\/rgw1:80"
                      ],
                      "log_meta": "true",
                      "log_data": "false",
                      "bucket_index_max_shards": 0,
                      "read_only": "false"
                  }
              ],
              "placement_targets": [
                  {
                      "name": "default-placement",
                      "tags": []
                  }
              ],
              "default_placement": "default-placement",
              "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7"
          }
      ],
      "short_zone_ids": [
          {
              "key": "83859a9a-9901-4f00-aa6d-285c777e10f0",
              "val": 630926044
          }
      ]
  },
  "master_zonegroup": "d4018b8d-8c0d-4072-8919-608726fa369e",
  "master_zone": "83859a9a-9901-4f00-aa6d-285c777e10f0",
  "period_config": {
      "bucket_quota": {
          "enabled": false,
          "max_size_kb": -1,
          "max_objects": -1
      },
      "user_quota": {
          "enabled": false,
          "max_size_kb": -1,
          "max_objects": -1
      }
  },
  "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7",
  "realm_name": "gold",
  "realm_epoch": 2
}</pre></div></section><section class="sect3" id="ceph-rgw-fed-masterzone-startrgw" data-id-title="Start the Object Gateway"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">13.11.9.3 </span><span class="title-name">Start the Object Gateway</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-fed-masterzone-startrgw">#</a></h4></div></div></div><p>
     You need to mention the Object Gateway zone and port options in the configuration
     file before starting the Object Gateway. For more information on Object Gateway and its
     configuration, see <a class="xref" href="cha-ceph-gw.html" title="Chapter 13. Ceph Object Gateway">Chapter 13, <em>Ceph Object Gateway</em></a>. The configuration
     section of Object Gateway should look similar to this:
    </p><div class="verbatim-wrap"><pre class="screen">[client.rgw.us-east-1]
rgw_frontends="civetweb port=80"
rgw_zone=us-east-1</pre></div><p>
     Start the Object Gateway:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">root # </code>systemctl start ceph-radosgw@rgw.us-east-1</pre></div></section></section><section class="sect2" id="ceph-rgw-fed-secondaryzone" data-id-title="Creating a Secondary Zone"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">13.11.10 </span><span class="title-name">Creating a Secondary Zone</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-fed-secondaryzone">#</a></h3></div></div></div><p>
    In the same cluster, create and configure the secondary zone named
    <code class="literal">us-east-2</code>. You can execute all the following commands in
    the node hosting the master zone itself.
   </p><p>
    To create the secondary zone, use the same command as when you created the
    primary zone, except dropping the master flag:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin zone create --rgw-zonegroup=us --endpoints=http://rgw2:80 \
--rgw-zone=us-east-2 --access-key=<em class="replaceable">$SYSTEM_ACCESS_KEY</em> --secret=<em class="replaceable">$SYSTEM_SECRET_KEY</em>
{
  "id": "950c1a43-6836-41a2-a161-64777e07e8b8",
  "name": "us-east-2",
  "domain_root": "us-east-2.rgw.data.root",
  "control_pool": "us-east-2.rgw.control",
  "gc_pool": "us-east-2.rgw.gc",
  "log_pool": "us-east-2.rgw.log",
  "intent_log_pool": "us-east-2.rgw.intent-log",
  "usage_log_pool": "us-east-2.rgw.usage",
  "user_keys_pool": "us-east-2.rgw.users.keys",
  "user_email_pool": "us-east-2.rgw.users.email",
  "user_swift_pool": "us-east-2.rgw.users.swift",
  "user_uid_pool": "us-east-2.rgw.users.uid",
  "system_key": {
      "access_key": "1555b35654ad1656d804",
      "secret_key": "h7GhxuBLTrlhVUyxSPUKUV8r\/2EI4ngqJxD7iBdBYLhwluN30JaT3Q=="
  },
  "placement_pools": [
      {
          "key": "default-placement",
          "val": {
              "index_pool": "us-east-2.rgw.buckets.index",
              "data_pool": "us-east-2.rgw.buckets.data",
              "data_extra_pool": "us-east-2.rgw.buckets.non-ec",
              "index_type": 0
          }
      }
  ],
  "metadata_heap": "us-east-2.rgw.meta",
  "realm_id": "815d74c2-80d6-4e63-8cfc-232037f7ff5c"
}</pre></div><section class="sect3" id="ceph-rgw-fed-secondzone-updateperiod" data-id-title="Update the Period"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">13.11.10.1 </span><span class="title-name">Update the Period</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-fed-secondzone-updateperiod">#</a></h4></div></div></div><p>
     Inform all the gateways of the new change in the system map by doing a
     period update and committing the changes:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin period update --commit
{
  "id": "b5e4d3ec-2a62-4746-b479-4b2bc14b27d1",
  "epoch": 2,
  "predecessor_uuid": "09559832-67a4-4101-8b3f-10dfcd6b2707",
  "sync_status": [ "[...]"
  ],
  "period_map": {
      "id": "b5e4d3ec-2a62-4746-b479-4b2bc14b27d1",
      "zonegroups": [
          {
              "id": "d4018b8d-8c0d-4072-8919-608726fa369e",
              "name": "us",
              "api_name": "us",
              "is_master": "true",
              "endpoints": [
                  "http:\/\/rgw1:80"
              ],
              "hostnames": [],
              "hostnames_s3website": [],
              "master_zone": "83859a9a-9901-4f00-aa6d-285c777e10f0",
              "zones": [
                  {
                      "id": "83859a9a-9901-4f00-aa6d-285c777e10f0",
                      "name": "us-east-1",
                      "endpoints": [
                          "http:\/\/rgw1:80"
                      ],
                      "log_meta": "true",
                      "log_data": "false",
                      "bucket_index_max_shards": 0,
                      "read_only": "false"
                  },
                  {
                      "id": "950c1a43-6836-41a2-a161-64777e07e8b8",
                      "name": "us-east-2",
                      "endpoints": [
                          "http:\/\/rgw2:80"
                      ],
                      "log_meta": "false",
                      "log_data": "true",
                      "bucket_index_max_shards": 0,
                      "read_only": "false"
                  }

              ],
              "placement_targets": [
                  {
                      "name": "default-placement",
                      "tags": []
                  }
              ],
              "default_placement": "default-placement",
              "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7"
          }
      ],
      "short_zone_ids": [
          {
              "key": "83859a9a-9901-4f00-aa6d-285c777e10f0",
              "val": 630926044
          },
          {
              "key": "950c1a43-6836-41a2-a161-64777e07e8b8",
              "val": 4276257543
          }

      ]
  },
  "master_zonegroup": "d4018b8d-8c0d-4072-8919-608726fa369e",
  "master_zone": "83859a9a-9901-4f00-aa6d-285c777e10f0",
  "period_config": {
      "bucket_quota": {
          "enabled": false,
          "max_size_kb": -1,
          "max_objects": -1
      },
      "user_quota": {
          "enabled": false,
          "max_size_kb": -1,
          "max_objects": -1
      }
  },
  "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7",
  "realm_name": "gold",
  "realm_epoch": 2
}</pre></div></section><section class="sect3" id="ceph-rgw-fed-secondzone-startrgw" data-id-title="Start the Object Gateway"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">13.11.10.2 </span><span class="title-name">Start the Object Gateway</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-fed-secondzone-startrgw">#</a></h4></div></div></div><p>
     Adjust the configuration of the Object Gateway for the secondary zone, and start
     it:
    </p><div class="verbatim-wrap"><pre class="screen">[client.rgw.us-east-2]
rgw_frontends="civetweb port=80"
rgw_zone=us-east-2</pre></div><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>sudo systemctl start ceph-radosgw@rgw.us-east-2</pre></div></section></section><section class="sect2" id="ceph-rgw-fed-seccluster" data-id-title="Adding Object Gateway to the Second Cluster"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">13.11.11 </span><span class="title-name">Adding Object Gateway to the Second Cluster</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-fed-seccluster">#</a></h3></div></div></div><p>
    The second Ceph cluster belongs to the same zonegroup as the initial one,
    but may be geographically located elsewhere.
   </p><section class="sect3" id="ceph-rgw-fed-seccluster-realm" data-id-title="Default Realm and Zonegroup"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">13.11.11.1 </span><span class="title-name">Default Realm and Zonegroup</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-fed-seccluster-realm">#</a></h4></div></div></div><p>
     Since you already created the realm for the first gateway, pull the realm
     here and make it the default here:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin realm pull --url=http://rgw1:80 \
--access-key=<em class="replaceable">$SYSTEM_ACCESS_KEY</em> --secret=<em class="replaceable">$SYSTEM_SECRET_KEY</em>
{
  "id": "4a367026-bd8f-40ee-b486-8212482ddcd7",
  "name": "gold",
  "current_period": "b5e4d3ec-2a62-4746-b479-4b2bc14b27d1",
  "epoch": 2
}
<code class="prompt user">cephadm &gt; </code>radosgw-admin realm default --rgw-realm=gold</pre></div><p>
     Get the configuration from the master zone by pulling the period:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin period pull --url=http://rgw1:80 \
--access-key=<em class="replaceable">$SYSTEM_ACCESS_KEY</em> --secret=<em class="replaceable">$SYSTEM_SECRET_KEY</em></pre></div><p>
     Set the default zonegroup to the already created <code class="literal">us</code>
     zonegroup:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin zonegroup default --rgw-zonegroup=us</pre></div></section><section class="sect3" id="ceph-rgw-fed-seccluster-seczone" data-id-title="Secondary Zone Configuration"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">13.11.11.2 </span><span class="title-name">Secondary Zone Configuration</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-fed-seccluster-seczone">#</a></h4></div></div></div><p>
     Create a new zone named <code class="literal">us-west</code> with the same system
     keys:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin zone create --rgw-zonegroup=us --rgw-zone=us-west \
--access-key=<em class="replaceable">$SYSTEM_ACCESS_KEY</em> --secret=<em class="replaceable">$SYSTEM_SECRET_KEY</em> \
--endpoints=http://rgw3:80 --default
{
  "id": "950c1a43-6836-41a2-a161-64777e07e8b8",
  "name": "us-west",
  "domain_root": "us-west.rgw.data.root",
  "control_pool": "us-west.rgw.control",
  "gc_pool": "us-west.rgw.gc",
  "log_pool": "us-west.rgw.log",
  "intent_log_pool": "us-west.rgw.intent-log",
  "usage_log_pool": "us-west.rgw.usage",
  "user_keys_pool": "us-west.rgw.users.keys",
  "user_email_pool": "us-west.rgw.users.email",
  "user_swift_pool": "us-west.rgw.users.swift",
  "user_uid_pool": "us-west.rgw.users.uid",
  "system_key": {
      "access_key": "1555b35654ad1656d804",
      "secret_key": "h7GhxuBLTrlhVUyxSPUKUV8r\/2EI4ngqJxD7iBdBYLhwluN30JaT3Q=="
  },
  "placement_pools": [
      {
          "key": "default-placement",
          "val": {
              "index_pool": "us-west.rgw.buckets.index",
              "data_pool": "us-west.rgw.buckets.data",
              "data_extra_pool": "us-west.rgw.buckets.non-ec",
              "index_type": 0
          }
      }
  ],
  "metadata_heap": "us-west.rgw.meta",
  "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7"
}</pre></div></section><section class="sect3" id="ceph-rgw-fed-seccluster-period" data-id-title="Update the Period"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">13.11.11.3 </span><span class="title-name">Update the Period</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-fed-seccluster-period">#</a></h4></div></div></div><p>
     To propagate the zonegroup map changes, we update and commit the period:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>radosgw-admin period update --commit --rgw-zone=us-west
{
  "id": "b5e4d3ec-2a62-4746-b479-4b2bc14b27d1",
  "epoch": 3,
  "predecessor_uuid": "09559832-67a4-4101-8b3f-10dfcd6b2707",
  "sync_status": [
      "", # truncated
  ],
  "period_map": {
      "id": "b5e4d3ec-2a62-4746-b479-4b2bc14b27d1",
      "zonegroups": [
          {
              "id": "d4018b8d-8c0d-4072-8919-608726fa369e",
              "name": "us",
              "api_name": "us",
              "is_master": "true",
              "endpoints": [
                  "http:\/\/rgw1:80"
              ],
              "hostnames": [],
              "hostnames_s3website": [],
              "master_zone": "83859a9a-9901-4f00-aa6d-285c777e10f0",
              "zones": [
                  {
                      "id": "83859a9a-9901-4f00-aa6d-285c777e10f0",
                      "name": "us-east-1",
                      "endpoints": [
                          "http:\/\/rgw1:80"
                      ],
                      "log_meta": "true",
                      "log_data": "true",
                      "bucket_index_max_shards": 0,
                      "read_only": "false"
                  },
                                  {
                      "id": "950c1a43-6836-41a2-a161-64777e07e8b8",
                      "name": "us-east-2",
                      "endpoints": [
                          "http:\/\/rgw2:80"
                      ],
                      "log_meta": "false",
                      "log_data": "true",
                      "bucket_index_max_shards": 0,
                      "read_only": "false"
                  },
                  {
                      "id": "d9522067-cb7b-4129-8751-591e45815b16",
                      "name": "us-west",
                      "endpoints": [
                          "http:\/\/rgw3:80"
                      ],
                      "log_meta": "false",
                      "log_data": "true",
                      "bucket_index_max_shards": 0,
                      "read_only": "false"
                  }
              ],
              "placement_targets": [
                  {
                      "name": "default-placement",
                      "tags": []
                  }
              ],
              "default_placement": "default-placement",
              "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7"
          }
      ],
      "short_zone_ids": [
          {
              "key": "83859a9a-9901-4f00-aa6d-285c777e10f0",
              "val": 630926044
          },
          {
              "key": "950c1a43-6836-41a2-a161-64777e07e8b8",
              "val": 4276257543
          },
          {
              "key": "d9522067-cb7b-4129-8751-591e45815b16",
              "val": 329470157
          }
      ]
  },
  "master_zonegroup": "d4018b8d-8c0d-4072-8919-608726fa369e",
  "master_zone": "83859a9a-9901-4f00-aa6d-285c777e10f0",
  "period_config": {
      "bucket_quota": {
          "enabled": false,
          "max_size_kb": -1,
          "max_objects": -1
      },
      "user_quota": {
          "enabled": false,
          "max_size_kb": -1,
          "max_objects": -1
      }
  },
  "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7",
  "realm_name": "gold",
  "realm_epoch": 2
}</pre></div><p>
     Note that the period epoch number has incremented, indicating a change in
     the configuration.
    </p></section><section class="sect3" id="ceph-rgw-fed-seccluster-rgwstart" data-id-title="Start the Object Gateway"><div class="titlepage"><div><div><h4 class="title"><span class="title-number">13.11.11.4 </span><span class="title-name">Start the Object Gateway</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-fed-seccluster-rgwstart">#</a></h4></div></div></div><p>
     This is similar to starting the Object Gateway in the first zone. The only
     difference is that the Object Gateway zone configuration should reflect the
     <code class="literal">us-west</code> zone name:
    </p><div class="verbatim-wrap"><pre class="screen">[client.rgw.us-west]
rgw_frontends="civetweb port=80"
rgw_zone=us-west</pre></div><p>
     Start the second Object Gateway:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">root # </code>systemctl start ceph-radosgw@rgw.us-west</pre></div></section></section><section class="sect2" id="ceph-rgw-fed-failover" data-id-title="Failover and Disaster Recovery"><div class="titlepage"><div><div><h3 class="title"><span class="title-number">13.11.12 </span><span class="title-name">Failover and Disaster Recovery</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ceph-rgw-fed-failover">#</a></h3></div></div></div><p>
    If the master zone should fail, failover to the secondary zone for disaster
    recovery.
   </p><div class="procedure"><div class="procedure-contents"><ol class="procedure" type="1"><li class="step"><p>
      Make the secondary zone the master and default zone. For example:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code><code class="command">radosgw-admin</code> zone modify --rgw-zone={zone-name} --master --default</pre></div><p>
      By default, Ceph Object Gateway will run in an active-active
      configuration. If the cluster was configured to run in an active-passive
      configuration, the secondary zone is a read-only zone. Remove the
      --read-only status to allow the zone to receive write operations. For
      example:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code><code class="command">radosgw-admin</code> zone modify --rgw-zone={zone-name} --master --default \
--read-only=False</pre></div></li><li class="step"><p>
      Update the period to make the changes take effect.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code><code class="command">radosgw-admin</code> period update --commit</pre></div></li><li class="step"><p>
      Finally, restart the Ceph Object Gateway.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">root # </code><code class="command">systemctl</code> restart ceph-radosgw@rgw.`hostname -s`</pre></div></li></ol></div></div><p>
    If the former master zone recovers, revert the operation.
   </p><div class="procedure"><div class="procedure-contents"><ol class="procedure" type="1"><li class="step"><p>
      From the recovered zone, pull the period from the current master zone.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code><code class="command">radosgw-admin</code> period pull --url={url-to-master-zone-gateway} \
--access-key={access-key} --secret={secret}</pre></div></li><li class="step"><p>
      Make the recovered zone the master and default zone.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code><code class="command">radosgw-admin</code> zone modify --rgw-zone={zone-name} --master --default</pre></div></li><li class="step"><p>
      Update the period to make the changes take effect.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code><code class="command">radosgw-admin</code> period update --commit</pre></div></li><li class="step"><p>
      Then, restart the Ceph Object Gateway in the recovered zone.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">root # </code><code class="command">systemctl</code> restart ceph-radosgw@rgw.`hostname -s`</pre></div></li><li class="step"><p>
      If the secondary zone needs to be a read-only configuration, update the
      secondary zone.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code><code class="command">radosgw-admin</code> zone modify --rgw-zone={zone-name} --read-only</pre></div></li><li class="step"><p>
      Update the period to make the changes take effect.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code><code class="command">radosgw-admin</code> period update --commit</pre></div></li><li class="step"><p>
      Finally, restart the Ceph Object Gateway in the secondary zone.
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">root # </code><code class="command">systemctl</code> restart ceph-radosgw@rgw.`hostname -s`</pre></div></li></ol></div></div></section></section><section class="sect1" id="ogw-haproxy" data-id-title="Load Balancing the Object Gateway Servers with HAProxy"><div class="titlepage"><div><div><h2 class="title"><span class="title-number">13.12 </span><span class="title-name">Load Balancing the Object Gateway Servers with HAProxy</span> <a title="Permalink" class="permalink" href="cha-ceph-gw.html#ogw-haproxy">#</a></h2></div></div></div><p>
   You can use the HAProxy load balancer to distribute all requests across
   multiple Object Gateway back-end servers. Refer to
   <a class="link" href="https://documentation.suse.com/sle-ha/12-SP5/single-html/SLE-HA-guide/#sec-ha-lb-haproxy" target="_blank">https://documentation.suse.com/sle-ha/12-SP5/single-html/SLE-HA-guide/#sec-ha-lb-haproxy</a>
   for more details on configuring HAProxy.
  </p><p>
   Following is a simple configuration of HAProxy for balancing Object Gateway nodes
   using round robin as the balancing algorithm:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephadm &gt; </code>cat /etc/haproxy/haproxy.cfg
[...]
frontend <em class="replaceable">https_frontend</em>
bind *:443 crt <em class="replaceable">path-to-cert.pem</em> [ciphers: ... ]
default_backend rgw

backend rgw
mode http
balance roundrobin
server rgw_server1 <em class="replaceable">rgw-endpoint1</em> weight 1 maxconn 100 check
server rgw_server2 <em class="replaceable">rgw-endpoint2</em> weight 1 maxconn 100 check
[...]</pre></div></section></section><nav class="bottom-pagination"><div><a class="pagination-link prev" href="part-dataccess.html"><span class="pagination-relation">Previous</span><span class="pagination-label"><span class="title-number">Part III </span>Accessing Cluster Data</span></a> </div><div><a class="pagination-link next" href="cha-ceph-iscsi.html"><span class="pagination-relation">Next</span><span class="pagination-label"><span class="title-number">Chapter 14 </span>Ceph iSCSI Gateway</span></a> </div></nav></article><aside id="_side-toc-page" class="side-toc"><div class="side-title">On this page</div><div class="toc"><ul><li><span class="sect1"><a href="cha-ceph-gw.html#sec-ceph-rgw-limits"><span class="title-number">13.1 </span><span class="title-name">Object Gateway Restrictions and Naming Limitations</span></a></span></li><li><span class="sect1"><a href="cha-ceph-gw.html#ogw-deploy"><span class="title-number">13.2 </span><span class="title-name">Deploying the Object Gateway</span></a></span></li><li><span class="sect1"><a href="cha-ceph-gw.html#ceph-rgw-operating"><span class="title-number">13.3 </span><span class="title-name">Operating the Object Gateway Service</span></a></span></li><li><span class="sect1"><a href="cha-ceph-gw.html#sec-ceph-rgw-configuration"><span class="title-number">13.4 </span><span class="title-name">Configuration Parameters</span></a></span></li><li><span class="sect1"><a href="cha-ceph-gw.html#ceph-rgw-access"><span class="title-number">13.5 </span><span class="title-name">Managing Object Gateway Access</span></a></span></li><li><span class="sect1"><a href="cha-ceph-gw.html#ceph-rgw-https"><span class="title-number">13.6 </span><span class="title-name">Enabling HTTPS/SSL for Object Gateways</span></a></span></li><li><span class="sect1"><a href="cha-ceph-gw.html#ceph-rgw-sync"><span class="title-number">13.7 </span><span class="title-name">Sync Modules</span></a></span></li><li><span class="sect1"><a href="cha-ceph-gw.html#ceph-rgw-ldap"><span class="title-number">13.8 </span><span class="title-name">LDAP Authentication</span></a></span></li><li><span class="sect1"><a href="cha-ceph-gw.html#ogw-bucket-sharding"><span class="title-number">13.9 </span><span class="title-name">Bucket Index Sharding</span></a></span></li><li><span class="sect1"><a href="cha-ceph-gw.html#ogw-keystone"><span class="title-number">13.10 </span><span class="title-name">Integrating OpenStack Keystone</span></a></span></li><li><span class="sect1"><a href="cha-ceph-gw.html#ceph-rgw-fed"><span class="title-number">13.11 </span><span class="title-name">Multisite Object Gateways</span></a></span></li><li><span class="sect1"><a href="cha-ceph-gw.html#ogw-haproxy"><span class="title-number">13.12 </span><span class="title-name">Load Balancing the Object Gateway Servers with HAProxy</span></a></span></li></ul></div><div class="side-title">Give feedback</div><ul class="feedback" id="_give-feedback"><li><a id="_feedback-reportbug" href="#" rel="nofollow" target="_blank">Report an issue</a></li><li><a id="_feedback-editurl" href="https://github.com/SUSE/doc-ses/edit/maintenance/ses5/xml/admin_ceph_gateway.xml" rel="nofollow" target="_blank">Edit source document</a></li></ul><div class="side-title">Share this page</div><ul class="share"><li><a id="_share-fb" href="#" title="Facebook"> </a></li><li><a id="_share-in" href="#" title="LinkedIn"> </a></li><li><a id="_share-tw" href="#" title="Twitter"> </a></li><li><a id="_share-mail" href="#" title="E-Mail"> </a></li><li><a id="_print-button" href="#" title="Print this page"> </a></li></ul> </aside></main><footer id="_footer"><div class="growth-inhibitor"><div class="copy"><span class="copy__rights">© SUSE
                 2022</span></div></div></footer></body></html>