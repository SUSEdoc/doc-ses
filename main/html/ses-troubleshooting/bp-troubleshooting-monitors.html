<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes"/><title>SES 7.1 | Troubleshooting Guide | Troubleshooting Ceph Monitors and Ceph Managers</title><link rel="stylesheet" type="text/css" href="static/css/style.css"/>
<meta name="title" content="Troubleshooting Ceph Monitors and Ceph Managers | SES …"/>
<meta name="description" content="Are the monitors running?"/>
<meta name="product-name" content="SUSE Enterprise Storage"/>
<meta name="product-number" content="7.1"/>
<meta name="book-title" content="Troubleshooting Guide"/>
<meta name="chapter-title" content="Chapter 6. Troubleshooting Ceph Monitors and Ceph Managers"/>
<meta name="tracker-url" content="https://github.com/SUSE/doc-ses/issues/new"/>
<meta name="tracker-type" content="gh"/>
<meta name="tracker-gh-assignee" content="tbazant"/>
<meta name="tracker-gh-template" content="&#10;     ### Type of report&#10;   - [ ] bug&#10;   - [ ] feature request&#10;&#10;### Source Document&#10;@@source@@&#10;&#10;### Summary&#10;&lt;!-- A clear and concise description of what the bug/feature request is. --&gt;&#10;&#10;### Steps To Reproduce&#10;&lt;!-- Steps to reproduce the behavior if you ran through steps in the document. --&gt;&#10;&#10;### Expected Results&#10;&lt;!-- A clear and concise description of what you expected to happen. --&gt;&#10;&#10;### Actual Results&#10;&lt;!-- Explain what actually happened if steps were executed, and if applicable, add screenshots to help explain your problem. --&gt;&#10;&#10;### Notes&#10;&lt;!-- Add any other context about the problem here. --&gt;&#10;&#10;    "/>
<meta name="tracker-gh-labels" content="bug,question,feature request"/>
<meta property="og:title" content="Troubleshooting Ceph Monitors and Ceph Managers | SES …"/>
<meta property="og:description" content="Are the monitors running?"/>
<meta property="og:type" content="article"/>
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Troubleshooting Ceph Monitors and Ceph Managers | SES …"/>
<meta name="twitter:description" content="Are the monitors running?"/>
<link rel="prev" href="bp-troubleshooting-pgs.html" title="Chapter 5. Troubleshooting placement groups (PGs)"/><link rel="next" href="bp-troubleshooting-networking.html" title="Chapter 7. Troubleshooting networking"/>
<script type="text/javascript">

if ( window.location.protocol.toLowerCase() != 'file:' ) {
  document.write('<link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css"></link>');
};

</script><noscript><link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css"/></noscript><script src="static/js/jquery-1.12.4.min.js" type="text/javascript"> </script><script src="static/js/script.js" type="text/javascript"> </script><script src="static/js/highlight.min.js" type="text/javascript"> </script><script>

$(document).ready(function() {
  $('.verbatim-wrap.highlight').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});
hljs.configure({
  useBR: false
});

</script><meta name="edit-url" content="https://github.com/SUSE/doc-ses/edit/main/xml/bp_troubleshooting_monitors.xml"/></head><body class="draft wide offline js-off" onload="$('#betawarn-button-wrap').toggle();if (document.cookie.length > 0) {if (document.cookie.indexOf('betawarn=closed') != -1){$('#betawarn').toggle()}};"><div id="betawarn" style="position:fixed;bottom:0;z-index:9025;background-color:#FDE8E8;padding:1em;margin-left:10%;margin-right:10%;display:block;border-top:.75em solid #E11;width:80%"><p style="color:#333;margin:1em 0;padding:0;">This is a draft document that was built and uploaded automatically. It may document beta software and be incomplete or even incorrect. <strong>Use this document at your own risk.</strong></p> <div id="betawarn-button-wrap" style="display:none;margin:0;padding:0;"><a href="#" onclick="$('#betawarn').toggle();var d=new Date();d.setTime(d.getTime()+(0.5*24*60*60*1000));document.cookie='betawarn=closed; expires='+d.toUTCString()+'; path=/'; return false;" style="color:#333;text-decoration:underline;float:left;margin-top:.5em;padding:1em;display:block;background-color:#FABEBE;">I understand this is a draft</a></div></div><div class="bypass-block"><a href="#_content">Jump to content</a><a href="#_bottom-pagination">Jump to page navigation: previous page [access key p]/next page [access key n]</a></div><header id="_mainnav"><div class="growth-inhibitor"><img src="static/images/logo.svg" alt="Logo" class="logo"/></div></header><div class="crumbs"><div class="growth-inhibitor"><a class="crumb" href="index.html">Troubleshooting Guide</a><span> / </span><a class="crumb" href="bp-troubleshooting-monitors.html">Troubleshooting Ceph Monitors and Ceph Managers</a></div></div><main id="_content"><nav id="_side-toc-overall" class="side-toc"><div class="side-title">Troubleshooting Guide</div><ol><li><a href="preface-troubleshooting.html" class=" "><span class="title-number"> </span><span class="title-name">About this guide</span></a></li><li><a href="report-software.html" class=" "><span class="title-number">1 </span><span class="title-name">Reporting software problems</span></a></li><li><a href="bp-troubleshooting-logging.html" class=" "><span class="title-number">2 </span><span class="title-name">Troubleshooting logging and debugging</span></a></li><li><a href="bp-troubleshooting-cephadm.html" class=" "><span class="title-number">3 </span><span class="title-name">Troubleshooting cephadm</span></a></li><li><a href="bp-troubleshooting-osds.html" class=" "><span class="title-number">4 </span><span class="title-name">Troubleshooting OSDs</span></a></li><li><a href="bp-troubleshooting-pgs.html" class=" "><span class="title-number">5 </span><span class="title-name">Troubleshooting placement groups (PGs)</span></a></li><li><a href="bp-troubleshooting-monitors.html" class=" you-are-here"><span class="title-number">6 </span><span class="title-name">Troubleshooting Ceph Monitors and Ceph Managers</span></a></li><li><a href="bp-troubleshooting-networking.html" class=" "><span class="title-number">7 </span><span class="title-name">Troubleshooting networking</span></a></li><li><a href="bp-troubleshooting-nfs.html" class=" "><span class="title-number">8 </span><span class="title-name">Troubleshooting NFS Ganesha</span></a></li><li><a href="bp-troubleshooting-status.html" class=" "><span class="title-number">9 </span><span class="title-name">Troubleshooting Ceph health status</span></a></li><li><a href="bp-troubleshooting-dashboard.html" class=" "><span class="title-number">10 </span><span class="title-name">Troubleshooting the Ceph Dashboard</span></a></li><li><a href="bp-troubleshooting-objectgateway.html" class=" "><span class="title-number">11 </span><span class="title-name">Troubleshooting Object Gateway</span></a></li><li><a href="bp-troubleshooting-cephfs.html" class=" "><span class="title-number">12 </span><span class="title-name">Troubleshooting CephFS</span></a></li><li><a href="storage-tips.html" class=" "><span class="title-number">13 </span><span class="title-name">Hints and tips</span></a></li><li><a href="storage-faqs.html" class=" "><span class="title-number">14 </span><span class="title-name">Frequently asked questions</span></a></li><li><a href="bk03apa.html" class=" "><span class="title-number">A </span><span class="title-name">Ceph maintenance updates based on upstream 'Pacific' point releases</span></a></li><li><a href="bk03go01.html" class=" "><span class="title-number"> </span><span class="title-name">Glossary</span></a></li> </ol> </nav><button id="_open-side-toc-overall" title="Contents"> </button><article class="documentation"><button id="_unfold-side-toc-page">On this page</button><section class="chapter" id="bp-troubleshooting-monitors" data-id-title="Troubleshooting Ceph Monitors and Ceph Managers"><div class="titlepage"><div><div class="version-info">Applies to  <span class="productname">SUSE Enterprise Storage</span> <span class="productnumber">7.1</span></div><div><div class="title-container"><h1 class="title"><span class="title-number-name"><span class="title-number">6 </span><span class="title-name">Troubleshooting Ceph Monitors and Ceph Managers</span></span> <a title="Permalink" class="permalink" href="bp-troubleshooting-monitors.html#">#</a></h1><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-ses/edit/main/xml/bp_troubleshooting_monitors.xml" title="Edit source document"> </a></div></div></div></div></div><section class="sect1" id="mons-initial-troubleshooting" data-id-title="Initial troubleshooting"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">6.1 </span><span class="title-name">Initial troubleshooting</span></span> <a title="Permalink" class="permalink" href="bp-troubleshooting-monitors.html#mons-initial-troubleshooting">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-ses/edit/main/xml/bp_troubleshooting_monitors.xml" title="Edit source document"> </a></div></div></div></div></div><div class="qandaset" id="id-1.5.8.3.2"><div class="free-id" id="id-1.5.8.3.2.1"> </div><dl class="qandaentry"><dt class="question" id="id-1.5.8.3.2.1.1"><strong>Q:</strong>
      Are the monitors running?
     </dt><dd class="answer" id="id-1.5.8.3.2.1.2"><p>
      Ensure the monitors are running, this is an important to check if you
      have performed an upgrade and not manually restarted the monitors.
     </p></dd></dl><div class="free-id" id="id-1.5.8.3.2.2"> </div><dl class="qandaentry"><dt class="question" id="id-1.5.8.3.2.2.1"><strong>Q:</strong>
      Are you able to connect to the monitor’s servers?
     </dt><dd class="answer" id="id-1.5.8.3.2.2.2"><p>
      Occasionally, you can be running <code class="literal">iptable</code> rules that
      block access to monitor servers or monitor ports. This can often be the
      case from monitor stress-testing that was forgotten. We recommend trying
      to <code class="literal">ssh</code> into the server and, if that succeeds, try
      connecting to the monitor's port using your tool of choice (such as
      <code class="command">telnet</code> or <code class="command">netcat</code>).
     </p></dd></dl><div class="free-id" id="id-1.5.8.3.2.3"> </div><dl class="qandaentry"><dt class="question" id="id-1.5.8.3.2.3.1"><strong>Q:</strong>
      Does <code class="command">ceph -s</code> run and obtain a reply from the cluster?
     </dt><dd class="answer" id="id-1.5.8.3.2.3.2"><p>
      If the answer is yes, then your cluster is up and running. The monitors
      will only answer to a status request if there is a formed quorum. If
      <code class="command">ceph -s</code> is blocked, without obtaining a reply from the
      cluster or showing a lot of fault messages, then it is possible that your
      monitors are either down completely or just a portion is up – a portion
      that is not enough to form a quorum (keep in mind that a quorum if formed
      by a majority of monitors).
     </p></dd></dl><div class="free-id" id="id-1.5.8.3.2.4"> </div><dl class="qandaentry"><dt class="question" id="id-1.5.8.3.2.4.1"><strong>Q:</strong>
      What if <code class="command">ceph -s</code> does not finish?
     </dt><dd class="answer" id="id-1.5.8.3.2.4.2"><p>
      Contact each monitor individually for the status, regardless of a quorum
      being formed. This can be achieved using <code class="command">ceph tell mon.ID
      mon_status</code> with the ID being the monitor's identifier. Perform
      this for each monitor in the cluster. The section
      <a class="xref" href="bp-troubleshooting-monitors.html#mons-understanding-mons-status" title="6.3. Understanding mons_status">Section 6.3, “Understanding <code class="literal">mons_status</code>”</a> explains how to
      interpret the output of this command.
     </p></dd></dl></div></section><section class="sect1" id="mons-admin-socket" data-id-title="Using the monitors admin socket"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">6.2 </span><span class="title-name">Using the monitor's admin socket</span></span> <a title="Permalink" class="permalink" href="bp-troubleshooting-monitors.html#mons-admin-socket">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-ses/edit/main/xml/bp_troubleshooting_monitors.xml" title="Edit source document"> </a></div></div></div></div></div><p>
   The admin socket allows you to interact with a given daemon directly using a
   Unix socket file. This file can be found in your monitor's run directory. By
   default, the admin socket will be kept in
   <code class="filename">/var/run/ceph/ceph-mon.ID.asok</code> but this can vary if you
   defined it otherwise. If you are unable to find it there, check your
   <code class="filename">ceph.conf</code> for an alternative path or run:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph-conf --name mon.ID --show-config-value admin_socket</pre></div><p>
   Keep in mind that the admin socket is only available while the monitor is
   running. When the monitor is properly shutdown, the admin socket is removed.
   If however the monitor is not running and the admin socket still persists,
   it is likely that the monitor was improperly shutdown. Regardless, if the
   monitor is not running, you will not be able to use the admin socket, with
   ceph likely returning <code class="literal">Error 111: Connection Refused</code>. To
   accessing the admin socket run <code class="command">ceph tell</code> on the daemon
   you are interested in. For example:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph tell mon.<em class="replaceable">ID</em> mon_status</pre></div><p>
   This passes the command help to the running MON daemon
   <em class="replaceable">ID</em> via the admin socket, which is a file ending
   in <code class="filename">.asok</code> somewhere under
   <code class="filename">/var/run/ceph</code>. When you know the full path to the file,
   you can run the following:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph --admin-daemon <em class="replaceable">PATH_TO_FILE</em> <em class="replaceable">COMMAND</em></pre></div><p>
   Using help as the command to the <code class="command">ceph tool</code> shows the
   supported commands available through the admin socket. Take a look at
   <code class="option">config get</code>, <code class="option">config show</code>, <code class="option">mon
   stat</code> and <code class="option">quorum_status</code>, as those can be
   enlightening when troubleshooting a monitor.
  </p></section><section class="sect1" id="mons-understanding-mons-status" data-id-title="Understanding mons_status"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">6.3 </span><span class="title-name">Understanding <code class="literal">mons_status</code></span></span> <a title="Permalink" class="permalink" href="bp-troubleshooting-monitors.html#mons-understanding-mons-status">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-ses/edit/main/xml/bp_troubleshooting_monitors.xml" title="Edit source document"> </a></div></div></div></div></div><p>
   <code class="literal">mon_status</code> can be obtained via the admin socket. This
   command outputs a multitude of information about the monitor including the
   same output you would get with <code class="option">quorum_status</code>. For example,
   the following example output of <code class="command">ceph tell mon.c
   mon_status</code>:
  </p><div class="verbatim-wrap"><pre class="screen">  { "name": "c",
  "rank": 2,
  "state": "peon",
  "election_epoch": 38,
  "quorum": [
        1,
        2],
  "outside_quorum": [],
  "extra_probe_peers": [],
  "sync_provider": [],
  "monmap": { "epoch": 3,
      "fsid": "5c4e9d53-e2e1-478a-8061-f543f8be4cf8",
      "modified": "2013-10-30 04:12:01.945629",
      "created": "2013-10-29 14:14:41.914786",
      "mons": [
            { "rank": 0,
              "name": "a",
              "addr": "127.0.0.1:6789\/0"},
            { "rank": 1,
              "name": "b",
              "addr": "127.0.0.1:6790\/0"},
            { "rank": 2,
              "name": "c",
              "addr": "127.0.0.1:6795\/0"}]}}</pre></div><p>
   This example shows that there are three montiors in the monmap
   (<code class="literal">a</code>, <code class="literal">b</code> and <code class="literal">c</code>), the
   quorum is formed by only two monitors, and <code class="literal">c</code> is in the
   quorum as a <code class="literal">peon</code>. This means that monitor
   <code class="literal">a</code> is out of quorum. This is because there are two
   monitors in this set: 1 and 2. These are not monitor names. These are
   monitor ranks, as established in the current monmap. It shows that the
   missing monitor is the one with a rank of 0, and according to the monmap
   that would be <code class="literal">mon.a</code>.
  </p><p>
   Ranks (re)calculated whenever you add or remove monitors and follow this
   rule: the greater the <code class="literal">IP:PORT</code> combination, the lower the
   rank is. In this case, considering that <code class="literal">127.0.0.1:6789</code> is
   lower than all the remaining <code class="literal">IP:PORT</code> combinations,
   <code class="literal">mon.a</code> has rank 0.
  </p></section><section class="sect1" id="mons-restoring-quorum" data-id-title="Restoring the MONs quorum"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">6.4 </span><span class="title-name">Restoring the MONs quorum</span></span> <a title="Permalink" class="permalink" href="bp-troubleshooting-monitors.html#mons-restoring-quorum">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-ses/edit/main/xml/bp_troubleshooting_monitors.xml" title="Edit source document"> </a></div></div></div></div></div><p>
   If the Ceph Monitors cannot form a quorum, cephadm will not be able to manage the
   cluster until the quorum is restored. In order to restore the Ceph Monitor quorum,
   remove unhealthy Ceph Monitors form the monmap by following these steps:
  </p><div class="procedure"><div class="procedure-contents"><ol class="procedure" type="1"><li class="step"><p>
     Stop all Ceph Monitors. Log in to each Ceph Monitor host via SSH and run the following
     command there:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>cephadm unit --name mon.`hostname` stop</pre></div></li><li class="step"><p>
     Identify a surviving monitor by logging in to that host via SSH and
     running:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>cephadm shell --name mon.`hostname`</pre></div></li><li class="step"><p>
     Extract a copy of the monmap to a file, for example
     <code class="filename">/tmp/monmap</code>. Note that
     <em class="replaceable">MON_ID</em> is usually identical to the string that
     the <code class="command">hostname</code> command returns:
    </p><div class="verbatim-wrap"><pre class="screen">ceph-mon -i <em class="replaceable">MON_ID</em> --extract-monmap <em class="replaceable">/tmp/monmap</em></pre></div></li><li class="step"><p>
     Remove the non-surviving or problematic monitors. For example, if you have
     three monitors, <code class="literal">mon.a</code>, <code class="literal">mon.b</code>, and
     <code class="literal">mon.c</code> where only <code class="literal">mon.a</code> is surviving,
     follow this example:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>monmaptool /tmp/monmap --rm b
<code class="prompt user">cephuser@adm &gt; </code>monmaptool /tmp/monmap --rm c</pre></div></li><li class="step"><p>
     Inject the surviving map with the removed monitors into the surviving
     monitor(s). For example, to inject the map into the monitor
     <code class="literal">mon.a</code>, follow this example:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph-mon -i a --inject-monmap /tmp/monmap</pre></div></li><li class="step"><p>
     Start only the surviving monitors, and verify that the monitors form a
     quorum with the <code class="command">ceph -s</code> command.
    </p></li></ol></div></div><div id="id-1.5.8.6.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><div class="admon-title">Note</div><p>
    You may wish to archive the removed monitors' data directories from
    <code class="filename">/var/lib/ceph/mon</code> in a safe location, or delete it if
    you are confident the remaining monitors are healthy and are sufficiently
    redundant.
   </p></div></section><section class="sect1" id="mons-common-issues" data-id-title="Most common monitor issues"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">6.5 </span><span class="title-name">Most common monitor issues</span></span> <a title="Permalink" class="permalink" href="bp-troubleshooting-monitors.html#mons-common-issues">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-ses/edit/main/xml/bp_troubleshooting_monitors.xml" title="Edit source document"> </a></div></div></div></div></div><section class="sect2" id="monitor-down" data-id-title="Have quorum but at least one monitor is down"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">6.5.1 </span><span class="title-name">Have quorum but at least one monitor is down</span></span> <a title="Permalink" class="permalink" href="bp-troubleshooting-monitors.html#monitor-down">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-ses/edit/main/xml/bp_troubleshooting_monitors.xml" title="Edit source document"> </a></div></div></div></div></div><p>
    When this happens, depending on the version of Ceph you are running, you
    should be seeing something similar to:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph health detail
[snip]
mon.a (rank 0) addr 127.0.0.1:6789/0 is down (out of quorum)</pre></div><p>
    To troubleshoot, make sure that <code class="literal">mon.a</code> is running. After
    that, make sure you are able to connect to <code class="literal">mon.a</code>'s
    server from the other monitors' servers. Check the ports as well. Check
    iptables on all your monitor nodes and make sure you are not dropping or
    rejecting connections. If this initial troubleshooting does not solve your
    problems, check the problematic monitor's <code class="literal">mon_status</code> via
    the admin socket. Considering the monitor is out of the quorum, its state
    should be one of <code class="literal">probing</code>, <code class="literal">electing</code> or
    <code class="literal">synchronizing</code>. If it happens to be either
    <code class="literal">leader</code> or <code class="literal">peon</code>, then the monitor
    believes itself to be in the quorum, while the remaining cluster is sure it
    is not; or maybe it got into the quorum while we were troubleshooting the
    monitor. Check using <code class="command">ceph -s</code> again, just to make sure.
    Continue if the monitor is not yet in quorum.
   </p><div class="qandaset" id="id-1.5.8.7.2.5"><div class="free-id" id="id-1.5.8.7.2.5.1"> </div><dl class="qandaentry"><dt class="question" id="id-1.5.8.7.2.5.1.1"><strong>1.</strong>
       What if the state is <code class="literal">probing</code>?
      </dt><dd class="answer" id="id-1.5.8.7.2.5.1.2"><p>
       This means the monitor is still looking for the other monitors. Every
       time you start a monitor, the monitor stays in this state for some time
       while trying to find the rest of the monitors specified in the
       <code class="literal">monmap</code>. The time a monitor spends in this state can
       vary. For instance, when on a single-monitor cluster, the monitor passes
       through the probing state almost instantaneously, since there are no
       other monitors around. On a multi-monitor cluster, the monitors will
       stay in this state until they find enough monitors to form a quorum –
       this means that if you have 2 out of 3 monitors down, the one remaining
       monitor stays in this state indefinitely until one of the other monitors
       is brought up manually.
      </p><p>
       If there is a quorum, the monitor should be able to find the remaining
       monitors as long as they can be reached. If your monitor is stuck
       probing and you have gone through with all the communication
       troubleshooting, then there is a chance that the monitor is trying to
       reach the other monitors on a wrong address.
       <code class="literal">mon_status</code> outputs the <code class="literal">monmap</code>
       known to the monitor and checks if the other monitor’s locations match
       reality. If they do not, then it may be related to a broken mon map. If
       they do, then it may be related to severe clock skews amongst the
       monitor nodes and you should refer to <a class="xref" href="bp-troubleshooting-monitors.html#clock-skews" title="6.5.2. Fixing clock skews">Section 6.5.2, “Fixing clock skews”</a>.
      </p></dd></dl><div class="free-id" id="id-1.5.8.7.2.5.2"> </div><dl class="qandaentry"><dt class="question" id="id-1.5.8.7.2.5.2.1"><strong>2.</strong>
       What if the state is <code class="literal">electing</code>?
      </dt><dd class="answer" id="id-1.5.8.7.2.5.2.2"><p>
       This means the monitor is in the middle of an election. These should be
       fast to complete, but at times the monitors can get stuck electing. This
       is usually a sign of a clock skew among the monitor nodes. See
       <a class="xref" href="bp-troubleshooting-monitors.html#clock-skews" title="6.5.2. Fixing clock skews">Section 6.5.2, “Fixing clock skews”</a> for more information. This is not a state
       that is likely to persist and aside from old bugs there is not an
       obvious reason besides clock skews on why this would happen.
      </p></dd></dl><div class="free-id" id="id-1.5.8.7.2.5.3"> </div><dl class="qandaentry"><dt class="question" id="id-1.5.8.7.2.5.3.1"><strong>3.</strong>
       What if the state is <code class="literal">synchronizing</code>?
      </dt><dd class="answer" id="id-1.5.8.7.2.5.3.2"><p>
       This means the monitor is synchronizing with the rest of the cluster in
       order to join the quorum. However, if you notice that the monitor jumps
       from synchronizing to electing and then back to synchronizing, then it
       can mean that the cluster state is advancing (i.e., generating new maps)
       way too fast for the synchronization process to keep up.
      </p></dd></dl><div class="free-id" id="id-1.5.8.7.2.5.4"> </div><dl class="qandaentry"><dt class="question" id="id-1.5.8.7.2.5.4.1"><strong>4.</strong>
       What if the state is <code class="literal">leader</code> or
       <code class="literal">peon</code>?
      </dt><dd class="answer" id="id-1.5.8.7.2.5.4.2"><p>
       This should not happen. If this does happen, it is likely related to
       clock skews, see <a class="xref" href="bp-troubleshooting-monitors.html#clock-skews" title="6.5.2. Fixing clock skews">Section 6.5.2, “Fixing clock skews”</a> for more information. If
       you see no issue with the clock skews, prepare your logs and reach out
       to your support representative.
      </p></dd></dl></div></section><section class="sect2" id="clock-skews" data-id-title="Fixing clock skews"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">6.5.2 </span><span class="title-name">Fixing clock skews</span></span> <a title="Permalink" class="permalink" href="bp-troubleshooting-monitors.html#clock-skews">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-ses/edit/main/xml/bp_troubleshooting_monitors.xml" title="Edit source document"> </a></div></div></div></div></div><p>
    Monitors can be severely affected by significant clock skews across the
    monitor nodes. This usually translates into weird behavior with no obvious
    cause. To avoid such issues, run a clock synchronization tool on your
    monitor nodes.
   </p><p>
    By default, the maximum tolerated clock skew allows clocks to drift up to
    0.05 seconds. This value is configurable via the
    <code class="option">mon-clock-drift-allowed</code> option, however we do not
    recommend doing this. The clock skew mechanism is in place because clock
    skewed monitor may not properly behave. Changing this value without testing
    it first may cause unforeseen effects on the stability of the monitors and
    overall cluster healthiness, although there is no risk of data loss.
   </p><p>
    The monitors will warn you if there is a clock skew by sending a
    <code class="literal">HEALTH_WARN</code> alert. Run the <code class="command">ceph health
    detail</code> command to determine what monitor is flagging a clock
    skew. For example:
   </p><div class="verbatim-wrap"><pre class="screen">mon.c addr 10.10.0.1:6789/0 clock skew 0.08235s &gt; max 0.05s (latency 0.0045s)</pre></div><p>
    If you have a clock skew, synchronize your clocks. Running an NTP client
    may help. If you are already using one and you hit this sort of issue,
    check if you are using an NTP server remote to your network and consider
    hosting your own NTP server on your network. This last option tends to
    reduce the amount of issues with monitor clock skews.
   </p></section><section class="sect2" id="client-connect-mount" data-id-title="Connecting and mounting to the client"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">6.5.3 </span><span class="title-name">Connecting and mounting to the client</span></span> <a title="Permalink" class="permalink" href="bp-troubleshooting-monitors.html#client-connect-mount">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-ses/edit/main/xml/bp_troubleshooting_monitors.xml" title="Edit source document"> </a></div></div></div></div></div><p>
    If you cannot connect or mount to the client, check your iptables. Some OS
    install utilities add a <code class="option">REJECT</code> rule to iptables. The rule
    rejects all clients trying to connect to the host except for SSH. If your
    monitor host’s IP tables have a <code class="option">REJECT</code> rule in place,
    clients connecting from a separate node will fail to mount with a timeout
    error. You need to address iptables rules that reject clients trying to
    connect to Ceph daemons. For example, address rules that look like similar
    to this:
   </p><div class="verbatim-wrap"><pre class="screen">REJECT all -- anywhere anywhere reject-with icmp-host-prohibited</pre></div><p>
    You may also need to add rules to iptables on your Ceph hosts to ensure
    that clients can access the ports associated with your Ceph monitors (for
    example, port 6789 by default) and Ceph OSDs (for example, 6800 through
    7300 by default). For example:
   </p><div class="verbatim-wrap"><pre class="screen">iptables -A INPUT -m multiport -p tcp -s {ip-address}/{netmask} --dports 6789,6800:7300 -j ACCEPT</pre></div></section></section><section class="sect1" id="mons-store-failures" data-id-title="Monitor store failures"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">6.6 </span><span class="title-name">Monitor store failures</span></span> <a title="Permalink" class="permalink" href="bp-troubleshooting-monitors.html#mons-store-failures">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-ses/edit/main/xml/bp_troubleshooting_monitors.xml" title="Edit source document"> </a></div></div></div></div></div><section class="sect2" id="store-corruption" data-id-title="Identifying symptoms of store corruption"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">6.6.1 </span><span class="title-name">Identifying symptoms of store corruption</span></span> <a title="Permalink" class="permalink" href="bp-troubleshooting-monitors.html#store-corruption">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-ses/edit/main/xml/bp_troubleshooting_monitors.xml" title="Edit source document"> </a></div></div></div></div></div><p>
    Ceph monitor stores the cluster map in a key/value store such as LevelDB.
    If a monitor fails due to the key/value store corruption, following error
    messages might be found in the monitor log:
   </p><div class="verbatim-wrap"><pre class="screen">Corruption: error in middle of record</pre></div><p>
    Or:
   </p><div class="verbatim-wrap"><pre class="screen">Corruption: 1 missing files; e.g.: /var/lib/ceph/mon/mon.foo/store.db/1234567.ldb</pre></div></section><section class="sect2" id="healthy-monitor-recovery" data-id-title="Recovering using healthy monitors"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">6.6.2 </span><span class="title-name">Recovering using healthy monitors</span></span> <a title="Permalink" class="permalink" href="bp-troubleshooting-monitors.html#healthy-monitor-recovery">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-ses/edit/main/xml/bp_troubleshooting_monitors.xml" title="Edit source document"> </a></div></div></div></div></div><p>
    If there are any survivors, replace the corrupted one with a new one. After
    booting up, the new joiner will sync up with a healthy peer, and once it is
    fully synchronized, it will be able to serve the clients.
   </p></section><section class="sect2" id="recovery-using-osds" data-id-title="Recovering using OSDs"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">6.6.3 </span><span class="title-name">Recovering using OSDs</span></span> <a title="Permalink" class="permalink" href="bp-troubleshooting-monitors.html#recovery-using-osds">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-ses/edit/main/xml/bp_troubleshooting_monitors.xml" title="Edit source document"> </a></div></div></div></div></div><p>
    But what if all monitors fail at the same time? Since users are encouraged
    to deploy at least three (and preferably five) monitors in a Ceph cluster,
    the chance of simultaneous failure is rare. But unplanned power-downs in a
    data center with improperly configured disk/fs settings could fail the
    underlying file system, and hence kill all the monitors. In this case, we
    can recover the monitor store with the information stored in OSDs.
   </p><div class="verbatim-wrap"><pre class="screen">  ms=/root/mon-store
  mkdir $ms

  # collect the cluster map from stopped OSDs
  for host in $hosts; do
    rsync -avz $ms/. user@$host:$ms.remote
    rm -rf $ms
    ssh user@$host EOF
      for osd in /var/lib/ceph/osd/ceph-*; do
        ceph-objectstore-tool --data-path \$osd --no-mon-config --op update-mon-db --mon-store-path $ms.remote
      done
  EOF
    rsync -avz user@$host:$ms.remote/. $ms
  done

  # rebuild the monitor store from the collected map, if the cluster does not
  # use cephx authentication, we can skip the following steps to update the
  # keyring with the caps, and there is no need to pass the "--keyring" option.
  # i.e. just use "ceph-monstore-tool $ms rebuild" instead
  ceph-authtool /path/to/admin.keyring -n mon. \
    --cap mon 'allow *'
  ceph-authtool /path/to/admin.keyring -n client.admin \
    --cap mon 'allow *' --cap osd 'allow *' --cap mds 'allow *'
  # add one or more ceph-mgr's key to the keyring. in this case, an encoded key
  # for mgr.x is added, you can find the encoded key in
  # /etc/ceph/${cluster}.${mgr_name}.keyring on the machine where ceph-mgr is
  # deployed
  ceph-authtool /path/to/admin.keyring --add-key 'AQDN8kBe9PLWARAAZwxXMr+n85SBYbSlLcZnMA==' -n mgr.x \
    --cap mon 'allow profile mgr' --cap osd 'allow *' --cap mds 'allow *'
  # if your monitors' ids are not single characters like 'a', 'b', 'c', please
  # specify them in the command line by passing them as arguments of the "--mon-ids"
  # option. if you are not sure, please check your ceph.conf to see if there is any
  # sections named like '[mon.foo]'. don't pass the "--mon-ids" option, if you are
  # using DNS SRV for looking up monitors.
  ceph-monstore-tool $ms rebuild -- --keyring /path/to/admin.keyring --mon-ids alpha beta gamma

  # make a backup of the corrupted store.db just in case!  repeat for
  # all monitors.
  mv /var/lib/ceph/mon/mon.foo/store.db /var/lib/ceph/mon/mon.foo/store.db.corrupted

  # move rebuild store.db into place.  repeat for all monitors.
  mv $ms/store.db /var/lib/ceph/mon/mon.foo/store.db
  chown -R ceph:ceph /var/lib/ceph/mon/mon.foo/store.db</pre></div><div class="procedure"><div class="procedure-contents"><ol class="procedure" type="1"><li class="step"><p>
      Collect the map from all OSD hosts.
     </p></li><li class="step"><p>
      Rebuild the store.
     </p></li><li class="step"><p>
      Fill the entities in the keyring file with appropriate caps.
     </p></li><li class="step"><p>
      Replace the corrupted store on <code class="literal">mon.foo</code> with the
      recovered copy.
     </p></li></ol></div></div><section class="sect3" id="using-osds-known-limitations" data-id-title="Known limitations"><div class="titlepage"><div><div><div class="title-container"><h4 class="title"><span class="title-number-name"><span class="title-number">6.6.3.1 </span><span class="title-name">Known limitations</span></span> <a title="Permalink" class="permalink" href="bp-troubleshooting-monitors.html#using-osds-known-limitations">#</a></h4><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-ses/edit/main/xml/bp_troubleshooting_monitors.xml" title="Edit source document"> </a></div></div></div></div></div><p>
     The following information is not recoverable using the steps above:
    </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
       Some added keyrings: all the OSD keyrings added using the <code class="command">ceph
       auth add</code> command are recovered from the OSD’s copy. The
       <code class="literal">client.admin</code> keyring is imported using
       <code class="literal">ceph-monstore-tool</code>. The MDS keyrings and other
       keyrings are missing in the recovered monitor store. You may need to
       re-add them manually.
      </p></li><li class="listitem"><p>
       Creating pools: If any RADOS pools were in the process of being
       creating, that state is lost. The recovery tool assumes that all pools
       have been created. If there are PGs that are stuck in the
       <code class="literal">unknown</code> state after the recovery for a partially
       created pool, you can force creation of the empty PG with the
       <code class="command">ceph osd force-create-pg</code> command. This will create an
       empty PG, so only do this if you know the pool is empty.
      </p></li><li class="listitem"><p>
       MDS Maps: the MDS maps are lost.
      </p></li></ul></div></section></section></section><section class="sect1" id="next-steps" data-id-title="Next steps"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">6.7 </span><span class="title-name">Next steps</span></span> <a title="Permalink" class="permalink" href="bp-troubleshooting-monitors.html#next-steps">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-ses/edit/main/xml/bp_troubleshooting_monitors.xml" title="Edit source document"> </a></div></div></div></div></div><section class="sect2" id="preparing-logs-mons" data-id-title="Preparing your logs"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">6.7.1 </span><span class="title-name">Preparing your logs</span></span> <a title="Permalink" class="permalink" href="bp-troubleshooting-monitors.html#preparing-logs-mons">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-ses/edit/main/xml/bp_troubleshooting_monitors.xml" title="Edit source document"> </a></div></div></div></div></div><p>
    Monitor logs are, by default, kept in
    <code class="filename">/var/log/ceph/ceph-mon.FOO.log*</code>. However, your logs
    may not have the necessary information. If you do not find your monitor
    logs at their default location, you can check where they are by running:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph-conf --name mon.FOO --show-config-value log_file</pre></div><p>
    The amount of information in the logs are subject to the debug levels being
    enforced by your configuration files. If you have not enforced a specific
    debug level, then Ceph is using the default levels and your logs may not
    contain important information to track down you issue. A first step in
    getting relevant information into your logs will be to raise debug levels.
    Similarly to what happens on other components, different parts of the
    monitor will output their debug information on different subsystems. You
    will have to raise the debug levels of those subsystems more closely
    related to your issue. For most situations, setting the following options
    on your monitors will be enough to pinpoint a potential source of the
    issue:
   </p><div class="verbatim-wrap"><pre class="screen">debug mon = 10
debug ms = 1</pre></div></section><section class="sect2" id="restart-adjust-debug" data-id-title="Adjusting debug levels"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">6.7.2 </span><span class="title-name">Adjusting debug levels</span></span> <a title="Permalink" class="permalink" href="bp-troubleshooting-monitors.html#restart-adjust-debug">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-ses/edit/main/xml/bp_troubleshooting_monitors.xml" title="Edit source document"> </a></div></div></div></div></div><p>
    You do not need to restart a monitor to adjust debug legals. You may do it
    in one of two ways:
   </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
      If you have a quorum, either inject the debug option into the monitor you
      want to debug:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph tell mon.FOO config set debug_mon 10/10</pre></div><p>
      Or into all monitors at once:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph tell mon.* config set debug_mon 10/10</pre></div></li><li class="listitem"><p>
      If you have no quorum, use the monitor's admin socket and directly adjust
      the configuration options:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph daemon mon.FOO config set debug_mon 10/10</pre></div></li></ul></div><p>
    Going back to default values is as easy as rerunning the above commands
    using the debug level 1/10 instead. You can check your current values using
    the admin socket and the following commands:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph daemon mon.FOO config show</pre></div><p>
    Or:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph daemon mon.FOO config get 'OPTION_NAME'</pre></div></section></section><section class="sect1" id="deploy-mgr-manually" data-id-title="Manually deploying a MGR daemon"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">6.8 </span><span class="title-name">Manually deploying a MGR daemon</span></span> <a title="Permalink" class="permalink" href="bp-troubleshooting-monitors.html#deploy-mgr-manually">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-ses/edit/main/xml/bp_troubleshooting_monitors.xml" title="Edit source document"> </a></div></div></div></div></div><p>
   cephadm requires a MGR daemon in order to manage the cluster. If the last
   MGR of a cluster was removed, follow these steps to deploy an example MGR
   daemon named <code class="literal">mgr.hostname.smfvfd</code> on a random host of your
   cluster manually:
  </p><div class="procedure"><div class="procedure-contents"><ol class="procedure" type="1"><li class="step"><p>
     Disable the cephadm scheduler to prevent cephadm from removing the new
     MGR daemon:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph config-key set mgr/cephadm/pause true</pre></div></li><li class="step"><p>
     Get or create the auth entry for the new MGR daemon:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph auth get-or-create <em class="replaceable">mgr.hostname.smfvfd</em> \
mon "profile mgr" osd "allow *" mds "allow *"</pre></div></li><li class="step"><p>
     Generate a minimal <code class="filename">ceph.conf</code>:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph config generate-minimal-conf</pre></div></li><li class="step"><p>
     Find the name of the container image:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>ceph config get "mgr.hostname.smfvfd" container_image</pre></div></li><li class="step"><p>
     Create a file <code class="filename">config-json.json</code> which contains the
     information necessary to deploy the daemon, for example:
    </p><div class="verbatim-wrap"><pre class="screen">{
  "config": "# minimal ceph.conf for 8255263a-a97e-4934-822c-00bfe029b28f\n[global]\n\tfsid = 8255263a-a97e-4934-822c-00bfe029b28f\n\tmon_host = [v2:192.168.0.1:40483/0,v1:192.168.0.1:40484/0]\n",
  "keyring": "[mgr.hostname.smfvfd]\n\tkey = V2VyIGRhcyBsaWVzdCBpc3QgZG9vZi4=\n"
}</pre></div></li><li class="step"><p>
     Deploy the daemon:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">cephuser@adm &gt; </code>cephadm --image <em class="replaceable">IMAGE_NAME</em> \
 deploy --fsid <em class="replaceable">CLUSTER_FSID</em> \
 --name mgr.hostname.smfvfd --config-json config-json.json</pre></div></li></ol></div></div></section></section><nav class="bottom-pagination"><div><a class="pagination-link prev" href="bp-troubleshooting-pgs.html"><span class="pagination-relation">Previous</span><span class="pagination-label"><span class="title-number">Chapter 5 </span>Troubleshooting placement groups (PGs)</span></a> </div><div><a class="pagination-link next" href="bp-troubleshooting-networking.html"><span class="pagination-relation">Next</span><span class="pagination-label"><span class="title-number">Chapter 7 </span>Troubleshooting networking</span></a> </div></nav></article><aside id="_side-toc-page" class="side-toc"><div class="side-title">On this page</div><div class="toc"><ul><li><span class="sect1"><a href="bp-troubleshooting-monitors.html#mons-initial-troubleshooting"><span class="title-number">6.1 </span><span class="title-name">Initial troubleshooting</span></a></span></li><li><span class="sect1"><a href="bp-troubleshooting-monitors.html#mons-admin-socket"><span class="title-number">6.2 </span><span class="title-name">Using the monitor's admin socket</span></a></span></li><li><span class="sect1"><a href="bp-troubleshooting-monitors.html#mons-understanding-mons-status"><span class="title-number">6.3 </span><span class="title-name">Understanding <code class="literal">mons_status</code></span></a></span></li><li><span class="sect1"><a href="bp-troubleshooting-monitors.html#mons-restoring-quorum"><span class="title-number">6.4 </span><span class="title-name">Restoring the MONs quorum</span></a></span></li><li><span class="sect1"><a href="bp-troubleshooting-monitors.html#mons-common-issues"><span class="title-number">6.5 </span><span class="title-name">Most common monitor issues</span></a></span></li><li><span class="sect1"><a href="bp-troubleshooting-monitors.html#mons-store-failures"><span class="title-number">6.6 </span><span class="title-name">Monitor store failures</span></a></span></li><li><span class="sect1"><a href="bp-troubleshooting-monitors.html#next-steps"><span class="title-number">6.7 </span><span class="title-name">Next steps</span></a></span></li><li><span class="sect1"><a href="bp-troubleshooting-monitors.html#deploy-mgr-manually"><span class="title-number">6.8 </span><span class="title-name">Manually deploying a MGR daemon</span></a></span></li></ul></div><div class="side-title">Share this page</div><ul class="share"><li><a id="_share-fb" href="#" title="Facebook"> </a></li><li><a id="_share-in" href="#" title="LinkedIn"> </a></li><li><a id="_share-tw" href="#" title="Twitter"> </a></li><li><a id="_share-mail" href="#" title="E-Mail"> </a></li><li><a id="_print-button" href="#" title="Print this page"> </a></li></ul> </aside></main><footer id="_footer"><div class="growth-inhibitor"><div class="copy"><span class="copy__rights">© SUSE
                 2022</span></div></div></footer></body></html>